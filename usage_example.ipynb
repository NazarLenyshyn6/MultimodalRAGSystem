{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3064fb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\MultimodalRAGSystem\\LLM\\rag_llm.py:58: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  model: Ollama = pydantic.Field(default=Ollama(model='llama3.2'))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from DataIngestion.configurated_website_loaders import news_article_loader\n",
    "from Preprocessing.text_extraction import SimpleBS4TextExtractor\n",
    "from Preprocessing.text_spitting import RecursiveTextSplitter\n",
    "from Preprocessing.image_loaders import RequestsImageLoader\n",
    "from Preprocessing.image_describer import BLIPImageDescriber\n",
    "from Embedding.text_embedding import SentenceTransformerTextEmbedding\n",
    "from VectorStore.chroma_vector_store import ChromaVectorStore\n",
    "from Internals.adapters import ChromaTextEmbeddingAdapter\n",
    "from LLM.rag_llm import OllamaRAGLLM\n",
    "\n",
    "BASE_URL = \"https://www.deeplearning.ai/the-batch\"\n",
    "NEW_URL = \"https://www.deeplearning.ai/the-batch/issue-284/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f53e6279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParsedData(url=https://www.deeplearning.ai/the-batch/issue-284/, parsed_tags=dict_keys(['Title', 'Author', 'Published_date', 'Content', 'Summary', 'Tags', 'Paragraph', 'Image']))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data = news_article_loader.load(NEW_URL)\n",
    "loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb2488db",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_extractor = SimpleBS4TextExtractor()\n",
    "image_loader = RequestsImageLoader()\n",
    "\n",
    "text = text_extractor.extract_text_from_elements(loaded_data.get_all())\n",
    "images = []\n",
    "for img in loaded_data.image:\n",
    "    loaded_img = image_loader.load(img['src'])\n",
    "    if loaded_img is not None:\n",
    "        images.append(loaded_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ca65bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"issue 284\\nNews\\nDeepSeek Ups the Open Weights Ante\\nU.S. Moves to Expand AI Export Restrictions\\nAI Supercomputer on Your Desk\\nCalibrating Contrast\\n\\n\\nExplore Courses\\nAI Newsletter\\n\\nCommunity\\n\\nResources\\nCompany\\n\\n\\n\\n\\n\\n\\n\\n✨ New course! Enroll in Reinforcement Fine-Tuning LLMs with GRPO Explore Courses AI Newsletter The Batch Andrew's Letter Data Points ML Research Blog Community Forum Events Ambassadors Ambassador Spotlight Resources Company About Careers Contact Start Learning Weekly Issues Andrew's Letters Data Points ML Research Business Science Culture Hardware AI Careers About Subscribe The Batch Weekly Issues issue 284 Published Jan 15, 2025 Reading time 13 min read Published Jan 15, 2025 Reading time 13 min read Share Dear friends, Writing software, especially prototypes, is becoming cheaper. This will lead to increased demand for people who can decide what to build. AI Product Management has a bright future! Software is often written by teams that comprise Product Managers (PMs), who decide what to build (such as what features to implement for what users) and Software Developers, who write the code to build the product. Economics shows that when two goods are complements — such as cars (with internal-combustion engines) and gasoline — falling prices in one leads to higher demand for the other. For example, as cars became cheaper, more people bought them, which led to increased demand for gas. Something similar will happen in software. Given a clear specification for what to build, AI is making the building itself much faster and cheaper. This will significantly increase demand for people who can come up with clear specs for valuable things to build. This is why I’m excited about the future of Product Management, the discipline of developing and managing software products. I’m especially excited about the future of AI Product Management, the discipline of developing and managing AI software products. Many companies have an Engineer:PM ratio of, say, 6:1. (The ratio varies widely by company and industry, and anywhere from 4:1 to 10:1 is typical.) As coding becomes more efficient, I think teams will need more product management work (as well as design work) as a fraction of the total workforce. Perhaps engineers will step in to do some of this work, but if it remains the purview of specialized Product Managers, then the demand for these roles will grow. This change in the composition of software development teams is not yet moving forward at full speed. One major force slowing this shift, particularly in AI Product Management, is that Software Engineers, being technical, are understanding and embracing AI much faster than Product Managers. Even today, most companies have difficulty finding people who know how to develop products and also understand AI, and I expect this shortage to grow. Further, AI Product Management requires a different set of skills than traditional software Product Management. It requires: Technical proficiency in AI. PMs need to understand what products might be technically feasible to build. They also need to understand the lifecycle of AI projects, such as data collection, building, then monitoring, and maintenance of AI models. Iterative development. Because AI development is much more iterative than traditional software and requires more course corrections along the way, PMs need to understand how to manage such a process. Data proficiency. AI products often learn from data, and they can be designed to generate richer forms of data than traditional software. Skill in managing ambiguity. Because AI’s performance is hard to predict in advance, PMs need to be comfortable with this and have tactics to manage it. Ongoing learning. AI technology is advancing rapidly. PMs, like everyone else who aims to make best use of the technology, need to keep up with the latest technology advances, product ideas, and how they fit into users’ lives. Finally, AI Product Managers will need to know how to ensure that AI is implemented responsibly (for example, when we need to implement guardrails to prevent bad outcomes), and also be skilled at gathering feedback fast to keep projects moving. Increasingly, I also expect strong product managers to be able to build prototypes for themselves. The demand for good AI Product Managers will be huge. In addition to growing AI Product Management as a discipline, perhaps some engineers will also end up doing more product management work. The variety of valuable things we can build is nearly unlimited. What a great time to build! Keep learning, Andrew A MESSAGE FROM\\xa0DEEPLEARNING.AI Get up-close and personal with OpenAI’s groundbreaking o1 model! In our short course “Reasoning with o1,” you’ll learn how to get the best performance in coding, planning, and STEM tasks; perform complex, multi-step tasks; and optimize prompts with meta prompting. Enroll today News DeepSeek Ups the Open Weights Ante A new model from Hangzhou upstart DeepSeek delivers outstanding performance and may change the equation for training costs. What’s new: DeepSeek-V3 is an open large language model that outperforms Llama 3.1 405B and GPT-4o on key benchmarks and achieves exceptional scores in coding and math. The weights are open except for applications that involve military uses, harming minors, generating false information, and similar restrictions. You can download them here . Mixture of experts (MoE) basics: The MoE architecture uses different subsets of its parameters to process different inputs. Each MoE layer contains a group of neural networks, or experts, preceded by a gating module that learns to choose which one(s) to use based on the input. In this way, different experts learn to specialize in different types of examples. Because not all parameters are used to produce any given output, the network uses less energy and runs faster than models of similar size that use all parameters to process every input. How it works: DeepSeek-V3 is a mixture-of-experts (MoE) transformer that comprises 671 billion parameters, of which 37 billion are active at any moment. The team trained the model in 2.79 million GPU hours — less than 1/10 the time required to train Llama 3.1 405B , which DeepSeek-V3 substantially outperforms — at an extraordinarily low cost of $5.6 million. The developers trained it on roughly 15 trillion tokens, including a larger percentage of coding and math data relative to DeepSeek-V2. They fine-tuned it on a wide variety of tasks using output generated by DeepSeek-R1 and DeepSeek-V2.5. They further sharpened its performance across diverse domains using the reinforcement learning algorithm known as group relative policy optimization . Earlier work showed that training to predict the next two tokens would improve performance over learning to predict just one. The authors implemented this procedure. The model learned to predict the first token as usual and used an additional set of layers to learn to predict the second token. The additional layers aren’t used at inference. Following DeepSeek-V2 , DeepSeek-V3 uses multi-head latent attention, which saves memory during execution relative to other variants of attention. Also like DeepSeek-V2, the new model combines dedicated (routed) and shared experts. The model chooses eight of 256 experts for a particular input, but it also uses a shared expert that processes all inputs. Results: In DeepSeek’s tests, DeepSeek-V3 outperformed Llama 3.1 405B and Qwen 2.5 72B across the board, and its performance compared favorably with that of GPT-4o. DeepSeek-V3 showed exceptional performance in coding and math tasks. In coding, DeepSeek-V3 dominated in five of the seven benchmarks tested. However, DeepSeek-V3 lost to o1 on one of the five, according to a public leaderboard. Specifically, on Polyglot , which tests a model’s ability to generate code in response to difficult requests in multiple programming languages, DeepSeek-V3 (48.5 percent accuracy) beat Claude Sonnet 3.5 (45.3 percent accuracy), though it lost to o1 (61.7 percent accuracy). In language tasks, it performed neck-and-neck with Claude 3.5 Sonnet, achieving higher scores in some tasks and lower in others. Behind the news: OpenAI’s o1 models excel thanks to agentic workflows in which they reflect on their own outputs, use tools, and so on. DeepSeek swims against the tide and achieves superior results without relying on agentic workflows. Why it matters: Open models continue to challenge closed models, giving developers high-quality options that they can modify and deploy at will. But the larger story is DeepSeek-V3’s shockingly low training cost. The team doesn’t explain precisely how the model achieves outstanding performance with such a low processing budget. (The paper credits “meticulous engineering optimizations.”) But it’s likely that DeepSeek’s steady refinement of MoE is a key factor. DeepSeek-V2, also an MoE model, saved more than 40 percent in training versus the earlier DeepSeek 67B, which didn’t employ MoE. In 2022, Microsoft found that MoE cost five times less in training for equal performance compared to a dense model, and Google and Meta reported that MoE achieved better performance than dense models trained on the same numbers of tokens. We’re thinking: If they can be replicated, DeepSeek’s results have significant implications for the economics of training foundation models. If indeed it now costs around $5 million to build a GPT-4o-level model, more teams will be able to train such models, and the cost of competing with the AI giants could fall dramatically. U.S. Moves to Expand AI Export Restrictions The United States proposed limits on exports of AI technology that would dramatically expand previous restrictions, creating a new international hierarchy for access to advanced chips and models. What’s new: The Biden administration, which will transition to leadership under incoming President Trump next week, issued new rules that restrict exports of AI chips and models to most countries beyond a select group of close allies. The rules, which are not yet final, would create a three-tier system that limits exports to a number of close allies and blocks access entirely to China, Iran, North Korea, Russia, and others. They also would introduce the U.S.’ first-ever restrictions on exporting closed weights for large AI models. How it works: The restrictions were announced shortly after a leak reached the press. A public comment period of 120 days will enable the incoming U.S. Presidential administration to consider input from the business and diplomatic communities and modify the rules before they take effect. The rules are scheduled to take effect in one year. A new hierarchy divides nations into three groups that would have different degrees of access to AI chips both designed in the U.S. and manufactured abroad using U.S. technology, as well as proprietary AI models. Tier 1: Australia, Japan, Taiwan, the United Kingdom, and most of Europe would retain nearly unrestricted access. However, these nations must keep 75 percent of their AI computing power within allied countries. No more than 10 percent can be transferred to any single country outside this group to ensure that advanced AI development remains concentrated among close U.S. allies. Tier 2: Traditional U.S. allies and trade partners like Israel, Saudi Arabia, and Singapore face an initial cap of 507 million units of total processing power (TPP) — roughly the computational capacity of 32,000 Nvidia H100 chips — through the first quarter of 2025. The cap would increase to 1.02 billion TPP by 2027. U.S. companies that operate in these countries can apply for higher limits: 633 million TPP in Q1 2025, rising to 5.064 billion TPP by Q1 2027. Tier 3: China, Russia, and around two dozen other countries are blocked from receiving advanced AI chips, model weights, and specialized knowledge related to these systems. The U.S. Commerce Department’s export control agency must approve the export of models or transfer of weights of closed models that were trained using more than 10 26 computational operations. These rules target future systems, as no known models today used this amount of computation during training. Companies based in the U.S. must maintain at least 50 percent of their total AI computing power within U.S. borders. They also must track distribution of their models, implement security measures, and submit to regular audits. Behind the news: The proposed rules build on 2022’s CHIPS and Science Act , which was designed to strengthen domestic semiconductor production and restrict technologies abroad that could bear on U.S. security. An initial round of restrictions in late 2022 barred semiconductor suppliers AMD and Nvidia from selling advanced chips to Chinese firms. In November 2024, the U.S. tightened restrictions further, ordering Taiwan Semiconductor Manufacturing Company, which fabricates those chips, to halt production of advanced chips destined for China. Plus green AI infrastructure: In addition, President Biden issued an executive order to encourage the rapid build-out of computing infrastructure for AI. The federal government will hold competitions among private companies to lease sites it owns for the building of data centers at private expense. The selection of sites will take into account availability of sources of clean energy, including support for nuclear energy. The government will expedite permitting on these sites and support development of energy transmission lines around them. It will also encourage international allies to invest in AI infrastructure powered by clean energy. Why it matters: Protecting the United States’ advantages in high tech has been a rising priority for the White House over the past decade.\\xa0The earlier export restrictions forced many Chinese AI developers to rely on less-powerful hardware. The new limits are likely to have a far broader impact. They could force developers in the Tier 2 and Tier 3 countries to build less resource-intensive models and lead them to collaborate more closely with each other, reducing the value of U.S.-made technology worldwide. They could hurt U.S. chip vendors, which have warned that the rules could weaken U.S. competitiveness in the global economy. They could also force companies that are building huge data centers to process AI calculations to reconsider their plans. We’re thinking: The Biden administration’s embargo on AI chips has been leaky . So far, it has slowed down adversaries only slightly while spurring significant investment in potential suppliers that aren’t connected to the U.S. While the public comment period invites lobbying and industry feedback, ultimately geopolitical priorities may hold sway. Whatever the outcome, reducing the world’s dependence on U.S. chips and models would result in a very different global AI ecosystem. AI Supercomputer on Your Desk Nvidia’s new desktop computer is built specifically to run large AI models. What’s new: Project Digits is a personal supercomputer intended to help developers fine-tune and run large models locally. Project Digits, which is small enough to hold in one hand, will be available in May, starting at $3000. How it works: Project Digits is designed to run models of up to 200 billion parameters — roughly five times the size that fits comfortably on typical consumer hardware — provided they’re quantized to 4 bits of precision. Two units can be connected to run models such as Meta’s Llama 3.1 405B. Complete specifications are not yet available. Project Digits runs Nvidia’s DGX operating system, a flavor of Ubuntu Linux. The system is based on a GB10 system-on-a-chip that combines the Nvidia Blackwell GPU architecture (which serves as the basis for its latest B100 GPUs) and Grace CPU architecture (designed to manage AI workloads in data centers), connected via high-bandwidth NVLink interconnect. It comes with 128 GB of unified memory and 4 terabytes of solid-state storage. The system connects to Nvidia’s DGX Cloud service to enable developers to deploy models from a local machine to cloud infrastructure. Behind the news: In a blitz of announcements at the Consumer Electronics Show (CES), Nvidia also launched a platform for developing robotics, autonomous vehicles, and other physical AI systems. Cosmos includes pretrained language and vision models that range from 4 billion to 14 billion parameters for generating synthetic training data for robots or building policy models that translate a robot’s state into its next action. Nvidia also released Cosmos Nemotron, a 34 billion-parameter, vision-language model designed for use by AI agents, plus a video tokenizer and other tools for robotics developers. Why it matters: It’s common to train models on Nvidia A100 or H100 GPUs, which come with a price tag of at least $8,000 or $20,000 respectively, along with 40 gigabytes to 80 gigabytes of memory. These hefty requirements push many developers to buy access to computing infrastructure from a cloud provider. Coming in at $3,000 with 128 gigabytes of memory, Project Digits is designed to empower machine learning engineers to train and run larger models on their own machines. We’re thinking: We look forward to seeing cost/throughput comparisons between running a model on Project Digits, A100, and H100. Calibrating Contrast Contrastive loss functions make it possible to produce good embeddings without labeled data. A twist on this idea makes even more useful embeddings. What’s new: Vlad Sobal and colleagues at Meta, New York University, Brown University, Genentech, and Canadian Institute for Advanced Research introduced X-Sample contrastive loss (X-CLR), a self-supervised loss function that enables vision models to learn embeddings that capture similarities and differences among examples with greater subtlety. Key insight: Contrastive loss functions like SimCLR equally encourage a model to produce dissimilar embeddings of images of, say, a cat, a dog, and a dump truck. But, of course, cats and dogs are more similar to each other than either are to dump trucks. Instead of marking examples as similar or dissimilar, X-CLR assigns similarity scores, so a model can learn to produce embeddings that match those scores. How it works: The authors used X-CLR to train an embedding model on Conceptual Captions datasets of image-text pairs scraped from the web: CC-3M (3 million text-image pairs) and CC-12M (12 million text-image pairs). The model was similar to CLIP , except the text encoder was a sentence transformer pretrained on sentence pairs, and the vision encoder was a ResNet-50 pretrained on ImageNet. The sentence transformer embedded text captions for all examples. The system computed similarity scores according to cosine similarity between the text embeddings. Similarly, a ResNet-50 computed image embeddings, and the system computed similarity scores between them. The authors froze the sentence transformer and used the text similarity scores as labels in the loss function. The loss function minimized the difference between the similarity scores of the text embeddings and the corresponding similarity scores of the image embeddings. Results: Systems trained using X-CLR outperformed competitors in ImageNet classification, especially when less training data was available. (The authors followed CLIP’s method of classification: They computed the similarity between an image embedding and text embeddings of all classes. The image’s classification was the class that corresponds to the text embedding with the highest similarity to the image embedding.) The authors compared a system trained using X-CLR, one trained using SimCLR, and CLIP. After training on the CC-3M dataset, the X-CLR system achieved 58.2 percent accuracy on ImageNet, while the SimCLR model achieved 57.0 percent and CLIP achieved 41.0 percent. Training on CC-12M resulted in smaller differences: X-CLR achieved 59.4 percent accuracy, SimCLR achieved 58.9 percent, and CLIP achieved 58.8 percent. Why it matters: Contrastive loss functions are very useful, but the similar/dissimilar dichotomy leaves important nuances unaccounted for. Like CLIP, X-CLR takes advantage of both images and their captions for self-supervised learning. However, CLIP learns to recognize image-text pairs as similar or dissimilar, while X-CLR matches image-image pairs using captions as a similarity signal that’s continuous rather than discrete. We’re thinking: Reality is not black and white. Allowing for shades of gray makes for better modeling. Share Subscribe to The Batch Stay updated with weekly AI News and Insights delivered to your inbox Courses The Batch Community Careers About\\n✨ New course! Enroll in Reinforcement Fine-Tuning LLMs with GRPO Explore Courses AI Newsletter The Batch Andrew's Letter Data Points ML Research Blog Community Forum Events Ambassadors Ambassador Spotlight Resources Company About Careers Contact Start Learning Weekly Issues Andrew's Letters Data Points ML Research Business Science Culture Hardware AI Careers About Subscribe The Batch Weekly Issues issue 284 Published Jan 15, 2025 Reading time 13 min read Published Jan 15, 2025 Reading time 13 min read Share Dear friends, Writing software, especially prototypes, is becoming cheaper. This will lead to increased demand for people who can decide what to build. AI Product Management has a bright future! Software is often written by teams that comprise Product Managers (PMs), who decide what to build (such as what features to implement for what users) and Software Developers, who write the code to build the product. Economics shows that when two goods are complements — such as cars (with internal-combustion engines) and gasoline — falling prices in one leads to higher demand for the other. For example, as cars became cheaper, more people bought them, which led to increased demand for gas. Something similar will happen in software. Given a clear specification for what to build, AI is making the building itself much faster and cheaper. This will significantly increase demand for people who can come up with clear specs for valuable things to build. This is why I’m excited about the future of Product Management, the discipline of developing and managing software products. I’m especially excited about the future of AI Product Management, the discipline of developing and managing AI software products. Many companies have an Engineer:PM ratio of, say, 6:1. (The ratio varies widely by company and industry, and anywhere from 4:1 to 10:1 is typical.) As coding becomes more efficient, I think teams will need more product management work (as well as design work) as a fraction of the total workforce. Perhaps engineers will step in to do some of this work, but if it remains the purview of specialized Product Managers, then the demand for these roles will grow. This change in the composition of software development teams is not yet moving forward at full speed. One major force slowing this shift, particularly in AI Product Management, is that Software Engineers, being technical, are understanding and embracing AI much faster than Product Managers. Even today, most companies have difficulty finding people who know how to develop products and also understand AI, and I expect this shortage to grow. Further, AI Product Management requires a different set of skills than traditional software Product Management. It requires: Technical proficiency in AI. PMs need to understand what products might be technically feasible to build. They also need to understand the lifecycle of AI projects, such as data collection, building, then monitoring, and maintenance of AI models. Iterative development. Because AI development is much more iterative than traditional software and requires more course corrections along the way, PMs need to understand how to manage such a process. Data proficiency. AI products often learn from data, and they can be designed to generate richer forms of data than traditional software. Skill in managing ambiguity. Because AI’s performance is hard to predict in advance, PMs need to be comfortable with this and have tactics to manage it. Ongoing learning. AI technology is advancing rapidly. PMs, like everyone else who aims to make best use of the technology, need to keep up with the latest technology advances, product ideas, and how they fit into users’ lives. Finally, AI Product Managers will need to know how to ensure that AI is implemented responsibly (for example, when we need to implement guardrails to prevent bad outcomes), and also be skilled at gathering feedback fast to keep projects moving. Increasingly, I also expect strong product managers to be able to build prototypes for themselves. The demand for good AI Product Managers will be huge. In addition to growing AI Product Management as a discipline, perhaps some engineers will also end up doing more product management work. The variety of valuable things we can build is nearly unlimited. What a great time to build! Keep learning, Andrew A MESSAGE FROM\\xa0DEEPLEARNING.AI Get up-close and personal with OpenAI’s groundbreaking o1 model! In our short course “Reasoning with o1,” you’ll learn how to get the best performance in coding, planning, and STEM tasks; perform complex, multi-step tasks; and optimize prompts with meta prompting. Enroll today News DeepSeek Ups the Open Weights Ante A new model from Hangzhou upstart DeepSeek delivers outstanding performance and may change the equation for training costs. What’s new: DeepSeek-V3 is an open large language model that outperforms Llama 3.1 405B and GPT-4o on key benchmarks and achieves exceptional scores in coding and math. The weights are open except for applications that involve military uses, harming minors, generating false information, and similar restrictions. You can download them here . Mixture of experts (MoE) basics: The MoE architecture uses different subsets of its parameters to process different inputs. Each MoE layer contains a group of neural networks, or experts, preceded by a gating module that learns to choose which one(s) to use based on the input. In this way, different experts learn to specialize in different types of examples. Because not all parameters are used to produce any given output, the network uses less energy and runs faster than models of similar size that use all parameters to process every input. How it works: DeepSeek-V3 is a mixture-of-experts (MoE) transformer that comprises 671 billion parameters, of which 37 billion are active at any moment. The team trained the model in 2.79 million GPU hours — less than 1/10 the time required to train Llama 3.1 405B , which DeepSeek-V3 substantially outperforms — at an extraordinarily low cost of $5.6 million. The developers trained it on roughly 15 trillion tokens, including a larger percentage of coding and math data relative to DeepSeek-V2. They fine-tuned it on a wide variety of tasks using output generated by DeepSeek-R1 and DeepSeek-V2.5. They further sharpened its performance across diverse domains using the reinforcement learning algorithm known as group relative policy optimization . Earlier work showed that training to predict the next two tokens would improve performance over learning to predict just one. The authors implemented this procedure. The model learned to predict the first token as usual and used an additional set of layers to learn to predict the second token. The additional layers aren’t used at inference. Following DeepSeek-V2 , DeepSeek-V3 uses multi-head latent attention, which saves memory during execution relative to other variants of attention. Also like DeepSeek-V2, the new model combines dedicated (routed) and shared experts. The model chooses eight of 256 experts for a particular input, but it also uses a shared expert that processes all inputs. Results: In DeepSeek’s tests, DeepSeek-V3 outperformed Llama 3.1 405B and Qwen 2.5 72B across the board, and its performance compared favorably with that of GPT-4o. DeepSeek-V3 showed exceptional performance in coding and math tasks. In coding, DeepSeek-V3 dominated in five of the seven benchmarks tested. However, DeepSeek-V3 lost to o1 on one of the five, according to a public leaderboard. Specifically, on Polyglot , which tests a model’s ability to generate code in response to difficult requests in multiple programming languages, DeepSeek-V3 (48.5 percent accuracy) beat Claude Sonnet 3.5 (45.3 percent accuracy), though it lost to o1 (61.7 percent accuracy). In language tasks, it performed neck-and-neck with Claude 3.5 Sonnet, achieving higher scores in some tasks and lower in others. Behind the news: OpenAI’s o1 models excel thanks to agentic workflows in which they reflect on their own outputs, use tools, and so on. DeepSeek swims against the tide and achieves superior results without relying on agentic workflows. Why it matters: Open models continue to challenge closed models, giving developers high-quality options that they can modify and deploy at will. But the larger story is DeepSeek-V3’s shockingly low training cost. The team doesn’t explain precisely how the model achieves outstanding performance with such a low processing budget. (The paper credits “meticulous engineering optimizations.”) But it’s likely that DeepSeek’s steady refinement of MoE is a key factor. DeepSeek-V2, also an MoE model, saved more than 40 percent in training versus the earlier DeepSeek 67B, which didn’t employ MoE. In 2022, Microsoft found that MoE cost five times less in training for equal performance compared to a dense model, and Google and Meta reported that MoE achieved better performance than dense models trained on the same numbers of tokens. We’re thinking: If they can be replicated, DeepSeek’s results have significant implications for the economics of training foundation models. If indeed it now costs around $5 million to build a GPT-4o-level model, more teams will be able to train such models, and the cost of competing with the AI giants could fall dramatically. U.S. Moves to Expand AI Export Restrictions The United States proposed limits on exports of AI technology that would dramatically expand previous restrictions, creating a new international hierarchy for access to advanced chips and models. What’s new: The Biden administration, which will transition to leadership under incoming President Trump next week, issued new rules that restrict exports of AI chips and models to most countries beyond a select group of close allies. The rules, which are not yet final, would create a three-tier system that limits exports to a number of close allies and blocks access entirely to China, Iran, North Korea, Russia, and others. They also would introduce the U.S.’ first-ever restrictions on exporting closed weights for large AI models. How it works: The restrictions were announced shortly after a leak reached the press. A public comment period of 120 days will enable the incoming U.S. Presidential administration to consider input from the business and diplomatic communities and modify the rules before they take effect. The rules are scheduled to take effect in one year. A new hierarchy divides nations into three groups that would have different degrees of access to AI chips both designed in the U.S. and manufactured abroad using U.S. technology, as well as proprietary AI models. Tier 1: Australia, Japan, Taiwan, the United Kingdom, and most of Europe would retain nearly unrestricted access. However, these nations must keep 75 percent of their AI computing power within allied countries. No more than 10 percent can be transferred to any single country outside this group to ensure that advanced AI development remains concentrated among close U.S. allies. Tier 2: Traditional U.S. allies and trade partners like Israel, Saudi Arabia, and Singapore face an initial cap of 507 million units of total processing power (TPP) — roughly the computational capacity of 32,000 Nvidia H100 chips — through the first quarter of 2025. The cap would increase to 1.02 billion TPP by 2027. U.S. companies that operate in these countries can apply for higher limits: 633 million TPP in Q1 2025, rising to 5.064 billion TPP by Q1 2027. Tier 3: China, Russia, and around two dozen other countries are blocked from receiving advanced AI chips, model weights, and specialized knowledge related to these systems. The U.S. Commerce Department’s export control agency must approve the export of models or transfer of weights of closed models that were trained using more than 10 26 computational operations. These rules target future systems, as no known models today used this amount of computation during training. Companies based in the U.S. must maintain at least 50 percent of their total AI computing power within U.S. borders. They also must track distribution of their models, implement security measures, and submit to regular audits. Behind the news: The proposed rules build on 2022’s CHIPS and Science Act , which was designed to strengthen domestic semiconductor production and restrict technologies abroad that could bear on U.S. security. An initial round of restrictions in late 2022 barred semiconductor suppliers AMD and Nvidia from selling advanced chips to Chinese firms. In November 2024, the U.S. tightened restrictions further, ordering Taiwan Semiconductor Manufacturing Company, which fabricates those chips, to halt production of advanced chips destined for China. Plus green AI infrastructure: In addition, President Biden issued an executive order to encourage the rapid build-out of computing infrastructure for AI. The federal government will hold competitions among private companies to lease sites it owns for the building of data centers at private expense. The selection of sites will take into account availability of sources of clean energy, including support for nuclear energy. The government will expedite permitting on these sites and support development of energy transmission lines around them. It will also encourage international allies to invest in AI infrastructure powered by clean energy. Why it matters: Protecting the United States’ advantages in high tech has been a rising priority for the White House over the past decade.\\xa0The earlier export restrictions forced many Chinese AI developers to rely on less-powerful hardware. The new limits are likely to have a far broader impact. They could force developers in the Tier 2 and Tier 3 countries to build less resource-intensive models and lead them to collaborate more closely with each other, reducing the value of U.S.-made technology worldwide. They could hurt U.S. chip vendors, which have warned that the rules could weaken U.S. competitiveness in the global economy. They could also force companies that are building huge data centers to process AI calculations to reconsider their plans. We’re thinking: The Biden administration’s embargo on AI chips has been leaky . So far, it has slowed down adversaries only slightly while spurring significant investment in potential suppliers that aren’t connected to the U.S. While the public comment period invites lobbying and industry feedback, ultimately geopolitical priorities may hold sway. Whatever the outcome, reducing the world’s dependence on U.S. chips and models would result in a very different global AI ecosystem. AI Supercomputer on Your Desk Nvidia’s new desktop computer is built specifically to run large AI models. What’s new: Project Digits is a personal supercomputer intended to help developers fine-tune and run large models locally. Project Digits, which is small enough to hold in one hand, will be available in May, starting at $3000. How it works: Project Digits is designed to run models of up to 200 billion parameters — roughly five times the size that fits comfortably on typical consumer hardware — provided they’re quantized to 4 bits of precision. Two units can be connected to run models such as Meta’s Llama 3.1 405B. Complete specifications are not yet available. Project Digits runs Nvidia’s DGX operating system, a flavor of Ubuntu Linux. The system is based on a GB10 system-on-a-chip that combines the Nvidia Blackwell GPU architecture (which serves as the basis for its latest B100 GPUs) and Grace CPU architecture (designed to manage AI workloads in data centers), connected via high-bandwidth NVLink interconnect. It comes with 128 GB of unified memory and 4 terabytes of solid-state storage. The system connects to Nvidia’s DGX Cloud service to enable developers to deploy models from a local machine to cloud infrastructure. Behind the news: In a blitz of announcements at the Consumer Electronics Show (CES), Nvidia also launched a platform for developing robotics, autonomous vehicles, and other physical AI systems. Cosmos includes pretrained language and vision models that range from 4 billion to 14 billion parameters for generating synthetic training data for robots or building policy models that translate a robot’s state into its next action. Nvidia also released Cosmos Nemotron, a 34 billion-parameter, vision-language model designed for use by AI agents, plus a video tokenizer and other tools for robotics developers. Why it matters: It’s common to train models on Nvidia A100 or H100 GPUs, which come with a price tag of at least $8,000 or $20,000 respectively, along with 40 gigabytes to 80 gigabytes of memory. These hefty requirements push many developers to buy access to computing infrastructure from a cloud provider. Coming in at $3,000 with 128 gigabytes of memory, Project Digits is designed to empower machine learning engineers to train and run larger models on their own machines. We’re thinking: We look forward to seeing cost/throughput comparisons between running a model on Project Digits, A100, and H100. Calibrating Contrast Contrastive loss functions make it possible to produce good embeddings without labeled data. A twist on this idea makes even more useful embeddings. What’s new: Vlad Sobal and colleagues at Meta, New York University, Brown University, Genentech, and Canadian Institute for Advanced Research introduced X-Sample contrastive loss (X-CLR), a self-supervised loss function that enables vision models to learn embeddings that capture similarities and differences among examples with greater subtlety. Key insight: Contrastive loss functions like SimCLR equally encourage a model to produce dissimilar embeddings of images of, say, a cat, a dog, and a dump truck. But, of course, cats and dogs are more similar to each other than either are to dump trucks. Instead of marking examples as similar or dissimilar, X-CLR assigns similarity scores, so a model can learn to produce embeddings that match those scores. How it works: The authors used X-CLR to train an embedding model on Conceptual Captions datasets of image-text pairs scraped from the web: CC-3M (3 million text-image pairs) and CC-12M (12 million text-image pairs). The model was similar to CLIP , except the text encoder was a sentence transformer pretrained on sentence pairs, and the vision encoder was a ResNet-50 pretrained on ImageNet. The sentence transformer embedded text captions for all examples. The system computed similarity scores according to cosine similarity between the text embeddings. Similarly, a ResNet-50 computed image embeddings, and the system computed similarity scores between them. The authors froze the sentence transformer and used the text similarity scores as labels in the loss function. The loss function minimized the difference between the similarity scores of the text embeddings and the corresponding similarity scores of the image embeddings. Results: Systems trained using X-CLR outperformed competitors in ImageNet classification, especially when less training data was available. (The authors followed CLIP’s method of classification: They computed the similarity between an image embedding and text embeddings of all classes. The image’s classification was the class that corresponds to the text embedding with the highest similarity to the image embedding.) The authors compared a system trained using X-CLR, one trained using SimCLR, and CLIP. After training on the CC-3M dataset, the X-CLR system achieved 58.2 percent accuracy on ImageNet, while the SimCLR model achieved 57.0 percent and CLIP achieved 41.0 percent. Training on CC-12M resulted in smaller differences: X-CLR achieved 59.4 percent accuracy, SimCLR achieved 58.9 percent, and CLIP achieved 58.8 percent. Why it matters: Contrastive loss functions are very useful, but the similar/dissimilar dichotomy leaves important nuances unaccounted for. Like CLIP, X-CLR takes advantage of both images and their captions for self-supervised learning. However, CLIP learns to recognize image-text pairs as similar or dissimilar, while X-CLR matches image-image pairs using captions as a similarity signal that’s continuous rather than discrete. We’re thinking: Reality is not black and white. Allowing for shades of gray makes for better modeling. Share Subscribe to The Batch Stay updated with weekly AI News and Insights delivered to your inbox Courses The Batch Community Careers About\\n✨ New course! Enroll in Reinforcement Fine-Tuning LLMs with GRPO\\n✨ New course! Enroll in Reinforcement Fine-Tuning LLMs with GRPO\\n\\nExplore Courses AI Newsletter The Batch Andrew's Letter Data Points ML Research Blog Community Forum Events Ambassadors Ambassador Spotlight Resources Company About Careers Contact Start Learning\\n\\n\\nExplore Courses AI Newsletter The Batch Andrew's Letter Data Points ML Research Blog Community Forum Events Ambassadors Ambassador Spotlight Resources Company About Careers Contact Start Learning\\nExplore Courses AI Newsletter The Batch Andrew's Letter Data Points ML Research Blog Community Forum Events Ambassadors Ambassador Spotlight Resources Company About Careers Contact Start Learning\\nExplore Courses\\nAI Newsletter\\nThe Batch\\nAndrew's Letter\\nData Points\\nML Research\\nBlog\\nCommunity\\nForum\\nEvents\\nAmbassadors\\nAmbassador Spotlight\\nResources\\nCompany\\nAbout\\nCareers\\nContact\\n\\nWeekly Issues Andrew's Letters Data Points ML Research Business Science Culture Hardware AI Careers About Subscribe The Batch Weekly Issues issue 284 Published Jan 15, 2025 Reading time 13 min read Published Jan 15, 2025 Reading time 13 min read Share Dear friends, Writing software, especially prototypes, is becoming cheaper. This will lead to increased demand for people who can decide what to build. AI Product Management has a bright future! Software is often written by teams that comprise Product Managers (PMs), who decide what to build (such as what features to implement for what users) and Software Developers, who write the code to build the product. Economics shows that when two goods are complements — such as cars (with internal-combustion engines) and gasoline — falling prices in one leads to higher demand for the other. For example, as cars became cheaper, more people bought them, which led to increased demand for gas. Something similar will happen in software. Given a clear specification for what to build, AI is making the building itself much faster and cheaper. This will significantly increase demand for people who can come up with clear specs for valuable things to build. This is why I’m excited about the future of Product Management, the discipline of developing and managing software products. I’m especially excited about the future of AI Product Management, the discipline of developing and managing AI software products. Many companies have an Engineer:PM ratio of, say, 6:1. (The ratio varies widely by company and industry, and anywhere from 4:1 to 10:1 is typical.) As coding becomes more efficient, I think teams will need more product management work (as well as design work) as a fraction of the total workforce. Perhaps engineers will step in to do some of this work, but if it remains the purview of specialized Product Managers, then the demand for these roles will grow. This change in the composition of software development teams is not yet moving forward at full speed. One major force slowing this shift, particularly in AI Product Management, is that Software Engineers, being technical, are understanding and embracing AI much faster than Product Managers. Even today, most companies have difficulty finding people who know how to develop products and also understand AI, and I expect this shortage to grow. Further, AI Product Management requires a different set of skills than traditional software Product Management. It requires: Technical proficiency in AI. PMs need to understand what products might be technically feasible to build. They also need to understand the lifecycle of AI projects, such as data collection, building, then monitoring, and maintenance of AI models. Iterative development. Because AI development is much more iterative than traditional software and requires more course corrections along the way, PMs need to understand how to manage such a process. Data proficiency. AI products often learn from data, and they can be designed to generate richer forms of data than traditional software. Skill in managing ambiguity. Because AI’s performance is hard to predict in advance, PMs need to be comfortable with this and have tactics to manage it. Ongoing learning. AI technology is advancing rapidly. PMs, like everyone else who aims to make best use of the technology, need to keep up with the latest technology advances, product ideas, and how they fit into users’ lives. Finally, AI Product Managers will need to know how to ensure that AI is implemented responsibly (for example, when we need to implement guardrails to prevent bad outcomes), and also be skilled at gathering feedback fast to keep projects moving. Increasingly, I also expect strong product managers to be able to build prototypes for themselves. The demand for good AI Product Managers will be huge. In addition to growing AI Product Management as a discipline, perhaps some engineers will also end up doing more product management work. The variety of valuable things we can build is nearly unlimited. What a great time to build! Keep learning, Andrew A MESSAGE FROM\\xa0DEEPLEARNING.AI Get up-close and personal with OpenAI’s groundbreaking o1 model! In our short course “Reasoning with o1,” you’ll learn how to get the best performance in coding, planning, and STEM tasks; perform complex, multi-step tasks; and optimize prompts with meta prompting. Enroll today News DeepSeek Ups the Open Weights Ante A new model from Hangzhou upstart DeepSeek delivers outstanding performance and may change the equation for training costs. What’s new: DeepSeek-V3 is an open large language model that outperforms Llama 3.1 405B and GPT-4o on key benchmarks and achieves exceptional scores in coding and math. The weights are open except for applications that involve military uses, harming minors, generating false information, and similar restrictions. You can download them here . Mixture of experts (MoE) basics: The MoE architecture uses different subsets of its parameters to process different inputs. Each MoE layer contains a group of neural networks, or experts, preceded by a gating module that learns to choose which one(s) to use based on the input. In this way, different experts learn to specialize in different types of examples. Because not all parameters are used to produce any given output, the network uses less energy and runs faster than models of similar size that use all parameters to process every input. How it works: DeepSeek-V3 is a mixture-of-experts (MoE) transformer that comprises 671 billion parameters, of which 37 billion are active at any moment. The team trained the model in 2.79 million GPU hours — less than 1/10 the time required to train Llama 3.1 405B , which DeepSeek-V3 substantially outperforms — at an extraordinarily low cost of $5.6 million. The developers trained it on roughly 15 trillion tokens, including a larger percentage of coding and math data relative to DeepSeek-V2. They fine-tuned it on a wide variety of tasks using output generated by DeepSeek-R1 and DeepSeek-V2.5. They further sharpened its performance across diverse domains using the reinforcement learning algorithm known as group relative policy optimization . Earlier work showed that training to predict the next two tokens would improve performance over learning to predict just one. The authors implemented this procedure. The model learned to predict the first token as usual and used an additional set of layers to learn to predict the second token. The additional layers aren’t used at inference. Following DeepSeek-V2 , DeepSeek-V3 uses multi-head latent attention, which saves memory during execution relative to other variants of attention. Also like DeepSeek-V2, the new model combines dedicated (routed) and shared experts. The model chooses eight of 256 experts for a particular input, but it also uses a shared expert that processes all inputs. Results: In DeepSeek’s tests, DeepSeek-V3 outperformed Llama 3.1 405B and Qwen 2.5 72B across the board, and its performance compared favorably with that of GPT-4o. DeepSeek-V3 showed exceptional performance in coding and math tasks. In coding, DeepSeek-V3 dominated in five of the seven benchmarks tested. However, DeepSeek-V3 lost to o1 on one of the five, according to a public leaderboard. Specifically, on Polyglot , which tests a model’s ability to generate code in response to difficult requests in multiple programming languages, DeepSeek-V3 (48.5 percent accuracy) beat Claude Sonnet 3.5 (45.3 percent accuracy), though it lost to o1 (61.7 percent accuracy). In language tasks, it performed neck-and-neck with Claude 3.5 Sonnet, achieving higher scores in some tasks and lower in others. Behind the news: OpenAI’s o1 models excel thanks to agentic workflows in which they reflect on their own outputs, use tools, and so on. DeepSeek swims against the tide and achieves superior results without relying on agentic workflows. Why it matters: Open models continue to challenge closed models, giving developers high-quality options that they can modify and deploy at will. But the larger story is DeepSeek-V3’s shockingly low training cost. The team doesn’t explain precisely how the model achieves outstanding performance with such a low processing budget. (The paper credits “meticulous engineering optimizations.”) But it’s likely that DeepSeek’s steady refinement of MoE is a key factor. DeepSeek-V2, also an MoE model, saved more than 40 percent in training versus the earlier DeepSeek 67B, which didn’t employ MoE. In 2022, Microsoft found that MoE cost five times less in training for equal performance compared to a dense model, and Google and Meta reported that MoE achieved better performance than dense models trained on the same numbers of tokens. We’re thinking: If they can be replicated, DeepSeek’s results have significant implications for the economics of training foundation models. If indeed it now costs around $5 million to build a GPT-4o-level model, more teams will be able to train such models, and the cost of competing with the AI giants could fall dramatically. U.S. Moves to Expand AI Export Restrictions The United States proposed limits on exports of AI technology that would dramatically expand previous restrictions, creating a new international hierarchy for access to advanced chips and models. What’s new: The Biden administration, which will transition to leadership under incoming President Trump next week, issued new rules that restrict exports of AI chips and models to most countries beyond a select group of close allies. The rules, which are not yet final, would create a three-tier system that limits exports to a number of close allies and blocks access entirely to China, Iran, North Korea, Russia, and others. They also would introduce the U.S.’ first-ever restrictions on exporting closed weights for large AI models. How it works: The restrictions were announced shortly after a leak reached the press. A public comment period of 120 days will enable the incoming U.S. Presidential administration to consider input from the business and diplomatic communities and modify the rules before they take effect. The rules are scheduled to take effect in one year. A new hierarchy divides nations into three groups that would have different degrees of access to AI chips both designed in the U.S. and manufactured abroad using U.S. technology, as well as proprietary AI models. Tier 1: Australia, Japan, Taiwan, the United Kingdom, and most of Europe would retain nearly unrestricted access. However, these nations must keep 75 percent of their AI computing power within allied countries. No more than 10 percent can be transferred to any single country outside this group to ensure that advanced AI development remains concentrated among close U.S. allies. Tier 2: Traditional U.S. allies and trade partners like Israel, Saudi Arabia, and Singapore face an initial cap of 507 million units of total processing power (TPP) — roughly the computational capacity of 32,000 Nvidia H100 chips — through the first quarter of 2025. The cap would increase to 1.02 billion TPP by 2027. U.S. companies that operate in these countries can apply for higher limits: 633 million TPP in Q1 2025, rising to 5.064 billion TPP by Q1 2027. Tier 3: China, Russia, and around two dozen other countries are blocked from receiving advanced AI chips, model weights, and specialized knowledge related to these systems. The U.S. Commerce Department’s export control agency must approve the export of models or transfer of weights of closed models that were trained using more than 10 26 computational operations. These rules target future systems, as no known models today used this amount of computation during training. Companies based in the U.S. must maintain at least 50 percent of their total AI computing power within U.S. borders. They also must track distribution of their models, implement security measures, and submit to regular audits. Behind the news: The proposed rules build on 2022’s CHIPS and Science Act , which was designed to strengthen domestic semiconductor production and restrict technologies abroad that could bear on U.S. security. An initial round of restrictions in late 2022 barred semiconductor suppliers AMD and Nvidia from selling advanced chips to Chinese firms. In November 2024, the U.S. tightened restrictions further, ordering Taiwan Semiconductor Manufacturing Company, which fabricates those chips, to halt production of advanced chips destined for China. Plus green AI infrastructure: In addition, President Biden issued an executive order to encourage the rapid build-out of computing infrastructure for AI. The federal government will hold competitions among private companies to lease sites it owns for the building of data centers at private expense. The selection of sites will take into account availability of sources of clean energy, including support for nuclear energy. The government will expedite permitting on these sites and support development of energy transmission lines around them. It will also encourage international allies to invest in AI infrastructure powered by clean energy. Why it matters: Protecting the United States’ advantages in high tech has been a rising priority for the White House over the past decade.\\xa0The earlier export restrictions forced many Chinese AI developers to rely on less-powerful hardware. The new limits are likely to have a far broader impact. They could force developers in the Tier 2 and Tier 3 countries to build less resource-intensive models and lead them to collaborate more closely with each other, reducing the value of U.S.-made technology worldwide. They could hurt U.S. chip vendors, which have warned that the rules could weaken U.S. competitiveness in the global economy. They could also force companies that are building huge data centers to process AI calculations to reconsider their plans. We’re thinking: The Biden administration’s embargo on AI chips has been leaky . So far, it has slowed down adversaries only slightly while spurring significant investment in potential suppliers that aren’t connected to the U.S. While the public comment period invites lobbying and industry feedback, ultimately geopolitical priorities may hold sway. Whatever the outcome, reducing the world’s dependence on U.S. chips and models would result in a very different global AI ecosystem. AI Supercomputer on Your Desk Nvidia’s new desktop computer is built specifically to run large AI models. What’s new: Project Digits is a personal supercomputer intended to help developers fine-tune and run large models locally. Project Digits, which is small enough to hold in one hand, will be available in May, starting at $3000. How it works: Project Digits is designed to run models of up to 200 billion parameters — roughly five times the size that fits comfortably on typical consumer hardware — provided they’re quantized to 4 bits of precision. Two units can be connected to run models such as Meta’s Llama 3.1 405B. Complete specifications are not yet available. Project Digits runs Nvidia’s DGX operating system, a flavor of Ubuntu Linux. The system is based on a GB10 system-on-a-chip that combines the Nvidia Blackwell GPU architecture (which serves as the basis for its latest B100 GPUs) and Grace CPU architecture (designed to manage AI workloads in data centers), connected via high-bandwidth NVLink interconnect. It comes with 128 GB of unified memory and 4 terabytes of solid-state storage. The system connects to Nvidia’s DGX Cloud service to enable developers to deploy models from a local machine to cloud infrastructure. Behind the news: In a blitz of announcements at the Consumer Electronics Show (CES), Nvidia also launched a platform for developing robotics, autonomous vehicles, and other physical AI systems. Cosmos includes pretrained language and vision models that range from 4 billion to 14 billion parameters for generating synthetic training data for robots or building policy models that translate a robot’s state into its next action. Nvidia also released Cosmos Nemotron, a 34 billion-parameter, vision-language model designed for use by AI agents, plus a video tokenizer and other tools for robotics developers. Why it matters: It’s common to train models on Nvidia A100 or H100 GPUs, which come with a price tag of at least $8,000 or $20,000 respectively, along with 40 gigabytes to 80 gigabytes of memory. These hefty requirements push many developers to buy access to computing infrastructure from a cloud provider. Coming in at $3,000 with 128 gigabytes of memory, Project Digits is designed to empower machine learning engineers to train and run larger models on their own machines. We’re thinking: We look forward to seeing cost/throughput comparisons between running a model on Project Digits, A100, and H100. Calibrating Contrast Contrastive loss functions make it possible to produce good embeddings without labeled data. A twist on this idea makes even more useful embeddings. What’s new: Vlad Sobal and colleagues at Meta, New York University, Brown University, Genentech, and Canadian Institute for Advanced Research introduced X-Sample contrastive loss (X-CLR), a self-supervised loss function that enables vision models to learn embeddings that capture similarities and differences among examples with greater subtlety. Key insight: Contrastive loss functions like SimCLR equally encourage a model to produce dissimilar embeddings of images of, say, a cat, a dog, and a dump truck. But, of course, cats and dogs are more similar to each other than either are to dump trucks. Instead of marking examples as similar or dissimilar, X-CLR assigns similarity scores, so a model can learn to produce embeddings that match those scores. How it works: The authors used X-CLR to train an embedding model on Conceptual Captions datasets of image-text pairs scraped from the web: CC-3M (3 million text-image pairs) and CC-12M (12 million text-image pairs). The model was similar to CLIP , except the text encoder was a sentence transformer pretrained on sentence pairs, and the vision encoder was a ResNet-50 pretrained on ImageNet. The sentence transformer embedded text captions for all examples. The system computed similarity scores according to cosine similarity between the text embeddings. Similarly, a ResNet-50 computed image embeddings, and the system computed similarity scores between them. The authors froze the sentence transformer and used the text similarity scores as labels in the loss function. The loss function minimized the difference between the similarity scores of the text embeddings and the corresponding similarity scores of the image embeddings. Results: Systems trained using X-CLR outperformed competitors in ImageNet classification, especially when less training data was available. (The authors followed CLIP’s method of classification: They computed the similarity between an image embedding and text embeddings of all classes. The image’s classification was the class that corresponds to the text embedding with the highest similarity to the image embedding.) The authors compared a system trained using X-CLR, one trained using SimCLR, and CLIP. After training on the CC-3M dataset, the X-CLR system achieved 58.2 percent accuracy on ImageNet, while the SimCLR model achieved 57.0 percent and CLIP achieved 41.0 percent. Training on CC-12M resulted in smaller differences: X-CLR achieved 59.4 percent accuracy, SimCLR achieved 58.9 percent, and CLIP achieved 58.8 percent. Why it matters: Contrastive loss functions are very useful, but the similar/dissimilar dichotomy leaves important nuances unaccounted for. Like CLIP, X-CLR takes advantage of both images and their captions for self-supervised learning. However, CLIP learns to recognize image-text pairs as similar or dissimilar, while X-CLR matches image-image pairs using captions as a similarity signal that’s continuous rather than discrete. We’re thinking: Reality is not black and white. Allowing for shades of gray makes for better modeling. Share Subscribe to The Batch Stay updated with weekly AI News and Insights delivered to your inbox\\nWeekly Issues Andrew's Letters Data Points ML Research Business Science Culture Hardware AI Careers About Subscribe\\nWeekly Issues Andrew's Letters Data Points ML Research Business Science Culture Hardware AI Careers\\nWeekly Issues\\nAndrew's Letters\\nData Points\\nML Research\\nBusiness\\nScience\\nCulture\\nHardware\\nAI Careers\\nAbout Subscribe\\nAbout\\n\\nThe Batch\\nWeekly Issues\\nissue 284\\nPublished Jan 15, 2025\\nPublished\\n\\nPublished\\nJan 15, 2025\\nReading time 13 min read\\nReading time\\n\\nReading time\\n13 min read\\nPublished Jan 15, 2025 Reading time 13 min read Share Dear friends, Writing software, especially prototypes, is becoming cheaper. This will lead to increased demand for people who can decide what to build. AI Product Management has a bright future! Software is often written by teams that comprise Product Managers (PMs), who decide what to build (such as what features to implement for what users) and Software Developers, who write the code to build the product. Economics shows that when two goods are complements — such as cars (with internal-combustion engines) and gasoline — falling prices in one leads to higher demand for the other. For example, as cars became cheaper, more people bought them, which led to increased demand for gas. Something similar will happen in software. Given a clear specification for what to build, AI is making the building itself much faster and cheaper. This will significantly increase demand for people who can come up with clear specs for valuable things to build. This is why I’m excited about the future of Product Management, the discipline of developing and managing software products. I’m especially excited about the future of AI Product Management, the discipline of developing and managing AI software products. Many companies have an Engineer:PM ratio of, say, 6:1. (The ratio varies widely by company and industry, and anywhere from 4:1 to 10:1 is typical.) As coding becomes more efficient, I think teams will need more product management work (as well as design work) as a fraction of the total workforce. Perhaps engineers will step in to do some of this work, but if it remains the purview of specialized Product Managers, then the demand for these roles will grow. This change in the composition of software development teams is not yet moving forward at full speed. One major force slowing this shift, particularly in AI Product Management, is that Software Engineers, being technical, are understanding and embracing AI much faster than Product Managers. Even today, most companies have difficulty finding people who know how to develop products and also understand AI, and I expect this shortage to grow. Further, AI Product Management requires a different set of skills than traditional software Product Management. It requires: Technical proficiency in AI. PMs need to understand what products might be technically feasible to build. They also need to understand the lifecycle of AI projects, such as data collection, building, then monitoring, and maintenance of AI models. Iterative development. Because AI development is much more iterative than traditional software and requires more course corrections along the way, PMs need to understand how to manage such a process. Data proficiency. AI products often learn from data, and they can be designed to generate richer forms of data than traditional software. Skill in managing ambiguity. Because AI’s performance is hard to predict in advance, PMs need to be comfortable with this and have tactics to manage it. Ongoing learning. AI technology is advancing rapidly. PMs, like everyone else who aims to make best use of the technology, need to keep up with the latest technology advances, product ideas, and how they fit into users’ lives. Finally, AI Product Managers will need to know how to ensure that AI is implemented responsibly (for example, when we need to implement guardrails to prevent bad outcomes), and also be skilled at gathering feedback fast to keep projects moving. Increasingly, I also expect strong product managers to be able to build prototypes for themselves. The demand for good AI Product Managers will be huge. In addition to growing AI Product Management as a discipline, perhaps some engineers will also end up doing more product management work. The variety of valuable things we can build is nearly unlimited. What a great time to build! Keep learning, Andrew A MESSAGE FROM\\xa0DEEPLEARNING.AI Get up-close and personal with OpenAI’s groundbreaking o1 model! In our short course “Reasoning with o1,” you’ll learn how to get the best performance in coding, planning, and STEM tasks; perform complex, multi-step tasks; and optimize prompts with meta prompting. Enroll today News DeepSeek Ups the Open Weights Ante A new model from Hangzhou upstart DeepSeek delivers outstanding performance and may change the equation for training costs. What’s new: DeepSeek-V3 is an open large language model that outperforms Llama 3.1 405B and GPT-4o on key benchmarks and achieves exceptional scores in coding and math. The weights are open except for applications that involve military uses, harming minors, generating false information, and similar restrictions. You can download them here . Mixture of experts (MoE) basics: The MoE architecture uses different subsets of its parameters to process different inputs. Each MoE layer contains a group of neural networks, or experts, preceded by a gating module that learns to choose which one(s) to use based on the input. In this way, different experts learn to specialize in different types of examples. Because not all parameters are used to produce any given output, the network uses less energy and runs faster than models of similar size that use all parameters to process every input. How it works: DeepSeek-V3 is a mixture-of-experts (MoE) transformer that comprises 671 billion parameters, of which 37 billion are active at any moment. The team trained the model in 2.79 million GPU hours — less than 1/10 the time required to train Llama 3.1 405B , which DeepSeek-V3 substantially outperforms — at an extraordinarily low cost of $5.6 million. The developers trained it on roughly 15 trillion tokens, including a larger percentage of coding and math data relative to DeepSeek-V2. They fine-tuned it on a wide variety of tasks using output generated by DeepSeek-R1 and DeepSeek-V2.5. They further sharpened its performance across diverse domains using the reinforcement learning algorithm known as group relative policy optimization . Earlier work showed that training to predict the next two tokens would improve performance over learning to predict just one. The authors implemented this procedure. The model learned to predict the first token as usual and used an additional set of layers to learn to predict the second token. The additional layers aren’t used at inference. Following DeepSeek-V2 , DeepSeek-V3 uses multi-head latent attention, which saves memory during execution relative to other variants of attention. Also like DeepSeek-V2, the new model combines dedicated (routed) and shared experts. The model chooses eight of 256 experts for a particular input, but it also uses a shared expert that processes all inputs. Results: In DeepSeek’s tests, DeepSeek-V3 outperformed Llama 3.1 405B and Qwen 2.5 72B across the board, and its performance compared favorably with that of GPT-4o. DeepSeek-V3 showed exceptional performance in coding and math tasks. In coding, DeepSeek-V3 dominated in five of the seven benchmarks tested. However, DeepSeek-V3 lost to o1 on one of the five, according to a public leaderboard. Specifically, on Polyglot , which tests a model’s ability to generate code in response to difficult requests in multiple programming languages, DeepSeek-V3 (48.5 percent accuracy) beat Claude Sonnet 3.5 (45.3 percent accuracy), though it lost to o1 (61.7 percent accuracy). In language tasks, it performed neck-and-neck with Claude 3.5 Sonnet, achieving higher scores in some tasks and lower in others. Behind the news: OpenAI’s o1 models excel thanks to agentic workflows in which they reflect on their own outputs, use tools, and so on. DeepSeek swims against the tide and achieves superior results without relying on agentic workflows. Why it matters: Open models continue to challenge closed models, giving developers high-quality options that they can modify and deploy at will. But the larger story is DeepSeek-V3’s shockingly low training cost. The team doesn’t explain precisely how the model achieves outstanding performance with such a low processing budget. (The paper credits “meticulous engineering optimizations.”) But it’s likely that DeepSeek’s steady refinement of MoE is a key factor. DeepSeek-V2, also an MoE model, saved more than 40 percent in training versus the earlier DeepSeek 67B, which didn’t employ MoE. In 2022, Microsoft found that MoE cost five times less in training for equal performance compared to a dense model, and Google and Meta reported that MoE achieved better performance than dense models trained on the same numbers of tokens. We’re thinking: If they can be replicated, DeepSeek’s results have significant implications for the economics of training foundation models. If indeed it now costs around $5 million to build a GPT-4o-level model, more teams will be able to train such models, and the cost of competing with the AI giants could fall dramatically. U.S. Moves to Expand AI Export Restrictions The United States proposed limits on exports of AI technology that would dramatically expand previous restrictions, creating a new international hierarchy for access to advanced chips and models. What’s new: The Biden administration, which will transition to leadership under incoming President Trump next week, issued new rules that restrict exports of AI chips and models to most countries beyond a select group of close allies. The rules, which are not yet final, would create a three-tier system that limits exports to a number of close allies and blocks access entirely to China, Iran, North Korea, Russia, and others. They also would introduce the U.S.’ first-ever restrictions on exporting closed weights for large AI models. How it works: The restrictions were announced shortly after a leak reached the press. A public comment period of 120 days will enable the incoming U.S. Presidential administration to consider input from the business and diplomatic communities and modify the rules before they take effect. The rules are scheduled to take effect in one year. A new hierarchy divides nations into three groups that would have different degrees of access to AI chips both designed in the U.S. and manufactured abroad using U.S. technology, as well as proprietary AI models. Tier 1: Australia, Japan, Taiwan, the United Kingdom, and most of Europe would retain nearly unrestricted access. However, these nations must keep 75 percent of their AI computing power within allied countries. No more than 10 percent can be transferred to any single country outside this group to ensure that advanced AI development remains concentrated among close U.S. allies. Tier 2: Traditional U.S. allies and trade partners like Israel, Saudi Arabia, and Singapore face an initial cap of 507 million units of total processing power (TPP) — roughly the computational capacity of 32,000 Nvidia H100 chips — through the first quarter of 2025. The cap would increase to 1.02 billion TPP by 2027. U.S. companies that operate in these countries can apply for higher limits: 633 million TPP in Q1 2025, rising to 5.064 billion TPP by Q1 2027. Tier 3: China, Russia, and around two dozen other countries are blocked from receiving advanced AI chips, model weights, and specialized knowledge related to these systems. The U.S. Commerce Department’s export control agency must approve the export of models or transfer of weights of closed models that were trained using more than 10 26 computational operations. These rules target future systems, as no known models today used this amount of computation during training. Companies based in the U.S. must maintain at least 50 percent of their total AI computing power within U.S. borders. They also must track distribution of their models, implement security measures, and submit to regular audits. Behind the news: The proposed rules build on 2022’s CHIPS and Science Act , which was designed to strengthen domestic semiconductor production and restrict technologies abroad that could bear on U.S. security. An initial round of restrictions in late 2022 barred semiconductor suppliers AMD and Nvidia from selling advanced chips to Chinese firms. In November 2024, the U.S. tightened restrictions further, ordering Taiwan Semiconductor Manufacturing Company, which fabricates those chips, to halt production of advanced chips destined for China. Plus green AI infrastructure: In addition, President Biden issued an executive order to encourage the rapid build-out of computing infrastructure for AI. The federal government will hold competitions among private companies to lease sites it owns for the building of data centers at private expense. The selection of sites will take into account availability of sources of clean energy, including support for nuclear energy. The government will expedite permitting on these sites and support development of energy transmission lines around them. It will also encourage international allies to invest in AI infrastructure powered by clean energy. Why it matters: Protecting the United States’ advantages in high tech has been a rising priority for the White House over the past decade.\\xa0The earlier export restrictions forced many Chinese AI developers to rely on less-powerful hardware. The new limits are likely to have a far broader impact. They could force developers in the Tier 2 and Tier 3 countries to build less resource-intensive models and lead them to collaborate more closely with each other, reducing the value of U.S.-made technology worldwide. They could hurt U.S. chip vendors, which have warned that the rules could weaken U.S. competitiveness in the global economy. They could also force companies that are building huge data centers to process AI calculations to reconsider their plans. We’re thinking: The Biden administration’s embargo on AI chips has been leaky . So far, it has slowed down adversaries only slightly while spurring significant investment in potential suppliers that aren’t connected to the U.S. While the public comment period invites lobbying and industry feedback, ultimately geopolitical priorities may hold sway. Whatever the outcome, reducing the world’s dependence on U.S. chips and models would result in a very different global AI ecosystem. AI Supercomputer on Your Desk Nvidia’s new desktop computer is built specifically to run large AI models. What’s new: Project Digits is a personal supercomputer intended to help developers fine-tune and run large models locally. Project Digits, which is small enough to hold in one hand, will be available in May, starting at $3000. How it works: Project Digits is designed to run models of up to 200 billion parameters — roughly five times the size that fits comfortably on typical consumer hardware — provided they’re quantized to 4 bits of precision. Two units can be connected to run models such as Meta’s Llama 3.1 405B. Complete specifications are not yet available. Project Digits runs Nvidia’s DGX operating system, a flavor of Ubuntu Linux. The system is based on a GB10 system-on-a-chip that combines the Nvidia Blackwell GPU architecture (which serves as the basis for its latest B100 GPUs) and Grace CPU architecture (designed to manage AI workloads in data centers), connected via high-bandwidth NVLink interconnect. It comes with 128 GB of unified memory and 4 terabytes of solid-state storage. The system connects to Nvidia’s DGX Cloud service to enable developers to deploy models from a local machine to cloud infrastructure. Behind the news: In a blitz of announcements at the Consumer Electronics Show (CES), Nvidia also launched a platform for developing robotics, autonomous vehicles, and other physical AI systems. Cosmos includes pretrained language and vision models that range from 4 billion to 14 billion parameters for generating synthetic training data for robots or building policy models that translate a robot’s state into its next action. Nvidia also released Cosmos Nemotron, a 34 billion-parameter, vision-language model designed for use by AI agents, plus a video tokenizer and other tools for robotics developers. Why it matters: It’s common to train models on Nvidia A100 or H100 GPUs, which come with a price tag of at least $8,000 or $20,000 respectively, along with 40 gigabytes to 80 gigabytes of memory. These hefty requirements push many developers to buy access to computing infrastructure from a cloud provider. Coming in at $3,000 with 128 gigabytes of memory, Project Digits is designed to empower machine learning engineers to train and run larger models on their own machines. We’re thinking: We look forward to seeing cost/throughput comparisons between running a model on Project Digits, A100, and H100. Calibrating Contrast Contrastive loss functions make it possible to produce good embeddings without labeled data. A twist on this idea makes even more useful embeddings. What’s new: Vlad Sobal and colleagues at Meta, New York University, Brown University, Genentech, and Canadian Institute for Advanced Research introduced X-Sample contrastive loss (X-CLR), a self-supervised loss function that enables vision models to learn embeddings that capture similarities and differences among examples with greater subtlety. Key insight: Contrastive loss functions like SimCLR equally encourage a model to produce dissimilar embeddings of images of, say, a cat, a dog, and a dump truck. But, of course, cats and dogs are more similar to each other than either are to dump trucks. Instead of marking examples as similar or dissimilar, X-CLR assigns similarity scores, so a model can learn to produce embeddings that match those scores. How it works: The authors used X-CLR to train an embedding model on Conceptual Captions datasets of image-text pairs scraped from the web: CC-3M (3 million text-image pairs) and CC-12M (12 million text-image pairs). The model was similar to CLIP , except the text encoder was a sentence transformer pretrained on sentence pairs, and the vision encoder was a ResNet-50 pretrained on ImageNet. The sentence transformer embedded text captions for all examples. The system computed similarity scores according to cosine similarity between the text embeddings. Similarly, a ResNet-50 computed image embeddings, and the system computed similarity scores between them. The authors froze the sentence transformer and used the text similarity scores as labels in the loss function. The loss function minimized the difference between the similarity scores of the text embeddings and the corresponding similarity scores of the image embeddings. Results: Systems trained using X-CLR outperformed competitors in ImageNet classification, especially when less training data was available. (The authors followed CLIP’s method of classification: They computed the similarity between an image embedding and text embeddings of all classes. The image’s classification was the class that corresponds to the text embedding with the highest similarity to the image embedding.) The authors compared a system trained using X-CLR, one trained using SimCLR, and CLIP. After training on the CC-3M dataset, the X-CLR system achieved 58.2 percent accuracy on ImageNet, while the SimCLR model achieved 57.0 percent and CLIP achieved 41.0 percent. Training on CC-12M resulted in smaller differences: X-CLR achieved 59.4 percent accuracy, SimCLR achieved 58.9 percent, and CLIP achieved 58.8 percent. Why it matters: Contrastive loss functions are very useful, but the similar/dissimilar dichotomy leaves important nuances unaccounted for. Like CLIP, X-CLR takes advantage of both images and their captions for self-supervised learning. However, CLIP learns to recognize image-text pairs as similar or dissimilar, while X-CLR matches image-image pairs using captions as a similarity signal that’s continuous rather than discrete. We’re thinking: Reality is not black and white. Allowing for shades of gray makes for better modeling. Share\\nPublished Jan 15, 2025\\nPublished\\n\\nPublished\\nJan 15, 2025\\nJan 15, 2025\\nReading time 13 min read\\nReading time\\n\\nReading time\\n13 min read\\nShare\\nShare\\n\\nShare\\n\\nDear friends, Writing software, especially prototypes, is becoming cheaper. This will lead to increased demand for people who can decide what to build. AI Product Management has a bright future! Software is often written by teams that comprise Product Managers (PMs), who decide what to build (such as what features to implement for what users) and Software Developers, who write the code to build the product. Economics shows that when two goods are complements — such as cars (with internal-combustion engines) and gasoline — falling prices in one leads to higher demand for the other. For example, as cars became cheaper, more people bought them, which led to increased demand for gas. Something similar will happen in software. Given a clear specification for what to build, AI is making the building itself much faster and cheaper. This will significantly increase demand for people who can come up with clear specs for valuable things to build. This is why I’m excited about the future of Product Management, the discipline of developing and managing software products. I’m especially excited about the future of AI Product Management, the discipline of developing and managing AI software products. Many companies have an Engineer:PM ratio of, say, 6:1. (The ratio varies widely by company and industry, and anywhere from 4:1 to 10:1 is typical.) As coding becomes more efficient, I think teams will need more product management work (as well as design work) as a fraction of the total workforce. Perhaps engineers will step in to do some of this work, but if it remains the purview of specialized Product Managers, then the demand for these roles will grow. This change in the composition of software development teams is not yet moving forward at full speed. One major force slowing this shift, particularly in AI Product Management, is that Software Engineers, being technical, are understanding and embracing AI much faster than Product Managers. Even today, most companies have difficulty finding people who know how to develop products and also understand AI, and I expect this shortage to grow. Further, AI Product Management requires a different set of skills than traditional software Product Management. It requires: Technical proficiency in AI. PMs need to understand what products might be technically feasible to build. They also need to understand the lifecycle of AI projects, such as data collection, building, then monitoring, and maintenance of AI models. Iterative development. Because AI development is much more iterative than traditional software and requires more course corrections along the way, PMs need to understand how to manage such a process. Data proficiency. AI products often learn from data, and they can be designed to generate richer forms of data than traditional software. Skill in managing ambiguity. Because AI’s performance is hard to predict in advance, PMs need to be comfortable with this and have tactics to manage it. Ongoing learning. AI technology is advancing rapidly. PMs, like everyone else who aims to make best use of the technology, need to keep up with the latest technology advances, product ideas, and how they fit into users’ lives. Finally, AI Product Managers will need to know how to ensure that AI is implemented responsibly (for example, when we need to implement guardrails to prevent bad outcomes), and also be skilled at gathering feedback fast to keep projects moving. Increasingly, I also expect strong product managers to be able to build prototypes for themselves. The demand for good AI Product Managers will be huge. In addition to growing AI Product Management as a discipline, perhaps some engineers will also end up doing more product management work. The variety of valuable things we can build is nearly unlimited. What a great time to build! Keep learning, Andrew A MESSAGE FROM\\xa0DEEPLEARNING.AI Get up-close and personal with OpenAI’s groundbreaking o1 model! In our short course “Reasoning with o1,” you’ll learn how to get the best performance in coding, planning, and STEM tasks; perform complex, multi-step tasks; and optimize prompts with meta prompting. Enroll today News DeepSeek Ups the Open Weights Ante A new model from Hangzhou upstart DeepSeek delivers outstanding performance and may change the equation for training costs. What’s new: DeepSeek-V3 is an open large language model that outperforms Llama 3.1 405B and GPT-4o on key benchmarks and achieves exceptional scores in coding and math. The weights are open except for applications that involve military uses, harming minors, generating false information, and similar restrictions. You can download them here . Mixture of experts (MoE) basics: The MoE architecture uses different subsets of its parameters to process different inputs. Each MoE layer contains a group of neural networks, or experts, preceded by a gating module that learns to choose which one(s) to use based on the input. In this way, different experts learn to specialize in different types of examples. Because not all parameters are used to produce any given output, the network uses less energy and runs faster than models of similar size that use all parameters to process every input. How it works: DeepSeek-V3 is a mixture-of-experts (MoE) transformer that comprises 671 billion parameters, of which 37 billion are active at any moment. The team trained the model in 2.79 million GPU hours — less than 1/10 the time required to train Llama 3.1 405B , which DeepSeek-V3 substantially outperforms — at an extraordinarily low cost of $5.6 million. The developers trained it on roughly 15 trillion tokens, including a larger percentage of coding and math data relative to DeepSeek-V2. They fine-tuned it on a wide variety of tasks using output generated by DeepSeek-R1 and DeepSeek-V2.5. They further sharpened its performance across diverse domains using the reinforcement learning algorithm known as group relative policy optimization . Earlier work showed that training to predict the next two tokens would improve performance over learning to predict just one. The authors implemented this procedure. The model learned to predict the first token as usual and used an additional set of layers to learn to predict the second token. The additional layers aren’t used at inference. Following DeepSeek-V2 , DeepSeek-V3 uses multi-head latent attention, which saves memory during execution relative to other variants of attention. Also like DeepSeek-V2, the new model combines dedicated (routed) and shared experts. The model chooses eight of 256 experts for a particular input, but it also uses a shared expert that processes all inputs. Results: In DeepSeek’s tests, DeepSeek-V3 outperformed Llama 3.1 405B and Qwen 2.5 72B across the board, and its performance compared favorably with that of GPT-4o. DeepSeek-V3 showed exceptional performance in coding and math tasks. In coding, DeepSeek-V3 dominated in five of the seven benchmarks tested. However, DeepSeek-V3 lost to o1 on one of the five, according to a public leaderboard. Specifically, on Polyglot , which tests a model’s ability to generate code in response to difficult requests in multiple programming languages, DeepSeek-V3 (48.5 percent accuracy) beat Claude Sonnet 3.5 (45.3 percent accuracy), though it lost to o1 (61.7 percent accuracy). In language tasks, it performed neck-and-neck with Claude 3.5 Sonnet, achieving higher scores in some tasks and lower in others. Behind the news: OpenAI’s o1 models excel thanks to agentic workflows in which they reflect on their own outputs, use tools, and so on. DeepSeek swims against the tide and achieves superior results without relying on agentic workflows. Why it matters: Open models continue to challenge closed models, giving developers high-quality options that they can modify and deploy at will. But the larger story is DeepSeek-V3’s shockingly low training cost. The team doesn’t explain precisely how the model achieves outstanding performance with such a low processing budget. (The paper credits “meticulous engineering optimizations.”) But it’s likely that DeepSeek’s steady refinement of MoE is a key factor. DeepSeek-V2, also an MoE model, saved more than 40 percent in training versus the earlier DeepSeek 67B, which didn’t employ MoE. In 2022, Microsoft found that MoE cost five times less in training for equal performance compared to a dense model, and Google and Meta reported that MoE achieved better performance than dense models trained on the same numbers of tokens. We’re thinking: If they can be replicated, DeepSeek’s results have significant implications for the economics of training foundation models. If indeed it now costs around $5 million to build a GPT-4o-level model, more teams will be able to train such models, and the cost of competing with the AI giants could fall dramatically. U.S. Moves to Expand AI Export Restrictions The United States proposed limits on exports of AI technology that would dramatically expand previous restrictions, creating a new international hierarchy for access to advanced chips and models. What’s new: The Biden administration, which will transition to leadership under incoming President Trump next week, issued new rules that restrict exports of AI chips and models to most countries beyond a select group of close allies. The rules, which are not yet final, would create a three-tier system that limits exports to a number of close allies and blocks access entirely to China, Iran, North Korea, Russia, and others. They also would introduce the U.S.’ first-ever restrictions on exporting closed weights for large AI models. How it works: The restrictions were announced shortly after a leak reached the press. A public comment period of 120 days will enable the incoming U.S. Presidential administration to consider input from the business and diplomatic communities and modify the rules before they take effect. The rules are scheduled to take effect in one year. A new hierarchy divides nations into three groups that would have different degrees of access to AI chips both designed in the U.S. and manufactured abroad using U.S. technology, as well as proprietary AI models. Tier 1: Australia, Japan, Taiwan, the United Kingdom, and most of Europe would retain nearly unrestricted access. However, these nations must keep 75 percent of their AI computing power within allied countries. No more than 10 percent can be transferred to any single country outside this group to ensure that advanced AI development remains concentrated among close U.S. allies. Tier 2: Traditional U.S. allies and trade partners like Israel, Saudi Arabia, and Singapore face an initial cap of 507 million units of total processing power (TPP) — roughly the computational capacity of 32,000 Nvidia H100 chips — through the first quarter of 2025. The cap would increase to 1.02 billion TPP by 2027. U.S. companies that operate in these countries can apply for higher limits: 633 million TPP in Q1 2025, rising to 5.064 billion TPP by Q1 2027. Tier 3: China, Russia, and around two dozen other countries are blocked from receiving advanced AI chips, model weights, and specialized knowledge related to these systems. The U.S. Commerce Department’s export control agency must approve the export of models or transfer of weights of closed models that were trained using more than 10 26 computational operations. These rules target future systems, as no known models today used this amount of computation during training. Companies based in the U.S. must maintain at least 50 percent of their total AI computing power within U.S. borders. They also must track distribution of their models, implement security measures, and submit to regular audits. Behind the news: The proposed rules build on 2022’s CHIPS and Science Act , which was designed to strengthen domestic semiconductor production and restrict technologies abroad that could bear on U.S. security. An initial round of restrictions in late 2022 barred semiconductor suppliers AMD and Nvidia from selling advanced chips to Chinese firms. In November 2024, the U.S. tightened restrictions further, ordering Taiwan Semiconductor Manufacturing Company, which fabricates those chips, to halt production of advanced chips destined for China. Plus green AI infrastructure: In addition, President Biden issued an executive order to encourage the rapid build-out of computing infrastructure for AI. The federal government will hold competitions among private companies to lease sites it owns for the building of data centers at private expense. The selection of sites will take into account availability of sources of clean energy, including support for nuclear energy. The government will expedite permitting on these sites and support development of energy transmission lines around them. It will also encourage international allies to invest in AI infrastructure powered by clean energy. Why it matters: Protecting the United States’ advantages in high tech has been a rising priority for the White House over the past decade.\\xa0The earlier export restrictions forced many Chinese AI developers to rely on less-powerful hardware. The new limits are likely to have a far broader impact. They could force developers in the Tier 2 and Tier 3 countries to build less resource-intensive models and lead them to collaborate more closely with each other, reducing the value of U.S.-made technology worldwide. They could hurt U.S. chip vendors, which have warned that the rules could weaken U.S. competitiveness in the global economy. They could also force companies that are building huge data centers to process AI calculations to reconsider their plans. We’re thinking: The Biden administration’s embargo on AI chips has been leaky . So far, it has slowed down adversaries only slightly while spurring significant investment in potential suppliers that aren’t connected to the U.S. While the public comment period invites lobbying and industry feedback, ultimately geopolitical priorities may hold sway. Whatever the outcome, reducing the world’s dependence on U.S. chips and models would result in a very different global AI ecosystem. AI Supercomputer on Your Desk Nvidia’s new desktop computer is built specifically to run large AI models. What’s new: Project Digits is a personal supercomputer intended to help developers fine-tune and run large models locally. Project Digits, which is small enough to hold in one hand, will be available in May, starting at $3000. How it works: Project Digits is designed to run models of up to 200 billion parameters — roughly five times the size that fits comfortably on typical consumer hardware — provided they’re quantized to 4 bits of precision. Two units can be connected to run models such as Meta’s Llama 3.1 405B. Complete specifications are not yet available. Project Digits runs Nvidia’s DGX operating system, a flavor of Ubuntu Linux. The system is based on a GB10 system-on-a-chip that combines the Nvidia Blackwell GPU architecture (which serves as the basis for its latest B100 GPUs) and Grace CPU architecture (designed to manage AI workloads in data centers), connected via high-bandwidth NVLink interconnect. It comes with 128 GB of unified memory and 4 terabytes of solid-state storage. The system connects to Nvidia’s DGX Cloud service to enable developers to deploy models from a local machine to cloud infrastructure. Behind the news: In a blitz of announcements at the Consumer Electronics Show (CES), Nvidia also launched a platform for developing robotics, autonomous vehicles, and other physical AI systems. Cosmos includes pretrained language and vision models that range from 4 billion to 14 billion parameters for generating synthetic training data for robots or building policy models that translate a robot’s state into its next action. Nvidia also released Cosmos Nemotron, a 34 billion-parameter, vision-language model designed for use by AI agents, plus a video tokenizer and other tools for robotics developers. Why it matters: It’s common to train models on Nvidia A100 or H100 GPUs, which come with a price tag of at least $8,000 or $20,000 respectively, along with 40 gigabytes to 80 gigabytes of memory. These hefty requirements push many developers to buy access to computing infrastructure from a cloud provider. Coming in at $3,000 with 128 gigabytes of memory, Project Digits is designed to empower machine learning engineers to train and run larger models on their own machines. We’re thinking: We look forward to seeing cost/throughput comparisons between running a model on Project Digits, A100, and H100. Calibrating Contrast Contrastive loss functions make it possible to produce good embeddings without labeled data. A twist on this idea makes even more useful embeddings. What’s new: Vlad Sobal and colleagues at Meta, New York University, Brown University, Genentech, and Canadian Institute for Advanced Research introduced X-Sample contrastive loss (X-CLR), a self-supervised loss function that enables vision models to learn embeddings that capture similarities and differences among examples with greater subtlety. Key insight: Contrastive loss functions like SimCLR equally encourage a model to produce dissimilar embeddings of images of, say, a cat, a dog, and a dump truck. But, of course, cats and dogs are more similar to each other than either are to dump trucks. Instead of marking examples as similar or dissimilar, X-CLR assigns similarity scores, so a model can learn to produce embeddings that match those scores. How it works: The authors used X-CLR to train an embedding model on Conceptual Captions datasets of image-text pairs scraped from the web: CC-3M (3 million text-image pairs) and CC-12M (12 million text-image pairs). The model was similar to CLIP , except the text encoder was a sentence transformer pretrained on sentence pairs, and the vision encoder was a ResNet-50 pretrained on ImageNet. The sentence transformer embedded text captions for all examples. The system computed similarity scores according to cosine similarity between the text embeddings. Similarly, a ResNet-50 computed image embeddings, and the system computed similarity scores between them. The authors froze the sentence transformer and used the text similarity scores as labels in the loss function. The loss function minimized the difference between the similarity scores of the text embeddings and the corresponding similarity scores of the image embeddings. Results: Systems trained using X-CLR outperformed competitors in ImageNet classification, especially when less training data was available. (The authors followed CLIP’s method of classification: They computed the similarity between an image embedding and text embeddings of all classes. The image’s classification was the class that corresponds to the text embedding with the highest similarity to the image embedding.) The authors compared a system trained using X-CLR, one trained using SimCLR, and CLIP. After training on the CC-3M dataset, the X-CLR system achieved 58.2 percent accuracy on ImageNet, while the SimCLR model achieved 57.0 percent and CLIP achieved 41.0 percent. Training on CC-12M resulted in smaller differences: X-CLR achieved 59.4 percent accuracy, SimCLR achieved 58.9 percent, and CLIP achieved 58.8 percent. Why it matters: Contrastive loss functions are very useful, but the similar/dissimilar dichotomy leaves important nuances unaccounted for. Like CLIP, X-CLR takes advantage of both images and their captions for self-supervised learning. However, CLIP learns to recognize image-text pairs as similar or dissimilar, while X-CLR matches image-image pairs using captions as a similarity signal that’s continuous rather than discrete. We’re thinking: Reality is not black and white. Allowing for shades of gray makes for better modeling.\\n\\n\\nShare\\nShare\\n\\nShare\\n\\nSubscribe to The Batch Stay updated with weekly AI News and Insights delivered to your inbox\\nSubscribe to The Batch Stay updated with weekly AI News and Insights delivered to your inbox\\nSubscribe to The Batch Stay updated with weekly AI News and Insights delivered to your inbox\\n\\n\\n\\n\\nCourses The Batch Community Careers About\\n\\nCourses\\nThe Batch\\nCommunity\\nCareers\\nAbout\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nExplore Courses\\nAI Newsletter The Batch Andrew's Letter Data Points ML Research Blog\\nThe Batch\\nAndrew's Letter\\nData Points\\nML Research\\nBlog\\nCommunity Forum Events Ambassadors Ambassador Spotlight\\nForum\\nEvents\\nAmbassadors\\nAmbassador Spotlight\\nResources\\nCompany About Careers Contact\\nAbout\\nCareers\\nContact\\nWeekly Issues\\nAndrew's Letters\\nData Points\\nML Research\\nBusiness\\nScience\\nCulture\\nHardware\\nAI Careers\\nAbout\\nThe Batch\\nWeekly Issues\\nissue 284\\n\\n\\n\\nTechnical proficiency in AI. PMs need to understand what products might be technically feasible to build. They also need to understand the lifecycle of AI projects, such as data collection, building, then monitoring, and maintenance of AI models.\\nIterative development. Because AI development is much more iterative than traditional software and requires more course corrections along the way, PMs need to understand how to manage such a process.\\nData proficiency. AI products often learn from data, and they can be designed to generate richer forms of data than traditional software.\\nSkill in managing ambiguity. Because AI’s performance is hard to predict in advance, PMs need to be comfortable with this and have tactics to manage it.\\nOngoing learning. AI technology is advancing rapidly. PMs, like everyone else who aims to make best use of the technology, need to keep up with the latest technology advances, product ideas, and how they fit into users’ lives.\\nThe developers trained it on roughly 15 trillion tokens, including a larger percentage of coding and math data relative to DeepSeek-V2. They fine-tuned it on a wide variety of tasks using output generated by DeepSeek-R1 and DeepSeek-V2.5. They further sharpened its performance across diverse domains using the reinforcement learning algorithm known as group relative policy optimization .\\nEarlier work showed that training to predict the next two tokens would improve performance over learning to predict just one. The authors implemented this procedure. The model learned to predict the first token as usual and used an additional set of layers to learn to predict the second token. The additional layers aren’t used at inference.\\nFollowing DeepSeek-V2 , DeepSeek-V3 uses multi-head latent attention, which saves memory during execution relative to other variants of attention.\\nAlso like DeepSeek-V2, the new model combines dedicated (routed) and shared experts. The model chooses eight of 256 experts for a particular input, but it also uses a shared expert that processes all inputs.\\nDeepSeek-V3 showed exceptional performance in coding and math tasks. In coding, DeepSeek-V3 dominated in five of the seven benchmarks tested. However, DeepSeek-V3 lost to o1 on one of the five, according to a public leaderboard. Specifically, on Polyglot , which tests a model’s ability to generate code in response to difficult requests in multiple programming languages, DeepSeek-V3 (48.5 percent accuracy) beat Claude Sonnet 3.5 (45.3 percent accuracy), though it lost to o1 (61.7 percent accuracy).\\nIn language tasks, it performed neck-and-neck with Claude 3.5 Sonnet, achieving higher scores in some tasks and lower in others.\\nA new hierarchy divides nations into three groups that would have different degrees of access to AI chips both designed in the U.S. and manufactured abroad using U.S. technology, as well as proprietary AI models.\\nTier 1: Australia, Japan, Taiwan, the United Kingdom, and most of Europe would retain nearly unrestricted access. However, these nations must keep 75 percent of their AI computing power within allied countries. No more than 10 percent can be transferred to any single country outside this group to ensure that advanced AI development remains concentrated among close U.S. allies.\\nTier 2: Traditional U.S. allies and trade partners like Israel, Saudi Arabia, and Singapore face an initial cap of 507 million units of total processing power (TPP) — roughly the computational capacity of 32,000 Nvidia H100 chips — through the first quarter of 2025. The cap would increase to 1.02 billion TPP by 2027. U.S. companies that operate in these countries can apply for higher limits: 633 million TPP in Q1 2025, rising to 5.064 billion TPP by Q1 2027.\\nTier 3: China, Russia, and around two dozen other countries are blocked from receiving advanced AI chips, model weights, and specialized knowledge related to these systems.\\nThe U.S. Commerce Department’s export control agency must approve the export of models or transfer of weights of closed models that were trained using more than 10 26 computational operations. These rules target future systems, as no known models today used this amount of computation during training.\\nCompanies based in the U.S. must maintain at least 50 percent of their total AI computing power within U.S. borders. They also must track distribution of their models, implement security measures, and submit to regular audits.\\nProject Digits runs Nvidia’s DGX operating system, a flavor of Ubuntu Linux.\\nThe system is based on a GB10 system-on-a-chip that combines the Nvidia Blackwell GPU architecture (which serves as the basis for its latest B100 GPUs) and Grace CPU architecture (designed to manage AI workloads in data centers), connected via high-bandwidth NVLink interconnect.\\nIt comes with 128 GB of unified memory and 4 terabytes of solid-state storage.\\nThe system connects to Nvidia’s DGX Cloud service to enable developers to deploy models from a local machine to cloud infrastructure.\\nThe sentence transformer embedded text captions for all examples. The system computed similarity scores according to cosine similarity between the text embeddings.\\nSimilarly, a ResNet-50 computed image embeddings, and the system computed similarity scores between them.\\nThe authors froze the sentence transformer and used the text similarity scores as labels in the loss function. The loss function minimized the difference between the similarity scores of the text embeddings and the corresponding similarity scores of the image embeddings.\\nThe authors compared a system trained using X-CLR, one trained using SimCLR, and CLIP. After training on the CC-3M dataset, the X-CLR system achieved 58.2 percent accuracy on ImageNet, while the SimCLR model achieved 57.0 percent and CLIP achieved 41.0 percent.\\nTraining on CC-12M resulted in smaller differences: X-CLR achieved 59.4 percent accuracy, SimCLR achieved 58.9 percent, and CLIP achieved 58.8 percent.\\n\\n\\n\\nCourses\\nThe Batch\\nCommunity\\nCareers\\nAbout\\n✨ New course! Enroll in Reinforcement Fine-Tuning LLMs with GRPO\\nDear friends,\\nWriting software, especially prototypes, is becoming cheaper. This will lead to increased demand for people who can decide what to build. AI Product Management has a bright future!\\nSoftware is often written by teams that comprise Product Managers (PMs), who decide what to build (such as what features to implement for what users) and Software Developers, who write the code to build the product. Economics shows that when two goods are complements — such as cars (with internal-combustion engines) and gasoline — falling prices in one leads to higher demand for the other. For example, as cars became cheaper, more people bought them, which led to increased demand for gas. Something similar will happen in software. Given a clear specification for what to build, AI is making the building itself much faster and cheaper. This will significantly increase demand for people who can come up with clear specs for valuable things to build.\\nThis is why I’m excited about the future of Product Management, the discipline of developing and managing software products. I’m especially excited about the future of AI Product Management, the discipline of developing and managing AI software products.\\nMany companies have an Engineer:PM ratio of, say, 6:1. (The ratio varies widely by company and industry, and anywhere from 4:1 to 10:1 is typical.) As coding becomes more efficient, I think teams will need more product management work (as well as design work) as a fraction of the total workforce. Perhaps engineers will step in to do some of this work, but if it remains the purview of specialized Product Managers, then the demand for these roles will grow.\\nThis change in the composition of software development teams is not yet moving forward at full speed. One major force slowing this shift, particularly in AI Product Management, is that Software Engineers, being technical, are understanding and embracing AI much faster than Product Managers. Even today, most companies have difficulty finding people who know how to develop products and also understand AI, and I expect this shortage to grow.\\nFurther, AI Product Management requires a different set of skills than traditional software Product Management. It requires:\\nFinally, AI Product Managers will need to know how to ensure that AI is implemented responsibly (for example, when we need to implement guardrails to prevent bad outcomes), and also be skilled at gathering feedback fast to keep projects moving. Increasingly, I also expect strong product managers to be able to build prototypes for themselves.\\nThe demand for good AI Product Managers will be huge. In addition to growing AI Product Management as a discipline, perhaps some engineers will also end up doing more product management work.\\nThe variety of valuable things we can build is nearly unlimited. What a great time to build!\\nKeep learning,\\nAndrew\\nGet up-close and personal with OpenAI’s groundbreaking o1 model! In our short course “Reasoning with o1,” you’ll learn how to get the best performance in coding, planning, and STEM tasks; perform complex, multi-step tasks; and optimize prompts with meta prompting. Enroll today\\nA new model from Hangzhou upstart DeepSeek delivers outstanding performance and may change the equation for training costs.\\nWhat’s new: DeepSeek-V3 is an open large language model that outperforms Llama 3.1 405B and GPT-4o on key benchmarks and achieves exceptional scores in coding and math. The weights are open except for applications that involve military uses, harming minors, generating false information, and similar restrictions. You can download them here .\\nMixture of experts (MoE) basics: The MoE architecture uses different subsets of its parameters to process different inputs. Each MoE layer contains a group of neural networks, or experts, preceded by a gating module that learns to choose which one(s) to use based on the input. In this way, different experts learn to specialize in different types of examples. Because not all parameters are used to produce any given output, the network uses less energy and runs faster than models of similar size that use all parameters to process every input.\\nHow it works: DeepSeek-V3 is a mixture-of-experts (MoE) transformer that comprises 671 billion parameters, of which 37 billion are active at any moment. The team trained the model in 2.79 million GPU hours — less than 1/10 the time required to train Llama 3.1 405B , which DeepSeek-V3 substantially outperforms — at an extraordinarily low cost of $5.6 million.\\nResults: In DeepSeek’s tests, DeepSeek-V3 outperformed Llama 3.1 405B and Qwen 2.5 72B across the board, and its performance compared favorably with that of GPT-4o.\\nBehind the news: OpenAI’s o1 models excel thanks to agentic workflows in which they reflect on their own outputs, use tools, and so on. DeepSeek swims against the tide and achieves superior results without relying on agentic workflows.\\nWhy it matters: Open models continue to challenge closed models, giving developers high-quality options that they can modify and deploy at will. But the larger story is DeepSeek-V3’s shockingly low training cost. The team doesn’t explain precisely how the model achieves outstanding performance with such a low processing budget. (The paper credits “meticulous engineering optimizations.”) But it’s likely that DeepSeek’s steady refinement of MoE is a key factor. DeepSeek-V2, also an MoE model, saved more than 40 percent in training versus the earlier DeepSeek 67B, which didn’t employ MoE. In 2022, Microsoft found that MoE cost five times less in training for equal performance compared to a dense model, and Google and Meta reported that MoE achieved better performance than dense models trained on the same numbers of tokens.\\nWe’re thinking: If they can be replicated, DeepSeek’s results have significant implications for the economics of training foundation models. If indeed it now costs around $5 million to build a GPT-4o-level model, more teams will be able to train such models, and the cost of competing with the AI giants could fall dramatically.\\nThe United States proposed limits on exports of AI technology that would dramatically expand previous restrictions, creating a new international hierarchy for access to advanced chips and models.\\nWhat’s new: The Biden administration, which will transition to leadership under incoming President Trump next week, issued new rules that restrict exports of AI chips and models to most countries beyond a select group of close allies. The rules, which are not yet final, would create a three-tier system that limits exports to a number of close allies and blocks access entirely to China, Iran, North Korea, Russia, and others. They also would introduce the U.S.’ first-ever restrictions on exporting closed weights for large AI models.\\nHow it works: The restrictions were announced shortly after a leak reached the press. A public comment period of 120 days will enable the incoming U.S. Presidential administration to consider input from the business and diplomatic communities and modify the rules before they take effect. The rules are scheduled to take effect in one year.\\nBehind the news: The proposed rules build on 2022’s CHIPS and Science Act , which was designed to strengthen domestic semiconductor production and restrict technologies abroad that could bear on U.S. security. An initial round of restrictions in late 2022 barred semiconductor suppliers AMD and Nvidia from selling advanced chips to Chinese firms. In November 2024, the U.S. tightened restrictions further, ordering Taiwan Semiconductor Manufacturing Company, which fabricates those chips, to halt production of advanced chips destined for China.\\nPlus green AI infrastructure: In addition, President Biden issued an executive order to encourage the rapid build-out of computing infrastructure for AI. The federal government will hold competitions among private companies to lease sites it owns for the building of data centers at private expense. The selection of sites will take into account availability of sources of clean energy, including support for nuclear energy. The government will expedite permitting on these sites and support development of energy transmission lines around them. It will also encourage international allies to invest in AI infrastructure powered by clean energy.\\nWhy it matters: Protecting the United States’ advantages in high tech has been a rising priority for the White House over the past decade.\\xa0The earlier export restrictions forced many Chinese AI developers to rely on less-powerful hardware. The new limits are likely to have a far broader impact. They could force developers in the Tier 2 and Tier 3 countries to build less resource-intensive models and lead them to collaborate more closely with each other, reducing the value of U.S.-made technology worldwide. They could hurt U.S. chip vendors, which have warned that the rules could weaken U.S. competitiveness in the global economy. They could also force companies that are building huge data centers to process AI calculations to reconsider their plans.\\nWe’re thinking: The Biden administration’s embargo on AI chips has been leaky . So far, it has slowed down adversaries only slightly while spurring significant investment in potential suppliers that aren’t connected to the U.S. While the public comment period invites lobbying and industry feedback, ultimately geopolitical priorities may hold sway. Whatever the outcome, reducing the world’s dependence on U.S. chips and models would result in a very different global AI ecosystem.\\nNvidia’s new desktop computer is built specifically to run large AI models.\\nWhat’s new: Project Digits is a personal supercomputer intended to help developers fine-tune and run large models locally. Project Digits, which is small enough to hold in one hand, will be available in May, starting at $3000.\\nHow it works: Project Digits is designed to run models of up to 200 billion parameters — roughly five times the size that fits comfortably on typical consumer hardware — provided they’re quantized to 4 bits of precision. Two units can be connected to run models such as Meta’s Llama 3.1 405B. Complete specifications are not yet available.\\nBehind the news: In a blitz of announcements at the Consumer Electronics Show (CES), Nvidia also launched a platform for developing robotics, autonomous vehicles, and other physical AI systems. Cosmos includes pretrained language and vision models that range from 4 billion to 14 billion parameters for generating synthetic training data for robots or building policy models that translate a robot’s state into its next action. Nvidia also released Cosmos Nemotron, a 34 billion-parameter, vision-language model designed for use by AI agents, plus a video tokenizer and other tools for robotics developers.\\nWhy it matters: It’s common to train models on Nvidia A100 or H100 GPUs, which come with a price tag of at least $8,000 or $20,000 respectively, along with 40 gigabytes to 80 gigabytes of memory. These hefty requirements push many developers to buy access to computing infrastructure from a cloud provider. Coming in at $3,000 with 128 gigabytes of memory, Project Digits is designed to empower machine learning engineers to train and run larger models on their own machines.\\nWe’re thinking: We look forward to seeing cost/throughput comparisons between running a model on Project Digits, A100, and H100.\\nContrastive loss functions make it possible to produce good embeddings without labeled data. A twist on this idea makes even more useful embeddings.\\nWhat’s new: Vlad Sobal and colleagues at Meta, New York University, Brown University, Genentech, and Canadian Institute for Advanced Research introduced X-Sample contrastive loss (X-CLR), a self-supervised loss function that enables vision models to learn embeddings that capture similarities and differences among examples with greater subtlety.\\nKey insight: Contrastive loss functions like SimCLR equally encourage a model to produce dissimilar embeddings of images of, say, a cat, a dog, and a dump truck. But, of course, cats and dogs are more similar to each other than either are to dump trucks. Instead of marking examples as similar or dissimilar, X-CLR assigns similarity scores, so a model can learn to produce embeddings that match those scores.\\nHow it works: The authors used X-CLR to train an embedding model on Conceptual Captions datasets of image-text pairs scraped from the web: CC-3M (3 million text-image pairs) and CC-12M (12 million text-image pairs). The model was similar to CLIP , except the text encoder was a sentence transformer pretrained on sentence pairs, and the vision encoder was a ResNet-50 pretrained on ImageNet.\\nResults: Systems trained using X-CLR outperformed competitors in ImageNet classification, especially when less training data was available. (The authors followed CLIP’s method of classification: They computed the similarity between an image embedding and text embeddings of all classes. The image’s classification was the class that corresponds to the text embedding with the highest similarity to the image embedding.)\\nWhy it matters: Contrastive loss functions are very useful, but the similar/dissimilar dichotomy leaves important nuances unaccounted for. Like CLIP, X-CLR takes advantage of both images and their captions for self-supervised learning. However, CLIP learns to recognize image-text pairs as similar or dissimilar, while X-CLR matches image-image pairs using captions as a similarity signal that’s continuous rather than discrete.\\nWe’re thinking: Reality is not black and white. Allowing for shades of gray makes for better modeling.\\nStay updated with weekly AI News and Insights delivered to your inbox\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df56290c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LoadedImage(url=https://dl-staging-website.ghost.io/content/images/2025/01/AIProductManager-2_1200px-1.jpg),\n",
       " LoadedImage(url=https://dl-staging-website.ghost.io/content/images/2025/01/The-Batch-ads-and-exclusive-banners---2024-12-16T174314.640--1-.png),\n",
       " LoadedImage(url=https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--45-.png),\n",
       " LoadedImage(url=https://dl-staging-website.ghost.io/content/images/2025/01/BIDENCHIPS-10_1200px.jpg),\n",
       " LoadedImage(url=https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--47-.jpg),\n",
       " LoadedImage(url=https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--44-.gif)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fff41aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TextDocument(id='b0c2a28ce65fadc891e9f1f7388f8766c580740bbedcd365f2ad3429e2dc03c4-3f135ed6-7ab3-470e-bb23-606cc8d9bb93', content='issue 284\\nNews\\nDeepSeek Ups the Open Weights Ante\\nU.S. Moves to Expand AI Export Restrictions\\nAI Supercomputer on Your Desk\\nCalibrating Contrast\\n\\n\\nExplore Courses\\nAI Newsletter\\n\\nCommunity\\n\\nResources\\nCompany', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='223c5a21f701afa70a873faff243339d9b591ef583a3e35e76ea897519c34a57-39883cc8-d053-458b-8b35-5da8e70f610b', content=\"✨ New course! Enroll in Reinforcement Fine-Tuning LLMs with GRPO Explore Courses AI Newsletter The Batch Andrew's Letter Data Points ML Research Blog Community Forum Events Ambassadors Ambassador Spotlight Resources Company About Careers Contact Start Learning Weekly Issues Andrew's Letters Data Points ML Research Business Science Culture Hardware AI Careers About Subscribe The Batch Weekly Issues issue 284 Published Jan 15, 2025 Reading time 13 min read Published Jan 15, 2025 Reading time 13 min read Share Dear friends, Writing software, especially prototypes, is becoming cheaper. This will lead to increased demand for people who can decide what to build. AI Product Management has a bright future! Software is often written by teams that comprise Product Managers (PMs), who decide what to build (such as what features to implement for what users) and Software Developers, who write the code to build the product. Economics shows that when two goods are complements — such as cars (with internal-combustion engines) and gasoline — falling prices in one leads to higher demand for the other. For example, as cars became cheaper, more people bought them, which led to increased demand for gas. Something similar will happen in software. Given a clear specification for what to build, AI is making the building itself much faster and cheaper. This will significantly increase demand for people who can come up with clear specs for valuable things to build. This is why I’m excited about the\", source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='89d3187d2649da59240f88862a2dc9fb82efe1d394b1209ece5d74ee4cf7fbcf-d1fdc4ef-ad84-4201-8959-60ac7ed7f130', content='future of Product Management, the discipline of developing and managing software products. I’m especially excited about the future of AI Product Management, the discipline of developing and managing AI software products. Many companies have an Engineer:PM ratio of, say, 6:1. (The ratio varies widely by company and industry, and anywhere from 4:1 to 10:1 is typical.) As coding becomes more efficient, I think teams will need more product management work (as well as design work) as a fraction of the total workforce. Perhaps engineers will step in to do some of this work, but if it remains the purview of specialized Product Managers, then the demand for these roles will grow. This change in the composition of software development teams is not yet moving forward at full speed. One major force slowing this shift, particularly in AI Product Management, is that Software Engineers, being technical, are understanding and embracing AI much faster than Product Managers. Even today, most companies have difficulty finding people who know how to develop products and also understand AI, and I expect this shortage to grow. Further, AI Product Management requires a different set of skills than traditional software Product Management. It requires: Technical proficiency in AI. PMs need to understand what products might be technically feasible to build. They also need to understand the lifecycle of AI projects, such as data collection, building, then monitoring, and maintenance of AI models.', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='6abd43ca6b7ab4d0f7d93576ca43d7277213e7f95aaa32f75d26789c7f7c6e62-473d556c-5bf8-49d3-be3c-92920de8a239', content='Iterative development. Because AI development is much more iterative than traditional software and requires more course corrections along the way, PMs need to understand how to manage such a process. Data proficiency. AI products often learn from data, and they can be designed to generate richer forms of data than traditional software. Skill in managing ambiguity. Because AI’s performance is hard to predict in advance, PMs need to be comfortable with this and have tactics to manage it. Ongoing learning. AI technology is advancing rapidly. PMs, like everyone else who aims to make best use of the technology, need to keep up with the latest technology advances, product ideas, and how they fit into users’ lives. Finally, AI Product Managers will need to know how to ensure that AI is implemented responsibly (for example, when we need to implement guardrails to prevent bad outcomes), and also be skilled at gathering feedback fast to keep projects moving. Increasingly, I also expect strong product managers to be able to build prototypes for themselves. The demand for good AI Product Managers will be huge. In addition to growing AI Product Management as a discipline, perhaps some engineers will also end up doing more product management work. The variety of valuable things we can build is nearly unlimited. What a great time to build! Keep learning, Andrew A MESSAGE FROM\\xa0DEEPLEARNING.AI Get up-close and personal with OpenAI’s groundbreaking o1 model! In our short course “Reasoning', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='ea89d39363d03f1613c41a20faac742f34b251780a58041ba1f01800f407dad3-92eccb95-0647-44d3-ba22-85625721d2e0', content='with o1,” you’ll learn how to get the best performance in coding, planning, and STEM tasks; perform complex, multi-step tasks; and optimize prompts with meta prompting. Enroll today News DeepSeek Ups the Open Weights Ante A new model from Hangzhou upstart DeepSeek delivers outstanding performance and may change the equation for training costs. What’s new: DeepSeek-V3 is an open large language model that outperforms Llama 3.1 405B and GPT-4o on key benchmarks and achieves exceptional scores in coding and math. The weights are open except for applications that involve military uses, harming minors, generating false information, and similar restrictions. You can download them here . Mixture of experts (MoE) basics: The MoE architecture uses different subsets of its parameters to process different inputs. Each MoE layer contains a group of neural networks, or experts, preceded by a gating module that learns to choose which one(s) to use based on the input. In this way, different experts learn to specialize in different types of examples. Because not all parameters are used to produce any given output, the network uses less energy and runs faster than models of similar size that use all parameters to process every input. How it works: DeepSeek-V3 is a mixture-of-experts (MoE) transformer that comprises 671 billion parameters, of which 37 billion are active at any moment. The team trained the model in 2.79 million GPU hours — less than 1/10 the time required to train Llama 3.1', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='dc31bcd8b341ba0249308bf3abc2a8ba0422ace30561185ace554be202143ac6-42b7f446-409b-4b72-8582-2ccd0e61db44', content='405B , which DeepSeek-V3 substantially outperforms — at an extraordinarily low cost of $5.6 million. The developers trained it on roughly 15 trillion tokens, including a larger percentage of coding and math data relative to DeepSeek-V2. They fine-tuned it on a wide variety of tasks using output generated by DeepSeek-R1 and DeepSeek-V2.5. They further sharpened its performance across diverse domains using the reinforcement learning algorithm known as group relative policy optimization . Earlier work showed that training to predict the next two tokens would improve performance over learning to predict just one. The authors implemented this procedure. The model learned to predict the first token as usual and used an additional set of layers to learn to predict the second token. The additional layers aren’t used at inference. Following DeepSeek-V2 , DeepSeek-V3 uses multi-head latent attention, which saves memory during execution relative to other variants of attention. Also like DeepSeek-V2, the new model combines dedicated (routed) and shared experts. The model chooses eight of 256 experts for a particular input, but it also uses a shared expert that processes all inputs. Results: In DeepSeek’s tests, DeepSeek-V3 outperformed Llama 3.1 405B and Qwen 2.5 72B across the board, and its performance compared favorably with that of GPT-4o. DeepSeek-V3 showed exceptional performance in coding and math tasks. In coding, DeepSeek-V3 dominated in five of the seven benchmarks tested.', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='ff1b3702cc6228b5e3fe5f6d5c4f741e1af685578434a5ea23788a0990dc14da-41088630-9dda-4a43-b7b5-73999e10fd9c', content='However, DeepSeek-V3 lost to o1 on one of the five, according to a public leaderboard. Specifically, on Polyglot , which tests a model’s ability to generate code in response to difficult requests in multiple programming languages, DeepSeek-V3 (48.5 percent accuracy) beat Claude Sonnet 3.5 (45.3 percent accuracy), though it lost to o1 (61.7 percent accuracy). In language tasks, it performed neck-and-neck with Claude 3.5 Sonnet, achieving higher scores in some tasks and lower in others. Behind the news: OpenAI’s o1 models excel thanks to agentic workflows in which they reflect on their own outputs, use tools, and so on. DeepSeek swims against the tide and achieves superior results without relying on agentic workflows. Why it matters: Open models continue to challenge closed models, giving developers high-quality options that they can modify and deploy at will. But the larger story is DeepSeek-V3’s shockingly low training cost. The team doesn’t explain precisely how the model achieves outstanding performance with such a low processing budget. (The paper credits “meticulous engineering optimizations.”) But it’s likely that DeepSeek’s steady refinement of MoE is a key factor. DeepSeek-V2, also an MoE model, saved more than 40 percent in training versus the earlier DeepSeek 67B, which didn’t employ MoE. In 2022, Microsoft found that MoE cost five times less in training for equal performance compared to a dense model, and Google and Meta reported that MoE achieved better', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='c302c3e955980bf7710bcf8a337e61753d51d50b7d10fa293a58048c1fb5c5a7-bfeec16c-15c0-48e1-b91c-bbfd183e135f', content='performance than dense models trained on the same numbers of tokens. We’re thinking: If they can be replicated, DeepSeek’s results have significant implications for the economics of training foundation models. If indeed it now costs around $5 million to build a GPT-4o-level model, more teams will be able to train such models, and the cost of competing with the AI giants could fall dramatically. U.S. Moves to Expand AI Export Restrictions The United States proposed limits on exports of AI technology that would dramatically expand previous restrictions, creating a new international hierarchy for access to advanced chips and models. What’s new: The Biden administration, which will transition to leadership under incoming President Trump next week, issued new rules that restrict exports of AI chips and models to most countries beyond a select group of close allies. The rules, which are not yet final, would create a three-tier system that limits exports to a number of close allies and blocks access entirely to China, Iran, North Korea, Russia, and others. They also would introduce the U.S.’ first-ever restrictions on exporting closed weights for large AI models. How it works: The restrictions were announced shortly after a leak reached the press. A public comment period of 120 days will enable the incoming U.S. Presidential administration to consider input from the business and diplomatic communities and modify the rules before they take effect. The rules are scheduled to take', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='ec3fb709f2fa0418507d3bc5a34829f705a9e2156d4446aa4b4e681a65d8001c-b9b3ae43-ebb0-4137-945f-04d528a27b6d', content='effect in one year. A new hierarchy divides nations into three groups that would have different degrees of access to AI chips both designed in the U.S. and manufactured abroad using U.S. technology, as well as proprietary AI models. Tier 1: Australia, Japan, Taiwan, the United Kingdom, and most of Europe would retain nearly unrestricted access. However, these nations must keep 75 percent of their AI computing power within allied countries. No more than 10 percent can be transferred to any single country outside this group to ensure that advanced AI development remains concentrated among close U.S. allies. Tier 2: Traditional U.S. allies and trade partners like Israel, Saudi Arabia, and Singapore face an initial cap of 507 million units of total processing power (TPP) — roughly the computational capacity of 32,000 Nvidia H100 chips — through the first quarter of 2025. The cap would increase to 1.02 billion TPP by 2027. U.S. companies that operate in these countries can apply for higher limits: 633 million TPP in Q1 2025, rising to 5.064 billion TPP by Q1 2027. Tier 3: China, Russia, and around two dozen other countries are blocked from receiving advanced AI chips, model weights, and specialized knowledge related to these systems. The U.S. Commerce Department’s export control agency must approve the export of models or transfer of weights of closed models that were trained using more than 10 26 computational operations. These rules target future systems, as no known models', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='dbcf3bcd7105119e2fa46931cad4f1c36edd93a75b24a14932d630907368b6c6-e3771ff1-e422-4be5-97a4-39bae0e0023e', content='today used this amount of computation during training. Companies based in the U.S. must maintain at least 50 percent of their total AI computing power within U.S. borders. They also must track distribution of their models, implement security measures, and submit to regular audits. Behind the news: The proposed rules build on 2022’s CHIPS and Science Act , which was designed to strengthen domestic semiconductor production and restrict technologies abroad that could bear on U.S. security. An initial round of restrictions in late 2022 barred semiconductor suppliers AMD and Nvidia from selling advanced chips to Chinese firms. In November 2024, the U.S. tightened restrictions further, ordering Taiwan Semiconductor Manufacturing Company, which fabricates those chips, to halt production of advanced chips destined for China. Plus green AI infrastructure: In addition, President Biden issued an executive order to encourage the rapid build-out of computing infrastructure for AI. The federal government will hold competitions among private companies to lease sites it owns for the building of data centers at private expense. The selection of sites will take into account availability of sources of clean energy, including support for nuclear energy. The government will expedite permitting on these sites and support development of energy transmission lines around them. It will also encourage international allies to invest in AI infrastructure powered by clean energy. Why it matters:', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='5e12af524e96318c62b35bbfc08b659c1326fe5e222a03907f082d594454e6ab-954b310e-4416-44fc-a4d2-2f4b0ebb54dc', content='Protecting the United States’ advantages in high tech has been a rising priority for the White House over the past decade.\\xa0The earlier export restrictions forced many Chinese AI developers to rely on less-powerful hardware. The new limits are likely to have a far broader impact. They could force developers in the Tier 2 and Tier 3 countries to build less resource-intensive models and lead them to collaborate more closely with each other, reducing the value of U.S.-made technology worldwide. They could hurt U.S. chip vendors, which have warned that the rules could weaken U.S. competitiveness in the global economy. They could also force companies that are building huge data centers to process AI calculations to reconsider their plans. We’re thinking: The Biden administration’s embargo on AI chips has been leaky . So far, it has slowed down adversaries only slightly while spurring significant investment in potential suppliers that aren’t connected to the U.S. While the public comment period invites lobbying and industry feedback, ultimately geopolitical priorities may hold sway. Whatever the outcome, reducing the world’s dependence on U.S. chips and models would result in a very different global AI ecosystem. AI Supercomputer on Your Desk Nvidia’s new desktop computer is built specifically to run large AI models. What’s new: Project Digits is a personal supercomputer intended to help developers fine-tune and run large models locally. Project Digits, which is small enough to', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='b1d4ab004351fa1de64fbd3d3e72c346a4dd3eb0c5623885c623764bd7ebc97b-853c802d-25fd-4188-986a-d53a241376a7', content='hold in one hand, will be available in May, starting at $3000. How it works: Project Digits is designed to run models of up to 200 billion parameters — roughly five times the size that fits comfortably on typical consumer hardware — provided they’re quantized to 4 bits of precision. Two units can be connected to run models such as Meta’s Llama 3.1 405B. Complete specifications are not yet available. Project Digits runs Nvidia’s DGX operating system, a flavor of Ubuntu Linux. The system is based on a GB10 system-on-a-chip that combines the Nvidia Blackwell GPU architecture (which serves as the basis for its latest B100 GPUs) and Grace CPU architecture (designed to manage AI workloads in data centers), connected via high-bandwidth NVLink interconnect. It comes with 128 GB of unified memory and 4 terabytes of solid-state storage. The system connects to Nvidia’s DGX Cloud service to enable developers to deploy models from a local machine to cloud infrastructure. Behind the news: In a blitz of announcements at the Consumer Electronics Show (CES), Nvidia also launched a platform for developing robotics, autonomous vehicles, and other physical AI systems. Cosmos includes pretrained language and vision models that range from 4 billion to 14 billion parameters for generating synthetic training data for robots or building policy models that translate a robot’s state into its next action. Nvidia also released Cosmos Nemotron, a 34 billion-parameter, vision-language model designed for', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='e0d2cce71a2121d6ccdf7549ab3fc7a268156420b4db0876e38614282da0e86c-b93625a3-6da7-4169-ab29-c448144b5911', content='use by AI agents, plus a video tokenizer and other tools for robotics developers. Why it matters: It’s common to train models on Nvidia A100 or H100 GPUs, which come with a price tag of at least $8,000 or $20,000 respectively, along with 40 gigabytes to 80 gigabytes of memory. These hefty requirements push many developers to buy access to computing infrastructure from a cloud provider. Coming in at $3,000 with 128 gigabytes of memory, Project Digits is designed to empower machine learning engineers to train and run larger models on their own machines. We’re thinking: We look forward to seeing cost/throughput comparisons between running a model on Project Digits, A100, and H100. Calibrating Contrast Contrastive loss functions make it possible to produce good embeddings without labeled data. A twist on this idea makes even more useful embeddings. What’s new: Vlad Sobal and colleagues at Meta, New York University, Brown University, Genentech, and Canadian Institute for Advanced Research introduced X-Sample contrastive loss (X-CLR), a self-supervised loss function that enables vision models to learn embeddings that capture similarities and differences among examples with greater subtlety. Key insight: Contrastive loss functions like SimCLR equally encourage a model to produce dissimilar embeddings of images of, say, a cat, a dog, and a dump truck. But, of course, cats and dogs are more similar to each other than either are to dump trucks. Instead of marking examples as similar', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='b78afa75e9e4267b17aeeb08d80c3d3b46406af1479e13e19e3f199937bb67d9-a872b8c0-906d-441d-b443-eaf26cceedf2', content='or dissimilar, X-CLR assigns similarity scores, so a model can learn to produce embeddings that match those scores. How it works: The authors used X-CLR to train an embedding model on Conceptual Captions datasets of image-text pairs scraped from the web: CC-3M (3 million text-image pairs) and CC-12M (12 million text-image pairs). The model was similar to CLIP , except the text encoder was a sentence transformer pretrained on sentence pairs, and the vision encoder was a ResNet-50 pretrained on ImageNet. The sentence transformer embedded text captions for all examples. The system computed similarity scores according to cosine similarity between the text embeddings. Similarly, a ResNet-50 computed image embeddings, and the system computed similarity scores between them. The authors froze the sentence transformer and used the text similarity scores as labels in the loss function. The loss function minimized the difference between the similarity scores of the text embeddings and the corresponding similarity scores of the image embeddings. Results: Systems trained using X-CLR outperformed competitors in ImageNet classification, especially when less training data was available. (The authors followed CLIP’s method of classification: They computed the similarity between an image embedding and text embeddings of all classes. The image’s classification was the class that corresponds to the text embedding with the highest similarity to the image embedding.) The authors compared a system', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='652c074018c0e40378b0db3356b98022b6cc0d4516edffa02a68452da6a26bd5-735fbe3f-315e-4320-8bf3-4131622c0baa', content='trained using X-CLR, one trained using SimCLR, and CLIP. After training on the CC-3M dataset, the X-CLR system achieved 58.2 percent accuracy on ImageNet, while the SimCLR model achieved 57.0 percent and CLIP achieved 41.0 percent. Training on CC-12M resulted in smaller differences: X-CLR achieved 59.4 percent accuracy, SimCLR achieved 58.9 percent, and CLIP achieved 58.8 percent. Why it matters: Contrastive loss functions are very useful, but the similar/dissimilar dichotomy leaves important nuances unaccounted for. Like CLIP, X-CLR takes advantage of both images and their captions for self-supervised learning. However, CLIP learns to recognize image-text pairs as similar or dissimilar, while X-CLR matches image-image pairs using captions as a similarity signal that’s continuous rather than discrete. We’re thinking: Reality is not black and white. Allowing for shades of gray makes for better modeling. Share Subscribe to The Batch Stay updated with weekly AI News and Insights delivered to your inbox Courses The Batch Community Careers About', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='223c5a21f701afa70a873faff243339d9b591ef583a3e35e76ea897519c34a57-4cc322a5-7c67-439e-b2d7-9f2dcd90bac6', content=\"✨ New course! Enroll in Reinforcement Fine-Tuning LLMs with GRPO Explore Courses AI Newsletter The Batch Andrew's Letter Data Points ML Research Blog Community Forum Events Ambassadors Ambassador Spotlight Resources Company About Careers Contact Start Learning Weekly Issues Andrew's Letters Data Points ML Research Business Science Culture Hardware AI Careers About Subscribe The Batch Weekly Issues issue 284 Published Jan 15, 2025 Reading time 13 min read Published Jan 15, 2025 Reading time 13 min read Share Dear friends, Writing software, especially prototypes, is becoming cheaper. This will lead to increased demand for people who can decide what to build. AI Product Management has a bright future! Software is often written by teams that comprise Product Managers (PMs), who decide what to build (such as what features to implement for what users) and Software Developers, who write the code to build the product. Economics shows that when two goods are complements — such as cars (with internal-combustion engines) and gasoline — falling prices in one leads to higher demand for the other. For example, as cars became cheaper, more people bought them, which led to increased demand for gas. Something similar will happen in software. Given a clear specification for what to build, AI is making the building itself much faster and cheaper. This will significantly increase demand for people who can come up with clear specs for valuable things to build. This is why I’m excited about the\", source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='89d3187d2649da59240f88862a2dc9fb82efe1d394b1209ece5d74ee4cf7fbcf-e89e728a-8847-49bb-9399-3e3340ea9a64', content='future of Product Management, the discipline of developing and managing software products. I’m especially excited about the future of AI Product Management, the discipline of developing and managing AI software products. Many companies have an Engineer:PM ratio of, say, 6:1. (The ratio varies widely by company and industry, and anywhere from 4:1 to 10:1 is typical.) As coding becomes more efficient, I think teams will need more product management work (as well as design work) as a fraction of the total workforce. Perhaps engineers will step in to do some of this work, but if it remains the purview of specialized Product Managers, then the demand for these roles will grow. This change in the composition of software development teams is not yet moving forward at full speed. One major force slowing this shift, particularly in AI Product Management, is that Software Engineers, being technical, are understanding and embracing AI much faster than Product Managers. Even today, most companies have difficulty finding people who know how to develop products and also understand AI, and I expect this shortage to grow. Further, AI Product Management requires a different set of skills than traditional software Product Management. It requires: Technical proficiency in AI. PMs need to understand what products might be technically feasible to build. They also need to understand the lifecycle of AI projects, such as data collection, building, then monitoring, and maintenance of AI models.', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='6abd43ca6b7ab4d0f7d93576ca43d7277213e7f95aaa32f75d26789c7f7c6e62-3159d86e-60de-4b38-9ddc-5b45c5169b33', content='Iterative development. Because AI development is much more iterative than traditional software and requires more course corrections along the way, PMs need to understand how to manage such a process. Data proficiency. AI products often learn from data, and they can be designed to generate richer forms of data than traditional software. Skill in managing ambiguity. Because AI’s performance is hard to predict in advance, PMs need to be comfortable with this and have tactics to manage it. Ongoing learning. AI technology is advancing rapidly. PMs, like everyone else who aims to make best use of the technology, need to keep up with the latest technology advances, product ideas, and how they fit into users’ lives. Finally, AI Product Managers will need to know how to ensure that AI is implemented responsibly (for example, when we need to implement guardrails to prevent bad outcomes), and also be skilled at gathering feedback fast to keep projects moving. Increasingly, I also expect strong product managers to be able to build prototypes for themselves. The demand for good AI Product Managers will be huge. In addition to growing AI Product Management as a discipline, perhaps some engineers will also end up doing more product management work. The variety of valuable things we can build is nearly unlimited. What a great time to build! Keep learning, Andrew A MESSAGE FROM\\xa0DEEPLEARNING.AI Get up-close and personal with OpenAI’s groundbreaking o1 model! In our short course “Reasoning', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='ea89d39363d03f1613c41a20faac742f34b251780a58041ba1f01800f407dad3-0b427722-2cbb-465a-aeed-2a336958b634', content='with o1,” you’ll learn how to get the best performance in coding, planning, and STEM tasks; perform complex, multi-step tasks; and optimize prompts with meta prompting. Enroll today News DeepSeek Ups the Open Weights Ante A new model from Hangzhou upstart DeepSeek delivers outstanding performance and may change the equation for training costs. What’s new: DeepSeek-V3 is an open large language model that outperforms Llama 3.1 405B and GPT-4o on key benchmarks and achieves exceptional scores in coding and math. The weights are open except for applications that involve military uses, harming minors, generating false information, and similar restrictions. You can download them here . Mixture of experts (MoE) basics: The MoE architecture uses different subsets of its parameters to process different inputs. Each MoE layer contains a group of neural networks, or experts, preceded by a gating module that learns to choose which one(s) to use based on the input. In this way, different experts learn to specialize in different types of examples. Because not all parameters are used to produce any given output, the network uses less energy and runs faster than models of similar size that use all parameters to process every input. How it works: DeepSeek-V3 is a mixture-of-experts (MoE) transformer that comprises 671 billion parameters, of which 37 billion are active at any moment. The team trained the model in 2.79 million GPU hours — less than 1/10 the time required to train Llama 3.1', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='dc31bcd8b341ba0249308bf3abc2a8ba0422ace30561185ace554be202143ac6-179baf42-799c-4943-b9f6-69659c618cdf', content='405B , which DeepSeek-V3 substantially outperforms — at an extraordinarily low cost of $5.6 million. The developers trained it on roughly 15 trillion tokens, including a larger percentage of coding and math data relative to DeepSeek-V2. They fine-tuned it on a wide variety of tasks using output generated by DeepSeek-R1 and DeepSeek-V2.5. They further sharpened its performance across diverse domains using the reinforcement learning algorithm known as group relative policy optimization . Earlier work showed that training to predict the next two tokens would improve performance over learning to predict just one. The authors implemented this procedure. The model learned to predict the first token as usual and used an additional set of layers to learn to predict the second token. The additional layers aren’t used at inference. Following DeepSeek-V2 , DeepSeek-V3 uses multi-head latent attention, which saves memory during execution relative to other variants of attention. Also like DeepSeek-V2, the new model combines dedicated (routed) and shared experts. The model chooses eight of 256 experts for a particular input, but it also uses a shared expert that processes all inputs. Results: In DeepSeek’s tests, DeepSeek-V3 outperformed Llama 3.1 405B and Qwen 2.5 72B across the board, and its performance compared favorably with that of GPT-4o. DeepSeek-V3 showed exceptional performance in coding and math tasks. In coding, DeepSeek-V3 dominated in five of the seven benchmarks tested.', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='ff1b3702cc6228b5e3fe5f6d5c4f741e1af685578434a5ea23788a0990dc14da-78654b95-bd2e-4b31-a8f6-b5b6eb1c9101', content='However, DeepSeek-V3 lost to o1 on one of the five, according to a public leaderboard. Specifically, on Polyglot , which tests a model’s ability to generate code in response to difficult requests in multiple programming languages, DeepSeek-V3 (48.5 percent accuracy) beat Claude Sonnet 3.5 (45.3 percent accuracy), though it lost to o1 (61.7 percent accuracy). In language tasks, it performed neck-and-neck with Claude 3.5 Sonnet, achieving higher scores in some tasks and lower in others. Behind the news: OpenAI’s o1 models excel thanks to agentic workflows in which they reflect on their own outputs, use tools, and so on. DeepSeek swims against the tide and achieves superior results without relying on agentic workflows. Why it matters: Open models continue to challenge closed models, giving developers high-quality options that they can modify and deploy at will. But the larger story is DeepSeek-V3’s shockingly low training cost. The team doesn’t explain precisely how the model achieves outstanding performance with such a low processing budget. (The paper credits “meticulous engineering optimizations.”) But it’s likely that DeepSeek’s steady refinement of MoE is a key factor. DeepSeek-V2, also an MoE model, saved more than 40 percent in training versus the earlier DeepSeek 67B, which didn’t employ MoE. In 2022, Microsoft found that MoE cost five times less in training for equal performance compared to a dense model, and Google and Meta reported that MoE achieved better', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='c302c3e955980bf7710bcf8a337e61753d51d50b7d10fa293a58048c1fb5c5a7-b8c66982-7da7-4be6-b3d8-922ecb8e5103', content='performance than dense models trained on the same numbers of tokens. We’re thinking: If they can be replicated, DeepSeek’s results have significant implications for the economics of training foundation models. If indeed it now costs around $5 million to build a GPT-4o-level model, more teams will be able to train such models, and the cost of competing with the AI giants could fall dramatically. U.S. Moves to Expand AI Export Restrictions The United States proposed limits on exports of AI technology that would dramatically expand previous restrictions, creating a new international hierarchy for access to advanced chips and models. What’s new: The Biden administration, which will transition to leadership under incoming President Trump next week, issued new rules that restrict exports of AI chips and models to most countries beyond a select group of close allies. The rules, which are not yet final, would create a three-tier system that limits exports to a number of close allies and blocks access entirely to China, Iran, North Korea, Russia, and others. They also would introduce the U.S.’ first-ever restrictions on exporting closed weights for large AI models. How it works: The restrictions were announced shortly after a leak reached the press. A public comment period of 120 days will enable the incoming U.S. Presidential administration to consider input from the business and diplomatic communities and modify the rules before they take effect. The rules are scheduled to take', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='ec3fb709f2fa0418507d3bc5a34829f705a9e2156d4446aa4b4e681a65d8001c-94b2936b-ccf5-43d8-ac1c-7726201a9e6e', content='effect in one year. A new hierarchy divides nations into three groups that would have different degrees of access to AI chips both designed in the U.S. and manufactured abroad using U.S. technology, as well as proprietary AI models. Tier 1: Australia, Japan, Taiwan, the United Kingdom, and most of Europe would retain nearly unrestricted access. However, these nations must keep 75 percent of their AI computing power within allied countries. No more than 10 percent can be transferred to any single country outside this group to ensure that advanced AI development remains concentrated among close U.S. allies. Tier 2: Traditional U.S. allies and trade partners like Israel, Saudi Arabia, and Singapore face an initial cap of 507 million units of total processing power (TPP) — roughly the computational capacity of 32,000 Nvidia H100 chips — through the first quarter of 2025. The cap would increase to 1.02 billion TPP by 2027. U.S. companies that operate in these countries can apply for higher limits: 633 million TPP in Q1 2025, rising to 5.064 billion TPP by Q1 2027. Tier 3: China, Russia, and around two dozen other countries are blocked from receiving advanced AI chips, model weights, and specialized knowledge related to these systems. The U.S. Commerce Department’s export control agency must approve the export of models or transfer of weights of closed models that were trained using more than 10 26 computational operations. These rules target future systems, as no known models', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='dbcf3bcd7105119e2fa46931cad4f1c36edd93a75b24a14932d630907368b6c6-fbb539d3-68e5-45aa-ac1f-3b2358e880d0', content='today used this amount of computation during training. Companies based in the U.S. must maintain at least 50 percent of their total AI computing power within U.S. borders. They also must track distribution of their models, implement security measures, and submit to regular audits. Behind the news: The proposed rules build on 2022’s CHIPS and Science Act , which was designed to strengthen domestic semiconductor production and restrict technologies abroad that could bear on U.S. security. An initial round of restrictions in late 2022 barred semiconductor suppliers AMD and Nvidia from selling advanced chips to Chinese firms. In November 2024, the U.S. tightened restrictions further, ordering Taiwan Semiconductor Manufacturing Company, which fabricates those chips, to halt production of advanced chips destined for China. Plus green AI infrastructure: In addition, President Biden issued an executive order to encourage the rapid build-out of computing infrastructure for AI. The federal government will hold competitions among private companies to lease sites it owns for the building of data centers at private expense. The selection of sites will take into account availability of sources of clean energy, including support for nuclear energy. The government will expedite permitting on these sites and support development of energy transmission lines around them. It will also encourage international allies to invest in AI infrastructure powered by clean energy. Why it matters:', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='5e12af524e96318c62b35bbfc08b659c1326fe5e222a03907f082d594454e6ab-703aefcc-7915-4aab-acbe-c7d2d199add4', content='Protecting the United States’ advantages in high tech has been a rising priority for the White House over the past decade.\\xa0The earlier export restrictions forced many Chinese AI developers to rely on less-powerful hardware. The new limits are likely to have a far broader impact. They could force developers in the Tier 2 and Tier 3 countries to build less resource-intensive models and lead them to collaborate more closely with each other, reducing the value of U.S.-made technology worldwide. They could hurt U.S. chip vendors, which have warned that the rules could weaken U.S. competitiveness in the global economy. They could also force companies that are building huge data centers to process AI calculations to reconsider their plans. We’re thinking: The Biden administration’s embargo on AI chips has been leaky . So far, it has slowed down adversaries only slightly while spurring significant investment in potential suppliers that aren’t connected to the U.S. While the public comment period invites lobbying and industry feedback, ultimately geopolitical priorities may hold sway. Whatever the outcome, reducing the world’s dependence on U.S. chips and models would result in a very different global AI ecosystem. AI Supercomputer on Your Desk Nvidia’s new desktop computer is built specifically to run large AI models. What’s new: Project Digits is a personal supercomputer intended to help developers fine-tune and run large models locally. Project Digits, which is small enough to', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='b1d4ab004351fa1de64fbd3d3e72c346a4dd3eb0c5623885c623764bd7ebc97b-4695d295-3cf5-46a4-9511-6478a7d51cb8', content='hold in one hand, will be available in May, starting at $3000. How it works: Project Digits is designed to run models of up to 200 billion parameters — roughly five times the size that fits comfortably on typical consumer hardware — provided they’re quantized to 4 bits of precision. Two units can be connected to run models such as Meta’s Llama 3.1 405B. Complete specifications are not yet available. Project Digits runs Nvidia’s DGX operating system, a flavor of Ubuntu Linux. The system is based on a GB10 system-on-a-chip that combines the Nvidia Blackwell GPU architecture (which serves as the basis for its latest B100 GPUs) and Grace CPU architecture (designed to manage AI workloads in data centers), connected via high-bandwidth NVLink interconnect. It comes with 128 GB of unified memory and 4 terabytes of solid-state storage. The system connects to Nvidia’s DGX Cloud service to enable developers to deploy models from a local machine to cloud infrastructure. Behind the news: In a blitz of announcements at the Consumer Electronics Show (CES), Nvidia also launched a platform for developing robotics, autonomous vehicles, and other physical AI systems. Cosmos includes pretrained language and vision models that range from 4 billion to 14 billion parameters for generating synthetic training data for robots or building policy models that translate a robot’s state into its next action. Nvidia also released Cosmos Nemotron, a 34 billion-parameter, vision-language model designed for', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='e0d2cce71a2121d6ccdf7549ab3fc7a268156420b4db0876e38614282da0e86c-68d85e45-c0d4-4525-9539-122df356e3d7', content='use by AI agents, plus a video tokenizer and other tools for robotics developers. Why it matters: It’s common to train models on Nvidia A100 or H100 GPUs, which come with a price tag of at least $8,000 or $20,000 respectively, along with 40 gigabytes to 80 gigabytes of memory. These hefty requirements push many developers to buy access to computing infrastructure from a cloud provider. Coming in at $3,000 with 128 gigabytes of memory, Project Digits is designed to empower machine learning engineers to train and run larger models on their own machines. We’re thinking: We look forward to seeing cost/throughput comparisons between running a model on Project Digits, A100, and H100. Calibrating Contrast Contrastive loss functions make it possible to produce good embeddings without labeled data. A twist on this idea makes even more useful embeddings. What’s new: Vlad Sobal and colleagues at Meta, New York University, Brown University, Genentech, and Canadian Institute for Advanced Research introduced X-Sample contrastive loss (X-CLR), a self-supervised loss function that enables vision models to learn embeddings that capture similarities and differences among examples with greater subtlety. Key insight: Contrastive loss functions like SimCLR equally encourage a model to produce dissimilar embeddings of images of, say, a cat, a dog, and a dump truck. But, of course, cats and dogs are more similar to each other than either are to dump trucks. Instead of marking examples as similar', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='b78afa75e9e4267b17aeeb08d80c3d3b46406af1479e13e19e3f199937bb67d9-a41ed7fe-eab1-4f78-8450-517a7235e0b1', content='or dissimilar, X-CLR assigns similarity scores, so a model can learn to produce embeddings that match those scores. How it works: The authors used X-CLR to train an embedding model on Conceptual Captions datasets of image-text pairs scraped from the web: CC-3M (3 million text-image pairs) and CC-12M (12 million text-image pairs). The model was similar to CLIP , except the text encoder was a sentence transformer pretrained on sentence pairs, and the vision encoder was a ResNet-50 pretrained on ImageNet. The sentence transformer embedded text captions for all examples. The system computed similarity scores according to cosine similarity between the text embeddings. Similarly, a ResNet-50 computed image embeddings, and the system computed similarity scores between them. The authors froze the sentence transformer and used the text similarity scores as labels in the loss function. The loss function minimized the difference between the similarity scores of the text embeddings and the corresponding similarity scores of the image embeddings. Results: Systems trained using X-CLR outperformed competitors in ImageNet classification, especially when less training data was available. (The authors followed CLIP’s method of classification: They computed the similarity between an image embedding and text embeddings of all classes. The image’s classification was the class that corresponds to the text embedding with the highest similarity to the image embedding.) The authors compared a system', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='652c074018c0e40378b0db3356b98022b6cc0d4516edffa02a68452da6a26bd5-17792849-73a5-43ff-b430-e83aea88d01d', content='trained using X-CLR, one trained using SimCLR, and CLIP. After training on the CC-3M dataset, the X-CLR system achieved 58.2 percent accuracy on ImageNet, while the SimCLR model achieved 57.0 percent and CLIP achieved 41.0 percent. Training on CC-12M resulted in smaller differences: X-CLR achieved 59.4 percent accuracy, SimCLR achieved 58.9 percent, and CLIP achieved 58.8 percent. Why it matters: Contrastive loss functions are very useful, but the similar/dissimilar dichotomy leaves important nuances unaccounted for. Like CLIP, X-CLR takes advantage of both images and their captions for self-supervised learning. However, CLIP learns to recognize image-text pairs as similar or dissimilar, while X-CLR matches image-image pairs using captions as a similarity signal that’s continuous rather than discrete. We’re thinking: Reality is not black and white. Allowing for shades of gray makes for better modeling. Share Subscribe to The Batch Stay updated with weekly AI News and Insights delivered to your inbox Courses The Batch Community Careers About', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='093fd64bf8f9c852758b5552ca8a1efa40878312602d150e87af64d09b7b3402-abdc73e0-0724-45b0-bb4a-894b7f171213', content='✨ New course! Enroll in Reinforcement Fine-Tuning LLMs with GRPO\\n✨ New course! Enroll in Reinforcement Fine-Tuning LLMs with GRPO', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='a823f6e850d1ea8d315b67f43467f0437cb880cfe0d1db2609eafb18d820a025-234da2f4-dfeb-4314-b6d4-b7e8cfeefbaa', content=\"Explore Courses AI Newsletter The Batch Andrew's Letter Data Points ML Research Blog Community Forum Events Ambassadors Ambassador Spotlight Resources Company About Careers Contact Start Learning\\n\\n\\nExplore Courses AI Newsletter The Batch Andrew's Letter Data Points ML Research Blog Community Forum Events Ambassadors Ambassador Spotlight Resources Company About Careers Contact Start Learning\\nExplore Courses AI Newsletter The Batch Andrew's Letter Data Points ML Research Blog Community Forum Events Ambassadors Ambassador Spotlight Resources Company About Careers Contact Start Learning\\nExplore Courses\\nAI Newsletter\\nThe Batch\\nAndrew's Letter\\nData Points\\nML Research\\nBlog\\nCommunity\\nForum\\nEvents\\nAmbassadors\\nAmbassador Spotlight\\nResources\\nCompany\\nAbout\\nCareers\\nContact\", source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='d6ce9d55a3195681fa19b977f6fd5d856ee5e551a240966f2f2da52d7b5971f4-8f1cbe53-be95-4d68-90b9-da5c75236e0b', content=\"Weekly Issues Andrew's Letters Data Points ML Research Business Science Culture Hardware AI Careers About Subscribe The Batch Weekly Issues issue 284 Published Jan 15, 2025 Reading time 13 min read Published Jan 15, 2025 Reading time 13 min read Share Dear friends, Writing software, especially prototypes, is becoming cheaper. This will lead to increased demand for people who can decide what to build. AI Product Management has a bright future! Software is often written by teams that comprise Product Managers (PMs), who decide what to build (such as what features to implement for what users) and Software Developers, who write the code to build the product. Economics shows that when two goods are complements — such as cars (with internal-combustion engines) and gasoline — falling prices in one leads to higher demand for the other. For example, as cars became cheaper, more people bought them, which led to increased demand for gas. Something similar will happen in software. Given a clear specification for what to build, AI is making the building itself much faster and cheaper. This will significantly increase demand for people who can come up with clear specs for valuable things to build. This is why I’m excited about the future of Product Management, the discipline of developing and managing software products. I’m especially excited about the future of AI Product Management, the discipline of developing and managing AI software products. Many companies have an Engineer:PM ratio\", source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='bc08a5e541cb577d230ed220050d15ec6e251e48763ecba7a79e548a44a65cd6-aedcb56c-8a34-4016-b565-206f9228be86', content='of, say, 6:1. (The ratio varies widely by company and industry, and anywhere from 4:1 to 10:1 is typical.) As coding becomes more efficient, I think teams will need more product management work (as well as design work) as a fraction of the total workforce. Perhaps engineers will step in to do some of this work, but if it remains the purview of specialized Product Managers, then the demand for these roles will grow. This change in the composition of software development teams is not yet moving forward at full speed. One major force slowing this shift, particularly in AI Product Management, is that Software Engineers, being technical, are understanding and embracing AI much faster than Product Managers. Even today, most companies have difficulty finding people who know how to develop products and also understand AI, and I expect this shortage to grow. Further, AI Product Management requires a different set of skills than traditional software Product Management. It requires: Technical proficiency in AI. PMs need to understand what products might be technically feasible to build. They also need to understand the lifecycle of AI projects, such as data collection, building, then monitoring, and maintenance of AI models. Iterative development. Because AI development is much more iterative than traditional software and requires more course corrections along the way, PMs need to understand how to manage such a process. Data proficiency. AI products often learn from data, and they can', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='10f6c4d372ec7ddf6dc366f9679635425e55fbffa66fee31b4840cb86631e972-02495efa-42ee-41bb-bb47-751a896fe72f', content='be designed to generate richer forms of data than traditional software. Skill in managing ambiguity. Because AI’s performance is hard to predict in advance, PMs need to be comfortable with this and have tactics to manage it. Ongoing learning. AI technology is advancing rapidly. PMs, like everyone else who aims to make best use of the technology, need to keep up with the latest technology advances, product ideas, and how they fit into users’ lives. Finally, AI Product Managers will need to know how to ensure that AI is implemented responsibly (for example, when we need to implement guardrails to prevent bad outcomes), and also be skilled at gathering feedback fast to keep projects moving. Increasingly, I also expect strong product managers to be able to build prototypes for themselves. The demand for good AI Product Managers will be huge. In addition to growing AI Product Management as a discipline, perhaps some engineers will also end up doing more product management work. The variety of valuable things we can build is nearly unlimited. What a great time to build! Keep learning, Andrew A MESSAGE FROM\\xa0DEEPLEARNING.AI Get up-close and personal with OpenAI’s groundbreaking o1 model! In our short course “Reasoning with o1,” you’ll learn how to get the best performance in coding, planning, and STEM tasks; perform complex, multi-step tasks; and optimize prompts with meta prompting. Enroll today News DeepSeek Ups the Open Weights Ante A new model from Hangzhou upstart DeepSeek', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='f2f2196a46f15d5a7d291f8d02a369b0dcf2bb7cadf042d42d5dcad8aa85c1de-35b6d8e1-7cc9-45b7-8990-c3b3f3e9328a', content='delivers outstanding performance and may change the equation for training costs. What’s new: DeepSeek-V3 is an open large language model that outperforms Llama 3.1 405B and GPT-4o on key benchmarks and achieves exceptional scores in coding and math. The weights are open except for applications that involve military uses, harming minors, generating false information, and similar restrictions. You can download them here . Mixture of experts (MoE) basics: The MoE architecture uses different subsets of its parameters to process different inputs. Each MoE layer contains a group of neural networks, or experts, preceded by a gating module that learns to choose which one(s) to use based on the input. In this way, different experts learn to specialize in different types of examples. Because not all parameters are used to produce any given output, the network uses less energy and runs faster than models of similar size that use all parameters to process every input. How it works: DeepSeek-V3 is a mixture-of-experts (MoE) transformer that comprises 671 billion parameters, of which 37 billion are active at any moment. The team trained the model in 2.79 million GPU hours — less than 1/10 the time required to train Llama 3.1 405B , which DeepSeek-V3 substantially outperforms — at an extraordinarily low cost of $5.6 million. The developers trained it on roughly 15 trillion tokens, including a larger percentage of coding and math data relative to DeepSeek-V2. They fine-tuned it on a wide', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='08cd2ac5dd8c3243cf798677850b3647b2bedbcfbafac571c06c7386bd58d8af-637209eb-3916-4be2-8d59-a3019cfed704', content='variety of tasks using output generated by DeepSeek-R1 and DeepSeek-V2.5. They further sharpened its performance across diverse domains using the reinforcement learning algorithm known as group relative policy optimization . Earlier work showed that training to predict the next two tokens would improve performance over learning to predict just one. The authors implemented this procedure. The model learned to predict the first token as usual and used an additional set of layers to learn to predict the second token. The additional layers aren’t used at inference. Following DeepSeek-V2 , DeepSeek-V3 uses multi-head latent attention, which saves memory during execution relative to other variants of attention. Also like DeepSeek-V2, the new model combines dedicated (routed) and shared experts. The model chooses eight of 256 experts for a particular input, but it also uses a shared expert that processes all inputs. Results: In DeepSeek’s tests, DeepSeek-V3 outperformed Llama 3.1 405B and Qwen 2.5 72B across the board, and its performance compared favorably with that of GPT-4o. DeepSeek-V3 showed exceptional performance in coding and math tasks. In coding, DeepSeek-V3 dominated in five of the seven benchmarks tested. However, DeepSeek-V3 lost to o1 on one of the five, according to a public leaderboard. Specifically, on Polyglot , which tests a model’s ability to generate code in response to difficult requests in multiple programming languages, DeepSeek-V3 (48.5 percent accuracy)', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='8b1f417637da59cd01053992ee7b424dc9e4115655e800913fad092bba627949-da58f6b6-7bb6-4241-be23-bb432742df60', content='beat Claude Sonnet 3.5 (45.3 percent accuracy), though it lost to o1 (61.7 percent accuracy). In language tasks, it performed neck-and-neck with Claude 3.5 Sonnet, achieving higher scores in some tasks and lower in others. Behind the news: OpenAI’s o1 models excel thanks to agentic workflows in which they reflect on their own outputs, use tools, and so on. DeepSeek swims against the tide and achieves superior results without relying on agentic workflows. Why it matters: Open models continue to challenge closed models, giving developers high-quality options that they can modify and deploy at will. But the larger story is DeepSeek-V3’s shockingly low training cost. The team doesn’t explain precisely how the model achieves outstanding performance with such a low processing budget. (The paper credits “meticulous engineering optimizations.”) But it’s likely that DeepSeek’s steady refinement of MoE is a key factor. DeepSeek-V2, also an MoE model, saved more than 40 percent in training versus the earlier DeepSeek 67B, which didn’t employ MoE. In 2022, Microsoft found that MoE cost five times less in training for equal performance compared to a dense model, and Google and Meta reported that MoE achieved better performance than dense models trained on the same numbers of tokens. We’re thinking: If they can be replicated, DeepSeek’s results have significant implications for the economics of training foundation models. If indeed it now costs around $5 million to build a GPT-4o-level', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='e4a933abfb686f0f8a5e1679ecbaba7965329fc16f80cfc9738d9c4a06ba773e-d70f4410-5ae3-4928-80d9-dba3b87cbaf5', content='model, more teams will be able to train such models, and the cost of competing with the AI giants could fall dramatically. U.S. Moves to Expand AI Export Restrictions The United States proposed limits on exports of AI technology that would dramatically expand previous restrictions, creating a new international hierarchy for access to advanced chips and models. What’s new: The Biden administration, which will transition to leadership under incoming President Trump next week, issued new rules that restrict exports of AI chips and models to most countries beyond a select group of close allies. The rules, which are not yet final, would create a three-tier system that limits exports to a number of close allies and blocks access entirely to China, Iran, North Korea, Russia, and others. They also would introduce the U.S.’ first-ever restrictions on exporting closed weights for large AI models. How it works: The restrictions were announced shortly after a leak reached the press. A public comment period of 120 days will enable the incoming U.S. Presidential administration to consider input from the business and diplomatic communities and modify the rules before they take effect. The rules are scheduled to take effect in one year. A new hierarchy divides nations into three groups that would have different degrees of access to AI chips both designed in the U.S. and manufactured abroad using U.S. technology, as well as proprietary AI models. Tier 1: Australia, Japan, Taiwan, the United', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='6e5b0002518f176b891d1ba44313e2764e77d0a85d86cd7941a60a5912d487f7-620502d3-20c4-4962-bc70-08c7c78661d8', content='Kingdom, and most of Europe would retain nearly unrestricted access. However, these nations must keep 75 percent of their AI computing power within allied countries. No more than 10 percent can be transferred to any single country outside this group to ensure that advanced AI development remains concentrated among close U.S. allies. Tier 2: Traditional U.S. allies and trade partners like Israel, Saudi Arabia, and Singapore face an initial cap of 507 million units of total processing power (TPP) — roughly the computational capacity of 32,000 Nvidia H100 chips — through the first quarter of 2025. The cap would increase to 1.02 billion TPP by 2027. U.S. companies that operate in these countries can apply for higher limits: 633 million TPP in Q1 2025, rising to 5.064 billion TPP by Q1 2027. Tier 3: China, Russia, and around two dozen other countries are blocked from receiving advanced AI chips, model weights, and specialized knowledge related to these systems. The U.S. Commerce Department’s export control agency must approve the export of models or transfer of weights of closed models that were trained using more than 10 26 computational operations. These rules target future systems, as no known models today used this amount of computation during training. Companies based in the U.S. must maintain at least 50 percent of their total AI computing power within U.S. borders. They also must track distribution of their models, implement security measures, and submit to regular audits.', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='d5b0f69dae7be5f18474b1dd721d2380dfc22ddaac6f37d77cee01441042d835-c4672c4a-73ec-4103-b28b-94e596ef1bc5', content='Behind the news: The proposed rules build on 2022’s CHIPS and Science Act , which was designed to strengthen domestic semiconductor production and restrict technologies abroad that could bear on U.S. security. An initial round of restrictions in late 2022 barred semiconductor suppliers AMD and Nvidia from selling advanced chips to Chinese firms. In November 2024, the U.S. tightened restrictions further, ordering Taiwan Semiconductor Manufacturing Company, which fabricates those chips, to halt production of advanced chips destined for China. Plus green AI infrastructure: In addition, President Biden issued an executive order to encourage the rapid build-out of computing infrastructure for AI. The federal government will hold competitions among private companies to lease sites it owns for the building of data centers at private expense. The selection of sites will take into account availability of sources of clean energy, including support for nuclear energy. The government will expedite permitting on these sites and support development of energy transmission lines around them. It will also encourage international allies to invest in AI infrastructure powered by clean energy. Why it matters: Protecting the United States’ advantages in high tech has been a rising priority for the White House over the past decade.\\xa0The earlier export restrictions forced many Chinese AI developers to rely on less-powerful hardware. The new limits are likely to have a far broader impact. They could', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='f1bd7e93536e0b1f748a1aeddaa046065066a8ddfef446f38af12d4a4502c4b2-94c2f4cc-933c-428c-b537-922a17e0499f', content='force developers in the Tier 2 and Tier 3 countries to build less resource-intensive models and lead them to collaborate more closely with each other, reducing the value of U.S.-made technology worldwide. They could hurt U.S. chip vendors, which have warned that the rules could weaken U.S. competitiveness in the global economy. They could also force companies that are building huge data centers to process AI calculations to reconsider their plans. We’re thinking: The Biden administration’s embargo on AI chips has been leaky . So far, it has slowed down adversaries only slightly while spurring significant investment in potential suppliers that aren’t connected to the U.S. While the public comment period invites lobbying and industry feedback, ultimately geopolitical priorities may hold sway. Whatever the outcome, reducing the world’s dependence on U.S. chips and models would result in a very different global AI ecosystem. AI Supercomputer on Your Desk Nvidia’s new desktop computer is built specifically to run large AI models. What’s new: Project Digits is a personal supercomputer intended to help developers fine-tune and run large models locally. Project Digits, which is small enough to hold in one hand, will be available in May, starting at $3000. How it works: Project Digits is designed to run models of up to 200 billion parameters — roughly five times the size that fits comfortably on typical consumer hardware — provided they’re quantized to 4 bits of precision. Two units', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='3606b3a086420ec6180eff7a8613d6e277c849638e3fa4668e562f5799a5e5fd-59614c7f-8d02-4c14-ae5e-e56b0cd90081', content='can be connected to run models such as Meta’s Llama 3.1 405B. Complete specifications are not yet available. Project Digits runs Nvidia’s DGX operating system, a flavor of Ubuntu Linux. The system is based on a GB10 system-on-a-chip that combines the Nvidia Blackwell GPU architecture (which serves as the basis for its latest B100 GPUs) and Grace CPU architecture (designed to manage AI workloads in data centers), connected via high-bandwidth NVLink interconnect. It comes with 128 GB of unified memory and 4 terabytes of solid-state storage. The system connects to Nvidia’s DGX Cloud service to enable developers to deploy models from a local machine to cloud infrastructure. Behind the news: In a blitz of announcements at the Consumer Electronics Show (CES), Nvidia also launched a platform for developing robotics, autonomous vehicles, and other physical AI systems. Cosmos includes pretrained language and vision models that range from 4 billion to 14 billion parameters for generating synthetic training data for robots or building policy models that translate a robot’s state into its next action. Nvidia also released Cosmos Nemotron, a 34 billion-parameter, vision-language model designed for use by AI agents, plus a video tokenizer and other tools for robotics developers. Why it matters: It’s common to train models on Nvidia A100 or H100 GPUs, which come with a price tag of at least $8,000 or $20,000 respectively, along with 40 gigabytes to 80 gigabytes of memory. These hefty', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='2b3d622240e3850fbc958497d3928c68632293bdc4c5eeea99c75f7fd8047f70-9702a49f-5732-4187-997f-f59b289a9c73', content='requirements push many developers to buy access to computing infrastructure from a cloud provider. Coming in at $3,000 with 128 gigabytes of memory, Project Digits is designed to empower machine learning engineers to train and run larger models on their own machines. We’re thinking: We look forward to seeing cost/throughput comparisons between running a model on Project Digits, A100, and H100. Calibrating Contrast Contrastive loss functions make it possible to produce good embeddings without labeled data. A twist on this idea makes even more useful embeddings. What’s new: Vlad Sobal and colleagues at Meta, New York University, Brown University, Genentech, and Canadian Institute for Advanced Research introduced X-Sample contrastive loss (X-CLR), a self-supervised loss function that enables vision models to learn embeddings that capture similarities and differences among examples with greater subtlety. Key insight: Contrastive loss functions like SimCLR equally encourage a model to produce dissimilar embeddings of images of, say, a cat, a dog, and a dump truck. But, of course, cats and dogs are more similar to each other than either are to dump trucks. Instead of marking examples as similar or dissimilar, X-CLR assigns similarity scores, so a model can learn to produce embeddings that match those scores. How it works: The authors used X-CLR to train an embedding model on Conceptual Captions datasets of image-text pairs scraped from the web: CC-3M (3 million text-image pairs)', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='522558ee74f83643357b07d3b1b4dc231e464664b8ac607448ac92658a5ac56a-e3da67a5-9068-4858-afa9-68ec50cd759f', content='and CC-12M (12 million text-image pairs). The model was similar to CLIP , except the text encoder was a sentence transformer pretrained on sentence pairs, and the vision encoder was a ResNet-50 pretrained on ImageNet. The sentence transformer embedded text captions for all examples. The system computed similarity scores according to cosine similarity between the text embeddings. Similarly, a ResNet-50 computed image embeddings, and the system computed similarity scores between them. The authors froze the sentence transformer and used the text similarity scores as labels in the loss function. The loss function minimized the difference between the similarity scores of the text embeddings and the corresponding similarity scores of the image embeddings. Results: Systems trained using X-CLR outperformed competitors in ImageNet classification, especially when less training data was available. (The authors followed CLIP’s method of classification: They computed the similarity between an image embedding and text embeddings of all classes. The image’s classification was the class that corresponds to the text embedding with the highest similarity to the image embedding.) The authors compared a system trained using X-CLR, one trained using SimCLR, and CLIP. After training on the CC-3M dataset, the X-CLR system achieved 58.2 percent accuracy on ImageNet, while the SimCLR model achieved 57.0 percent and CLIP achieved 41.0 percent. Training on CC-12M resulted in smaller differences: X-CLR', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='793e201acac2ea8b4293dc2016119e839f769948e24255738ef6a0922ced625c-480c634d-fa21-4831-a2e0-991eb3999608', content='achieved 59.4 percent accuracy, SimCLR achieved 58.9 percent, and CLIP achieved 58.8 percent. Why it matters: Contrastive loss functions are very useful, but the similar/dissimilar dichotomy leaves important nuances unaccounted for. Like CLIP, X-CLR takes advantage of both images and their captions for self-supervised learning. However, CLIP learns to recognize image-text pairs as similar or dissimilar, while X-CLR matches image-image pairs using captions as a similarity signal that’s continuous rather than discrete. We’re thinking: Reality is not black and white. Allowing for shades of gray makes for better modeling. Share Subscribe to The Batch Stay updated with weekly AI News and Insights delivered to your inbox', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='578feb7bc63696d6a24950a0b24320561b019d42299dfaf179f58a42d7512101-191465c9-aa5e-4e79-a964-26f77e2aac51', content=\"Weekly Issues Andrew's Letters Data Points ML Research Business Science Culture Hardware AI Careers About Subscribe\\nWeekly Issues Andrew's Letters Data Points ML Research Business Science Culture Hardware AI Careers\\nWeekly Issues\\nAndrew's Letters\\nData Points\\nML Research\\nBusiness\\nScience\\nCulture\\nHardware\\nAI Careers\\nAbout Subscribe\\nAbout\", source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='0766da8047ee6f4cbf417f7272583cb8f2710d113687ad696ad5b29146d9da60-152a0b11-1dc5-40e8-be48-9415a01b6da1', content='The Batch\\nWeekly Issues\\nissue 284\\nPublished Jan 15, 2025\\nPublished\\n\\nPublished\\nJan 15, 2025\\nReading time 13 min read\\nReading time', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='38a615e0f3869ab9706b145633fbdcbe8cf9b15ff26fec49b89848776904d139-647200f9-3e87-44ee-8920-76f65f1a73c9', content='Reading time\\n13 min read', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='b3413e9a1f9ac37798096d4f785d22e3a7c24d5a3acf80692084dfcc5de1bec0-eaadc9c5-a517-495d-9f66-300e722ef58a', content='Published Jan 15, 2025 Reading time 13 min read Share Dear friends, Writing software, especially prototypes, is becoming cheaper. This will lead to increased demand for people who can decide what to build. AI Product Management has a bright future! Software is often written by teams that comprise Product Managers (PMs), who decide what to build (such as what features to implement for what users) and Software Developers, who write the code to build the product. Economics shows that when two goods are complements — such as cars (with internal-combustion engines) and gasoline — falling prices in one leads to higher demand for the other. For example, as cars became cheaper, more people bought them, which led to increased demand for gas. Something similar will happen in software. Given a clear specification for what to build, AI is making the building itself much faster and cheaper. This will significantly increase demand for people who can come up with clear specs for valuable things to build. This is why I’m excited about the future of Product Management, the discipline of developing and managing software products. I’m especially excited about the future of AI Product Management, the discipline of developing and managing AI software products. Many companies have an Engineer:PM ratio of, say, 6:1. (The ratio varies widely by company and industry, and anywhere from 4:1 to 10:1 is typical.) As coding becomes more efficient, I think teams will need more product management work (as', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='54db281fad2e51ad111b7904dbf39532aed1fb1965543fd47a4f3b09fdd7a041-74618ee7-51d1-4741-a45e-9bb3a07def3e', content='well as design work) as a fraction of the total workforce. Perhaps engineers will step in to do some of this work, but if it remains the purview of specialized Product Managers, then the demand for these roles will grow. This change in the composition of software development teams is not yet moving forward at full speed. One major force slowing this shift, particularly in AI Product Management, is that Software Engineers, being technical, are understanding and embracing AI much faster than Product Managers. Even today, most companies have difficulty finding people who know how to develop products and also understand AI, and I expect this shortage to grow. Further, AI Product Management requires a different set of skills than traditional software Product Management. It requires: Technical proficiency in AI. PMs need to understand what products might be technically feasible to build. They also need to understand the lifecycle of AI projects, such as data collection, building, then monitoring, and maintenance of AI models. Iterative development. Because AI development is much more iterative than traditional software and requires more course corrections along the way, PMs need to understand how to manage such a process. Data proficiency. AI products often learn from data, and they can be designed to generate richer forms of data than traditional software. Skill in managing ambiguity. Because AI’s performance is hard to predict in advance, PMs need to be comfortable with this and', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='c30b9ac23cdf7bac925221116d4ce21cc787c47347c2d74ad1a05e853cda1577-d811b9dc-0394-4767-b1fe-13e22225a94e', content='have tactics to manage it. Ongoing learning. AI technology is advancing rapidly. PMs, like everyone else who aims to make best use of the technology, need to keep up with the latest technology advances, product ideas, and how they fit into users’ lives. Finally, AI Product Managers will need to know how to ensure that AI is implemented responsibly (for example, when we need to implement guardrails to prevent bad outcomes), and also be skilled at gathering feedback fast to keep projects moving. Increasingly, I also expect strong product managers to be able to build prototypes for themselves. The demand for good AI Product Managers will be huge. In addition to growing AI Product Management as a discipline, perhaps some engineers will also end up doing more product management work. The variety of valuable things we can build is nearly unlimited. What a great time to build! Keep learning, Andrew A MESSAGE FROM\\xa0DEEPLEARNING.AI Get up-close and personal with OpenAI’s groundbreaking o1 model! In our short course “Reasoning with o1,” you’ll learn how to get the best performance in coding, planning, and STEM tasks; perform complex, multi-step tasks; and optimize prompts with meta prompting. Enroll today News DeepSeek Ups the Open Weights Ante A new model from Hangzhou upstart DeepSeek delivers outstanding performance and may change the equation for training costs. What’s new: DeepSeek-V3 is an open large language model that outperforms Llama 3.1 405B and GPT-4o on key benchmarks and', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='e3460f1e93763d2afc5bb5d62196ea6effad065c7233b54ea9a3564a6523072b-3f1cf771-5531-4d5a-b6f2-1f93f256540a', content='achieves exceptional scores in coding and math. The weights are open except for applications that involve military uses, harming minors, generating false information, and similar restrictions. You can download them here . Mixture of experts (MoE) basics: The MoE architecture uses different subsets of its parameters to process different inputs. Each MoE layer contains a group of neural networks, or experts, preceded by a gating module that learns to choose which one(s) to use based on the input. In this way, different experts learn to specialize in different types of examples. Because not all parameters are used to produce any given output, the network uses less energy and runs faster than models of similar size that use all parameters to process every input. How it works: DeepSeek-V3 is a mixture-of-experts (MoE) transformer that comprises 671 billion parameters, of which 37 billion are active at any moment. The team trained the model in 2.79 million GPU hours — less than 1/10 the time required to train Llama 3.1 405B , which DeepSeek-V3 substantially outperforms — at an extraordinarily low cost of $5.6 million. The developers trained it on roughly 15 trillion tokens, including a larger percentage of coding and math data relative to DeepSeek-V2. They fine-tuned it on a wide variety of tasks using output generated by DeepSeek-R1 and DeepSeek-V2.5. They further sharpened its performance across diverse domains using the reinforcement learning algorithm known as group relative', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='1b724333e8c4aba31633b7aed3dbd87d0b7de51718d2ce4956a364697b6e81bb-22713383-7ba9-407d-a8cf-140017d7f79a', content='policy optimization . Earlier work showed that training to predict the next two tokens would improve performance over learning to predict just one. The authors implemented this procedure. The model learned to predict the first token as usual and used an additional set of layers to learn to predict the second token. The additional layers aren’t used at inference. Following DeepSeek-V2 , DeepSeek-V3 uses multi-head latent attention, which saves memory during execution relative to other variants of attention. Also like DeepSeek-V2, the new model combines dedicated (routed) and shared experts. The model chooses eight of 256 experts for a particular input, but it also uses a shared expert that processes all inputs. Results: In DeepSeek’s tests, DeepSeek-V3 outperformed Llama 3.1 405B and Qwen 2.5 72B across the board, and its performance compared favorably with that of GPT-4o. DeepSeek-V3 showed exceptional performance in coding and math tasks. In coding, DeepSeek-V3 dominated in five of the seven benchmarks tested. However, DeepSeek-V3 lost to o1 on one of the five, according to a public leaderboard. Specifically, on Polyglot , which tests a model’s ability to generate code in response to difficult requests in multiple programming languages, DeepSeek-V3 (48.5 percent accuracy) beat Claude Sonnet 3.5 (45.3 percent accuracy), though it lost to o1 (61.7 percent accuracy). In language tasks, it performed neck-and-neck with Claude 3.5 Sonnet, achieving higher scores in some tasks and', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='85d86971035e2c34d55c63619d1fc28a6869326d74038545637fca5dc34f7e69-93994343-9a54-4c5d-ba57-e3adc7990cf4', content='lower in others. Behind the news: OpenAI’s o1 models excel thanks to agentic workflows in which they reflect on their own outputs, use tools, and so on. DeepSeek swims against the tide and achieves superior results without relying on agentic workflows. Why it matters: Open models continue to challenge closed models, giving developers high-quality options that they can modify and deploy at will. But the larger story is DeepSeek-V3’s shockingly low training cost. The team doesn’t explain precisely how the model achieves outstanding performance with such a low processing budget. (The paper credits “meticulous engineering optimizations.”) But it’s likely that DeepSeek’s steady refinement of MoE is a key factor. DeepSeek-V2, also an MoE model, saved more than 40 percent in training versus the earlier DeepSeek 67B, which didn’t employ MoE. In 2022, Microsoft found that MoE cost five times less in training for equal performance compared to a dense model, and Google and Meta reported that MoE achieved better performance than dense models trained on the same numbers of tokens. We’re thinking: If they can be replicated, DeepSeek’s results have significant implications for the economics of training foundation models. If indeed it now costs around $5 million to build a GPT-4o-level model, more teams will be able to train such models, and the cost of competing with the AI giants could fall dramatically. U.S. Moves to Expand AI Export Restrictions The United States proposed limits on', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='05f9c0c9f383c110fa764b6a2d893b2e463bba68c290e99988d4c5c43a1b7009-688c3313-3938-470a-bcf7-0deeec72ed31', content='exports of AI technology that would dramatically expand previous restrictions, creating a new international hierarchy for access to advanced chips and models. What’s new: The Biden administration, which will transition to leadership under incoming President Trump next week, issued new rules that restrict exports of AI chips and models to most countries beyond a select group of close allies. The rules, which are not yet final, would create a three-tier system that limits exports to a number of close allies and blocks access entirely to China, Iran, North Korea, Russia, and others. They also would introduce the U.S.’ first-ever restrictions on exporting closed weights for large AI models. How it works: The restrictions were announced shortly after a leak reached the press. A public comment period of 120 days will enable the incoming U.S. Presidential administration to consider input from the business and diplomatic communities and modify the rules before they take effect. The rules are scheduled to take effect in one year. A new hierarchy divides nations into three groups that would have different degrees of access to AI chips both designed in the U.S. and manufactured abroad using U.S. technology, as well as proprietary AI models. Tier 1: Australia, Japan, Taiwan, the United Kingdom, and most of Europe would retain nearly unrestricted access. However, these nations must keep 75 percent of their AI computing power within allied countries. No more than 10 percent can be', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='5be4286b3c08d24b4b37e90929be345c70de5efa860289e4677f81dcbb5d4f29-3d681b68-c47a-49b9-813d-1fb959f205a7', content='transferred to any single country outside this group to ensure that advanced AI development remains concentrated among close U.S. allies. Tier 2: Traditional U.S. allies and trade partners like Israel, Saudi Arabia, and Singapore face an initial cap of 507 million units of total processing power (TPP) — roughly the computational capacity of 32,000 Nvidia H100 chips — through the first quarter of 2025. The cap would increase to 1.02 billion TPP by 2027. U.S. companies that operate in these countries can apply for higher limits: 633 million TPP in Q1 2025, rising to 5.064 billion TPP by Q1 2027. Tier 3: China, Russia, and around two dozen other countries are blocked from receiving advanced AI chips, model weights, and specialized knowledge related to these systems. The U.S. Commerce Department’s export control agency must approve the export of models or transfer of weights of closed models that were trained using more than 10 26 computational operations. These rules target future systems, as no known models today used this amount of computation during training. Companies based in the U.S. must maintain at least 50 percent of their total AI computing power within U.S. borders. They also must track distribution of their models, implement security measures, and submit to regular audits. Behind the news: The proposed rules build on 2022’s CHIPS and Science Act , which was designed to strengthen domestic semiconductor production and restrict technologies abroad that could bear on', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='235efea3a8cf889b5be99e5a83f6ef1597fafa2226bad4a736efabd48eaeb68b-ac87be85-bafd-4d56-98a0-4af2b01e7682', content='U.S. security. An initial round of restrictions in late 2022 barred semiconductor suppliers AMD and Nvidia from selling advanced chips to Chinese firms. In November 2024, the U.S. tightened restrictions further, ordering Taiwan Semiconductor Manufacturing Company, which fabricates those chips, to halt production of advanced chips destined for China. Plus green AI infrastructure: In addition, President Biden issued an executive order to encourage the rapid build-out of computing infrastructure for AI. The federal government will hold competitions among private companies to lease sites it owns for the building of data centers at private expense. The selection of sites will take into account availability of sources of clean energy, including support for nuclear energy. The government will expedite permitting on these sites and support development of energy transmission lines around them. It will also encourage international allies to invest in AI infrastructure powered by clean energy. Why it matters: Protecting the United States’ advantages in high tech has been a rising priority for the White House over the past decade.\\xa0The earlier export restrictions forced many Chinese AI developers to rely on less-powerful hardware. The new limits are likely to have a far broader impact. They could force developers in the Tier 2 and Tier 3 countries to build less resource-intensive models and lead them to collaborate more closely with each other, reducing the value of U.S.-made technology', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='42855dcb51bede0d65de31bcebfa28990fb183bd579cf67518e0b8faa9c66445-0cfd3458-ac44-4e05-b2d4-93070588207c', content='worldwide. They could hurt U.S. chip vendors, which have warned that the rules could weaken U.S. competitiveness in the global economy. They could also force companies that are building huge data centers to process AI calculations to reconsider their plans. We’re thinking: The Biden administration’s embargo on AI chips has been leaky . So far, it has slowed down adversaries only slightly while spurring significant investment in potential suppliers that aren’t connected to the U.S. While the public comment period invites lobbying and industry feedback, ultimately geopolitical priorities may hold sway. Whatever the outcome, reducing the world’s dependence on U.S. chips and models would result in a very different global AI ecosystem. AI Supercomputer on Your Desk Nvidia’s new desktop computer is built specifically to run large AI models. What’s new: Project Digits is a personal supercomputer intended to help developers fine-tune and run large models locally. Project Digits, which is small enough to hold in one hand, will be available in May, starting at $3000. How it works: Project Digits is designed to run models of up to 200 billion parameters — roughly five times the size that fits comfortably on typical consumer hardware — provided they’re quantized to 4 bits of precision. Two units can be connected to run models such as Meta’s Llama 3.1 405B. Complete specifications are not yet available. Project Digits runs Nvidia’s DGX operating system, a flavor of Ubuntu Linux. The', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='547594176e43104e0bce000ce830433683b713d474495a40576342aca257bc42-9ecac01f-828d-4af4-ba95-3c687624d704', content='system is based on a GB10 system-on-a-chip that combines the Nvidia Blackwell GPU architecture (which serves as the basis for its latest B100 GPUs) and Grace CPU architecture (designed to manage AI workloads in data centers), connected via high-bandwidth NVLink interconnect. It comes with 128 GB of unified memory and 4 terabytes of solid-state storage. The system connects to Nvidia’s DGX Cloud service to enable developers to deploy models from a local machine to cloud infrastructure. Behind the news: In a blitz of announcements at the Consumer Electronics Show (CES), Nvidia also launched a platform for developing robotics, autonomous vehicles, and other physical AI systems. Cosmos includes pretrained language and vision models that range from 4 billion to 14 billion parameters for generating synthetic training data for robots or building policy models that translate a robot’s state into its next action. Nvidia also released Cosmos Nemotron, a 34 billion-parameter, vision-language model designed for use by AI agents, plus a video tokenizer and other tools for robotics developers. Why it matters: It’s common to train models on Nvidia A100 or H100 GPUs, which come with a price tag of at least $8,000 or $20,000 respectively, along with 40 gigabytes to 80 gigabytes of memory. These hefty requirements push many developers to buy access to computing infrastructure from a cloud provider. Coming in at $3,000 with 128 gigabytes of memory, Project Digits is designed to empower machine', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='06860b93c4ea29e2bb15541aade8b475129a02705cabbd293aa108ced8715b0f-6e0d4ae4-87e4-4e8e-9e52-411a56cce8e5', content='learning engineers to train and run larger models on their own machines. We’re thinking: We look forward to seeing cost/throughput comparisons between running a model on Project Digits, A100, and H100. Calibrating Contrast Contrastive loss functions make it possible to produce good embeddings without labeled data. A twist on this idea makes even more useful embeddings. What’s new: Vlad Sobal and colleagues at Meta, New York University, Brown University, Genentech, and Canadian Institute for Advanced Research introduced X-Sample contrastive loss (X-CLR), a self-supervised loss function that enables vision models to learn embeddings that capture similarities and differences among examples with greater subtlety. Key insight: Contrastive loss functions like SimCLR equally encourage a model to produce dissimilar embeddings of images of, say, a cat, a dog, and a dump truck. But, of course, cats and dogs are more similar to each other than either are to dump trucks. Instead of marking examples as similar or dissimilar, X-CLR assigns similarity scores, so a model can learn to produce embeddings that match those scores. How it works: The authors used X-CLR to train an embedding model on Conceptual Captions datasets of image-text pairs scraped from the web: CC-3M (3 million text-image pairs) and CC-12M (12 million text-image pairs). The model was similar to CLIP , except the text encoder was a sentence transformer pretrained on sentence pairs, and the vision encoder was a ResNet-50', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='21b929a8fc931bde6837651d9ed36536c1bea2ddb4ed47da331ccc404b30df27-bc5c9747-6433-43e1-bdeb-d0a84fe192c5', content='pretrained on ImageNet. The sentence transformer embedded text captions for all examples. The system computed similarity scores according to cosine similarity between the text embeddings. Similarly, a ResNet-50 computed image embeddings, and the system computed similarity scores between them. The authors froze the sentence transformer and used the text similarity scores as labels in the loss function. The loss function minimized the difference between the similarity scores of the text embeddings and the corresponding similarity scores of the image embeddings. Results: Systems trained using X-CLR outperformed competitors in ImageNet classification, especially when less training data was available. (The authors followed CLIP’s method of classification: They computed the similarity between an image embedding and text embeddings of all classes. The image’s classification was the class that corresponds to the text embedding with the highest similarity to the image embedding.) The authors compared a system trained using X-CLR, one trained using SimCLR, and CLIP. After training on the CC-3M dataset, the X-CLR system achieved 58.2 percent accuracy on ImageNet, while the SimCLR model achieved 57.0 percent and CLIP achieved 41.0 percent. Training on CC-12M resulted in smaller differences: X-CLR achieved 59.4 percent accuracy, SimCLR achieved 58.9 percent, and CLIP achieved 58.8 percent. Why it matters: Contrastive loss functions are very useful, but the similar/dissimilar dichotomy', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='f2d1b9d21a7123ad8fd7aa1e81e87db9b9df1c945bcecedcf5e95a2e08b5d27c-c4cc18b0-e80c-4390-83a4-e7fcce0f0d39', content='leaves important nuances unaccounted for. Like CLIP, X-CLR takes advantage of both images and their captions for self-supervised learning. However, CLIP learns to recognize image-text pairs as similar or dissimilar, while X-CLR matches image-image pairs using captions as a similarity signal that’s continuous rather than discrete. We’re thinking: Reality is not black and white. Allowing for shades of gray makes for better modeling. Share', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='9ef13da51c616da19d03b324401d4c07ae3d325a1c791b187fd912368de7cd6b-5a4753d2-5046-4be9-af88-be381b2950d4', content='Published Jan 15, 2025\\nPublished', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='2834b8850299c18abbe65c2128d041f90dda3b201c6a0c9367bcfb5809469bf1-d3a277de-b9d0-4c30-a321-e1e76100e17e', content='Published\\nJan 15, 2025\\nJan 15, 2025\\nReading time 13 min read\\nReading time\\n\\nReading time\\n13 min read\\nShare\\nShare\\n\\nShare', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='8a6ac8702145d6678026a00f366629372dbae2753fd81e4b49506277920abe3f-c432766e-300a-4684-9418-3bcb56d73bba', content='Dear friends, Writing software, especially prototypes, is becoming cheaper. This will lead to increased demand for people who can decide what to build. AI Product Management has a bright future! Software is often written by teams that comprise Product Managers (PMs), who decide what to build (such as what features to implement for what users) and Software Developers, who write the code to build the product. Economics shows that when two goods are complements — such as cars (with internal-combustion engines) and gasoline — falling prices in one leads to higher demand for the other. For example, as cars became cheaper, more people bought them, which led to increased demand for gas. Something similar will happen in software. Given a clear specification for what to build, AI is making the building itself much faster and cheaper. This will significantly increase demand for people who can come up with clear specs for valuable things to build. This is why I’m excited about the future of Product Management, the discipline of developing and managing software products. I’m especially excited about the future of AI Product Management, the discipline of developing and managing AI software products. Many companies have an Engineer:PM ratio of, say, 6:1. (The ratio varies widely by company and industry, and anywhere from 4:1 to 10:1 is typical.) As coding becomes more efficient, I think teams will need more product management work (as well as design work) as a fraction of the total', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='9394148dbdf6b760c2f9da92133ca370bb65731648e93e085d97bf616851146d-1d42205b-6b08-4c92-a3cf-5e90c542d8f7', content='workforce. Perhaps engineers will step in to do some of this work, but if it remains the purview of specialized Product Managers, then the demand for these roles will grow. This change in the composition of software development teams is not yet moving forward at full speed. One major force slowing this shift, particularly in AI Product Management, is that Software Engineers, being technical, are understanding and embracing AI much faster than Product Managers. Even today, most companies have difficulty finding people who know how to develop products and also understand AI, and I expect this shortage to grow. Further, AI Product Management requires a different set of skills than traditional software Product Management. It requires: Technical proficiency in AI. PMs need to understand what products might be technically feasible to build. They also need to understand the lifecycle of AI projects, such as data collection, building, then monitoring, and maintenance of AI models. Iterative development. Because AI development is much more iterative than traditional software and requires more course corrections along the way, PMs need to understand how to manage such a process. Data proficiency. AI products often learn from data, and they can be designed to generate richer forms of data than traditional software. Skill in managing ambiguity. Because AI’s performance is hard to predict in advance, PMs need to be comfortable with this and have tactics to manage it. Ongoing learning. AI', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='a34bbfb12962c2a0063103f9999223b186dc43bb28a6cfc48e6376f7608d16f6-2066d21f-7bda-4498-b769-274a2e226f06', content='technology is advancing rapidly. PMs, like everyone else who aims to make best use of the technology, need to keep up with the latest technology advances, product ideas, and how they fit into users’ lives. Finally, AI Product Managers will need to know how to ensure that AI is implemented responsibly (for example, when we need to implement guardrails to prevent bad outcomes), and also be skilled at gathering feedback fast to keep projects moving. Increasingly, I also expect strong product managers to be able to build prototypes for themselves. The demand for good AI Product Managers will be huge. In addition to growing AI Product Management as a discipline, perhaps some engineers will also end up doing more product management work. The variety of valuable things we can build is nearly unlimited. What a great time to build! Keep learning, Andrew A MESSAGE FROM\\xa0DEEPLEARNING.AI Get up-close and personal with OpenAI’s groundbreaking o1 model! In our short course “Reasoning with o1,” you’ll learn how to get the best performance in coding, planning, and STEM tasks; perform complex, multi-step tasks; and optimize prompts with meta prompting. Enroll today News DeepSeek Ups the Open Weights Ante A new model from Hangzhou upstart DeepSeek delivers outstanding performance and may change the equation for training costs. What’s new: DeepSeek-V3 is an open large language model that outperforms Llama 3.1 405B and GPT-4o on key benchmarks and achieves exceptional scores in coding and math.', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='a0db0d4535f5f68652d7e5e7b92497598ec643bd5df0d6504e9eaaa0d5edc52c-6f9882fd-1d4c-41a6-861e-a9b3da2f5ebd', content='The weights are open except for applications that involve military uses, harming minors, generating false information, and similar restrictions. You can download them here . Mixture of experts (MoE) basics: The MoE architecture uses different subsets of its parameters to process different inputs. Each MoE layer contains a group of neural networks, or experts, preceded by a gating module that learns to choose which one(s) to use based on the input. In this way, different experts learn to specialize in different types of examples. Because not all parameters are used to produce any given output, the network uses less energy and runs faster than models of similar size that use all parameters to process every input. How it works: DeepSeek-V3 is a mixture-of-experts (MoE) transformer that comprises 671 billion parameters, of which 37 billion are active at any moment. The team trained the model in 2.79 million GPU hours — less than 1/10 the time required to train Llama 3.1 405B , which DeepSeek-V3 substantially outperforms — at an extraordinarily low cost of $5.6 million. The developers trained it on roughly 15 trillion tokens, including a larger percentage of coding and math data relative to DeepSeek-V2. They fine-tuned it on a wide variety of tasks using output generated by DeepSeek-R1 and DeepSeek-V2.5. They further sharpened its performance across diverse domains using the reinforcement learning algorithm known as group relative policy optimization . Earlier work showed that', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='8dc67a8165dc184ede37887f24bb074194b85071f495ee530a85e68495873a1b-611d4d0a-40c1-485c-a3ab-8274738a7b62', content='training to predict the next two tokens would improve performance over learning to predict just one. The authors implemented this procedure. The model learned to predict the first token as usual and used an additional set of layers to learn to predict the second token. The additional layers aren’t used at inference. Following DeepSeek-V2 , DeepSeek-V3 uses multi-head latent attention, which saves memory during execution relative to other variants of attention. Also like DeepSeek-V2, the new model combines dedicated (routed) and shared experts. The model chooses eight of 256 experts for a particular input, but it also uses a shared expert that processes all inputs. Results: In DeepSeek’s tests, DeepSeek-V3 outperformed Llama 3.1 405B and Qwen 2.5 72B across the board, and its performance compared favorably with that of GPT-4o. DeepSeek-V3 showed exceptional performance in coding and math tasks. In coding, DeepSeek-V3 dominated in five of the seven benchmarks tested. However, DeepSeek-V3 lost to o1 on one of the five, according to a public leaderboard. Specifically, on Polyglot , which tests a model’s ability to generate code in response to difficult requests in multiple programming languages, DeepSeek-V3 (48.5 percent accuracy) beat Claude Sonnet 3.5 (45.3 percent accuracy), though it lost to o1 (61.7 percent accuracy). In language tasks, it performed neck-and-neck with Claude 3.5 Sonnet, achieving higher scores in some tasks and lower in others. Behind the news: OpenAI’s o1', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='52a569be6a10d285ff3503eb9ae5a18dd1840733a32849ec252001f926be4c0d-d87f35e5-b5ef-465a-8533-523228e0c021', content='models excel thanks to agentic workflows in which they reflect on their own outputs, use tools, and so on. DeepSeek swims against the tide and achieves superior results without relying on agentic workflows. Why it matters: Open models continue to challenge closed models, giving developers high-quality options that they can modify and deploy at will. But the larger story is DeepSeek-V3’s shockingly low training cost. The team doesn’t explain precisely how the model achieves outstanding performance with such a low processing budget. (The paper credits “meticulous engineering optimizations.”) But it’s likely that DeepSeek’s steady refinement of MoE is a key factor. DeepSeek-V2, also an MoE model, saved more than 40 percent in training versus the earlier DeepSeek 67B, which didn’t employ MoE. In 2022, Microsoft found that MoE cost five times less in training for equal performance compared to a dense model, and Google and Meta reported that MoE achieved better performance than dense models trained on the same numbers of tokens. We’re thinking: If they can be replicated, DeepSeek’s results have significant implications for the economics of training foundation models. If indeed it now costs around $5 million to build a GPT-4o-level model, more teams will be able to train such models, and the cost of competing with the AI giants could fall dramatically. U.S. Moves to Expand AI Export Restrictions The United States proposed limits on exports of AI technology that would dramatically', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='7908450fc01e4e5668fe972aa994779d6be951e4cdb246fc06da0ba83cdb2b86-1402710b-f4e6-43e2-a48b-a6c2ed858c8c', content='expand previous restrictions, creating a new international hierarchy for access to advanced chips and models. What’s new: The Biden administration, which will transition to leadership under incoming President Trump next week, issued new rules that restrict exports of AI chips and models to most countries beyond a select group of close allies. The rules, which are not yet final, would create a three-tier system that limits exports to a number of close allies and blocks access entirely to China, Iran, North Korea, Russia, and others. They also would introduce the U.S.’ first-ever restrictions on exporting closed weights for large AI models. How it works: The restrictions were announced shortly after a leak reached the press. A public comment period of 120 days will enable the incoming U.S. Presidential administration to consider input from the business and diplomatic communities and modify the rules before they take effect. The rules are scheduled to take effect in one year. A new hierarchy divides nations into three groups that would have different degrees of access to AI chips both designed in the U.S. and manufactured abroad using U.S. technology, as well as proprietary AI models. Tier 1: Australia, Japan, Taiwan, the United Kingdom, and most of Europe would retain nearly unrestricted access. However, these nations must keep 75 percent of their AI computing power within allied countries. No more than 10 percent can be transferred to any single country outside this group to', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='3c7f2ac0b39c5cbcebea7f124db3f4fa824ffc6b2b9ec518c59a4c418d19481c-400be3e5-6e6a-4193-a4e1-c9b6132efdf0', content='ensure that advanced AI development remains concentrated among close U.S. allies. Tier 2: Traditional U.S. allies and trade partners like Israel, Saudi Arabia, and Singapore face an initial cap of 507 million units of total processing power (TPP) — roughly the computational capacity of 32,000 Nvidia H100 chips — through the first quarter of 2025. The cap would increase to 1.02 billion TPP by 2027. U.S. companies that operate in these countries can apply for higher limits: 633 million TPP in Q1 2025, rising to 5.064 billion TPP by Q1 2027. Tier 3: China, Russia, and around two dozen other countries are blocked from receiving advanced AI chips, model weights, and specialized knowledge related to these systems. The U.S. Commerce Department’s export control agency must approve the export of models or transfer of weights of closed models that were trained using more than 10 26 computational operations. These rules target future systems, as no known models today used this amount of computation during training. Companies based in the U.S. must maintain at least 50 percent of their total AI computing power within U.S. borders. They also must track distribution of their models, implement security measures, and submit to regular audits. Behind the news: The proposed rules build on 2022’s CHIPS and Science Act , which was designed to strengthen domestic semiconductor production and restrict technologies abroad that could bear on U.S. security. An initial round of restrictions in late', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='449bac8d3eb42bc9163a9527d3a44a8466690a0636a570baf7eb518871a76fdf-f9733378-b1d3-46c0-9fcb-1784bbc28562', content='2022 barred semiconductor suppliers AMD and Nvidia from selling advanced chips to Chinese firms. In November 2024, the U.S. tightened restrictions further, ordering Taiwan Semiconductor Manufacturing Company, which fabricates those chips, to halt production of advanced chips destined for China. Plus green AI infrastructure: In addition, President Biden issued an executive order to encourage the rapid build-out of computing infrastructure for AI. The federal government will hold competitions among private companies to lease sites it owns for the building of data centers at private expense. The selection of sites will take into account availability of sources of clean energy, including support for nuclear energy. The government will expedite permitting on these sites and support development of energy transmission lines around them. It will also encourage international allies to invest in AI infrastructure powered by clean energy. Why it matters: Protecting the United States’ advantages in high tech has been a rising priority for the White House over the past decade.\\xa0The earlier export restrictions forced many Chinese AI developers to rely on less-powerful hardware. The new limits are likely to have a far broader impact. They could force developers in the Tier 2 and Tier 3 countries to build less resource-intensive models and lead them to collaborate more closely with each other, reducing the value of U.S.-made technology worldwide. They could hurt U.S. chip vendors, which have', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='5d3cf1f28a5f0750be1175c3d852b9fdd03aa6b4babab309192a616f1d10caf8-5d364c92-c99f-4fdb-be43-1e03e7a6e769', content='warned that the rules could weaken U.S. competitiveness in the global economy. They could also force companies that are building huge data centers to process AI calculations to reconsider their plans. We’re thinking: The Biden administration’s embargo on AI chips has been leaky . So far, it has slowed down adversaries only slightly while spurring significant investment in potential suppliers that aren’t connected to the U.S. While the public comment period invites lobbying and industry feedback, ultimately geopolitical priorities may hold sway. Whatever the outcome, reducing the world’s dependence on U.S. chips and models would result in a very different global AI ecosystem. AI Supercomputer on Your Desk Nvidia’s new desktop computer is built specifically to run large AI models. What’s new: Project Digits is a personal supercomputer intended to help developers fine-tune and run large models locally. Project Digits, which is small enough to hold in one hand, will be available in May, starting at $3000. How it works: Project Digits is designed to run models of up to 200 billion parameters — roughly five times the size that fits comfortably on typical consumer hardware — provided they’re quantized to 4 bits of precision. Two units can be connected to run models such as Meta’s Llama 3.1 405B. Complete specifications are not yet available. Project Digits runs Nvidia’s DGX operating system, a flavor of Ubuntu Linux. The system is based on a GB10 system-on-a-chip that combines the', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='ad8912714c71e22e898e29fd8ff530cb132e5401ac47fb3b39b6aeb8e39430ed-a5d20563-a872-4f7c-a5c5-7f63add0c60f', content='Nvidia Blackwell GPU architecture (which serves as the basis for its latest B100 GPUs) and Grace CPU architecture (designed to manage AI workloads in data centers), connected via high-bandwidth NVLink interconnect. It comes with 128 GB of unified memory and 4 terabytes of solid-state storage. The system connects to Nvidia’s DGX Cloud service to enable developers to deploy models from a local machine to cloud infrastructure. Behind the news: In a blitz of announcements at the Consumer Electronics Show (CES), Nvidia also launched a platform for developing robotics, autonomous vehicles, and other physical AI systems. Cosmos includes pretrained language and vision models that range from 4 billion to 14 billion parameters for generating synthetic training data for robots or building policy models that translate a robot’s state into its next action. Nvidia also released Cosmos Nemotron, a 34 billion-parameter, vision-language model designed for use by AI agents, plus a video tokenizer and other tools for robotics developers. Why it matters: It’s common to train models on Nvidia A100 or H100 GPUs, which come with a price tag of at least $8,000 or $20,000 respectively, along with 40 gigabytes to 80 gigabytes of memory. These hefty requirements push many developers to buy access to computing infrastructure from a cloud provider. Coming in at $3,000 with 128 gigabytes of memory, Project Digits is designed to empower machine learning engineers to train and run larger models on their', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='004cf9e4f7c4383f8f0d46ff22636b68ea2b66b36723787c686f853ce55cdb2f-e5cc9229-e430-4e37-a00c-642a894d7d96', content='own machines. We’re thinking: We look forward to seeing cost/throughput comparisons between running a model on Project Digits, A100, and H100. Calibrating Contrast Contrastive loss functions make it possible to produce good embeddings without labeled data. A twist on this idea makes even more useful embeddings. What’s new: Vlad Sobal and colleagues at Meta, New York University, Brown University, Genentech, and Canadian Institute for Advanced Research introduced X-Sample contrastive loss (X-CLR), a self-supervised loss function that enables vision models to learn embeddings that capture similarities and differences among examples with greater subtlety. Key insight: Contrastive loss functions like SimCLR equally encourage a model to produce dissimilar embeddings of images of, say, a cat, a dog, and a dump truck. But, of course, cats and dogs are more similar to each other than either are to dump trucks. Instead of marking examples as similar or dissimilar, X-CLR assigns similarity scores, so a model can learn to produce embeddings that match those scores. How it works: The authors used X-CLR to train an embedding model on Conceptual Captions datasets of image-text pairs scraped from the web: CC-3M (3 million text-image pairs) and CC-12M (12 million text-image pairs). The model was similar to CLIP , except the text encoder was a sentence transformer pretrained on sentence pairs, and the vision encoder was a ResNet-50 pretrained on ImageNet. The sentence transformer embedded', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='96d92fa9bf2a42152d2c2035a21769126c09d53b80981a1e0653aa98f84e757e-c5309220-72a4-44b5-852d-b7af83bb407a', content='text captions for all examples. The system computed similarity scores according to cosine similarity between the text embeddings. Similarly, a ResNet-50 computed image embeddings, and the system computed similarity scores between them. The authors froze the sentence transformer and used the text similarity scores as labels in the loss function. The loss function minimized the difference between the similarity scores of the text embeddings and the corresponding similarity scores of the image embeddings. Results: Systems trained using X-CLR outperformed competitors in ImageNet classification, especially when less training data was available. (The authors followed CLIP’s method of classification: They computed the similarity between an image embedding and text embeddings of all classes. The image’s classification was the class that corresponds to the text embedding with the highest similarity to the image embedding.) The authors compared a system trained using X-CLR, one trained using SimCLR, and CLIP. After training on the CC-3M dataset, the X-CLR system achieved 58.2 percent accuracy on ImageNet, while the SimCLR model achieved 57.0 percent and CLIP achieved 41.0 percent. Training on CC-12M resulted in smaller differences: X-CLR achieved 59.4 percent accuracy, SimCLR achieved 58.9 percent, and CLIP achieved 58.8 percent. Why it matters: Contrastive loss functions are very useful, but the similar/dissimilar dichotomy leaves important nuances unaccounted for. Like CLIP, X-CLR', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='96164c89e08d8275875ce3d3000f050f04dba1a9cb46a53d8616b0e3cfcb3773-53ac2766-dd0d-429f-ac8a-fbc035c55702', content='takes advantage of both images and their captions for self-supervised learning. However, CLIP learns to recognize image-text pairs as similar or dissimilar, while X-CLR matches image-image pairs using captions as a similarity signal that’s continuous rather than discrete. We’re thinking: Reality is not black and white. Allowing for shades of gray makes for better modeling.', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='0feca44fa6d5a547abc4d6e6d64f29a8a288ce9e9354764bd5245e512d7d59f7-25cc6f26-4a97-48e4-9652-0249b9e40174', content=\"Share\\nShare\\n\\nShare\\n\\nSubscribe to The Batch Stay updated with weekly AI News and Insights delivered to your inbox\\nSubscribe to The Batch Stay updated with weekly AI News and Insights delivered to your inbox\\nSubscribe to The Batch Stay updated with weekly AI News and Insights delivered to your inbox\\n\\n\\n\\n\\nCourses The Batch Community Careers About\\n\\nCourses\\nThe Batch\\nCommunity\\nCareers\\nAbout\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nExplore Courses\\nAI Newsletter The Batch Andrew's Letter Data Points ML Research Blog\\nThe Batch\\nAndrew's Letter\\nData Points\\nML Research\\nBlog\\nCommunity Forum Events Ambassadors Ambassador Spotlight\\nForum\\nEvents\\nAmbassadors\\nAmbassador Spotlight\\nResources\\nCompany About Careers Contact\\nAbout\\nCareers\\nContact\\nWeekly Issues\\nAndrew's Letters\\nData Points\\nML Research\\nBusiness\\nScience\\nCulture\\nHardware\\nAI Careers\\nAbout\\nThe Batch\\nWeekly Issues\\nissue 284\", source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='d02e297b265862f009c67d4ec2c8e39b0345e8061084699108db6f98bb1e0563-4a4a8519-eded-48ae-aa25-14d61506b042', content='Technical proficiency in AI. PMs need to understand what products might be technically feasible to build. They also need to understand the lifecycle of AI projects, such as data collection, building, then monitoring, and maintenance of AI models.\\nIterative development. Because AI development is much more iterative than traditional software and requires more course corrections along the way, PMs need to understand how to manage such a process.\\nData proficiency. AI products often learn from data, and they can be designed to generate richer forms of data than traditional software.\\nSkill in managing ambiguity. Because AI’s performance is hard to predict in advance, PMs need to be comfortable with this and have tactics to manage it.\\nOngoing learning. AI technology is advancing rapidly. PMs, like everyone else who aims to make best use of the technology, need to keep up with the latest technology advances, product ideas, and how they fit into users’ lives.\\nThe developers trained it on roughly 15 trillion tokens, including a larger percentage of coding and math data relative to DeepSeek-V2. They fine-tuned it on a wide variety of tasks using output generated by DeepSeek-R1 and DeepSeek-V2.5. They further sharpened its performance across diverse domains using the reinforcement learning algorithm known as group relative policy optimization .', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='cc6ee9a4eebb59beaefaf1c4c84107261720190036c5f43aaa794936b3c5d28a-bac869a3-8c3d-45a1-a10a-2189c2eb4702', content='Earlier work showed that training to predict the next two tokens would improve performance over learning to predict just one. The authors implemented this procedure. The model learned to predict the first token as usual and used an additional set of layers to learn to predict the second token. The additional layers aren’t used at inference.\\nFollowing DeepSeek-V2 , DeepSeek-V3 uses multi-head latent attention, which saves memory during execution relative to other variants of attention.\\nAlso like DeepSeek-V2, the new model combines dedicated (routed) and shared experts. The model chooses eight of 256 experts for a particular input, but it also uses a shared expert that processes all inputs.\\nDeepSeek-V3 showed exceptional performance in coding and math tasks. In coding, DeepSeek-V3 dominated in five of the seven benchmarks tested. However, DeepSeek-V3 lost to o1 on one of the five, according to a public leaderboard. Specifically, on Polyglot , which tests a model’s ability to generate code in response to difficult requests in multiple programming languages, DeepSeek-V3 (48.5 percent accuracy) beat Claude Sonnet 3.5 (45.3 percent accuracy), though it lost to o1 (61.7 percent accuracy).\\nIn language tasks, it performed neck-and-neck with Claude 3.5 Sonnet, achieving higher scores in some tasks and lower in others.', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='3bc367d0d2cac21b1239a3777d2eaced375e14da6f86363f2d15ac37971b7f77-e157a846-4733-4bbd-b1cc-6830cf478c3f', content='A new hierarchy divides nations into three groups that would have different degrees of access to AI chips both designed in the U.S. and manufactured abroad using U.S. technology, as well as proprietary AI models.\\nTier 1: Australia, Japan, Taiwan, the United Kingdom, and most of Europe would retain nearly unrestricted access. However, these nations must keep 75 percent of their AI computing power within allied countries. No more than 10 percent can be transferred to any single country outside this group to ensure that advanced AI development remains concentrated among close U.S. allies.\\nTier 2: Traditional U.S. allies and trade partners like Israel, Saudi Arabia, and Singapore face an initial cap of 507 million units of total processing power (TPP) — roughly the computational capacity of 32,000 Nvidia H100 chips — through the first quarter of 2025. The cap would increase to 1.02 billion TPP by 2027. U.S. companies that operate in these countries can apply for higher limits: 633 million TPP in Q1 2025, rising to 5.064 billion TPP by Q1 2027.\\nTier 3: China, Russia, and around two dozen other countries are blocked from receiving advanced AI chips, model weights, and specialized knowledge related to these systems.', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='b53fd95126f3947324d73cfd39e8688ee7f59790ee57a2e7ef85eeb2a4f45c82-8131af37-7a49-4201-bbe9-a9eab2faefd2', content='The U.S. Commerce Department’s export control agency must approve the export of models or transfer of weights of closed models that were trained using more than 10 26 computational operations. These rules target future systems, as no known models today used this amount of computation during training.\\nCompanies based in the U.S. must maintain at least 50 percent of their total AI computing power within U.S. borders. They also must track distribution of their models, implement security measures, and submit to regular audits.\\nProject Digits runs Nvidia’s DGX operating system, a flavor of Ubuntu Linux.\\nThe system is based on a GB10 system-on-a-chip that combines the Nvidia Blackwell GPU architecture (which serves as the basis for its latest B100 GPUs) and Grace CPU architecture (designed to manage AI workloads in data centers), connected via high-bandwidth NVLink interconnect.\\nIt comes with 128 GB of unified memory and 4 terabytes of solid-state storage.\\nThe system connects to Nvidia’s DGX Cloud service to enable developers to deploy models from a local machine to cloud infrastructure.\\nThe sentence transformer embedded text captions for all examples. The system computed similarity scores according to cosine similarity between the text embeddings.\\nSimilarly, a ResNet-50 computed image embeddings, and the system computed similarity scores between them.', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='ef50876e6838f8e43568e787e5da6d5f43d0f35546d8ecd985dae527d2685652-bd1eb64e-8258-42ec-bf11-edec3d57a206', content='The authors froze the sentence transformer and used the text similarity scores as labels in the loss function. The loss function minimized the difference between the similarity scores of the text embeddings and the corresponding similarity scores of the image embeddings.\\nThe authors compared a system trained using X-CLR, one trained using SimCLR, and CLIP. After training on the CC-3M dataset, the X-CLR system achieved 58.2 percent accuracy on ImageNet, while the SimCLR model achieved 57.0 percent and CLIP achieved 41.0 percent.\\nTraining on CC-12M resulted in smaller differences: X-CLR achieved 59.4 percent accuracy, SimCLR achieved 58.9 percent, and CLIP achieved 58.8 percent.', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='07b0a30c527289956b4635f4cbe91ba583e37746c068dceb4cbdb6bd9c453953-26e0af01-21dd-4618-909e-9907925bd848', content='Courses\\nThe Batch\\nCommunity\\nCareers\\nAbout\\n✨ New course! Enroll in Reinforcement Fine-Tuning LLMs with GRPO\\nDear friends,\\nWriting software, especially prototypes, is becoming cheaper. This will lead to increased demand for people who can decide what to build. AI Product Management has a bright future!\\nSoftware is often written by teams that comprise Product Managers (PMs), who decide what to build (such as what features to implement for what users) and Software Developers, who write the code to build the product. Economics shows that when two goods are complements — such as cars (with internal-combustion engines) and gasoline — falling prices in one leads to higher demand for the other. For example, as cars became cheaper, more people bought them, which led to increased demand for gas. Something similar will happen in software. Given a clear specification for what to build, AI is making the building itself much faster and cheaper. This will significantly increase demand for people who can come up with clear specs for valuable things to build.\\nThis is why I’m excited about the future of Product Management, the discipline of developing and managing software products. I’m especially excited about the future of AI Product Management, the discipline of developing and managing AI software products.', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='5b87302abea61fba66480db446e73fd973c64d9db3a8606090b7ede5a4cd4d02-16a39963-401d-4719-bc44-5cefbffbf685', content='Many companies have an Engineer:PM ratio of, say, 6:1. (The ratio varies widely by company and industry, and anywhere from 4:1 to 10:1 is typical.) As coding becomes more efficient, I think teams will need more product management work (as well as design work) as a fraction of the total workforce. Perhaps engineers will step in to do some of this work, but if it remains the purview of specialized Product Managers, then the demand for these roles will grow.\\nThis change in the composition of software development teams is not yet moving forward at full speed. One major force slowing this shift, particularly in AI Product Management, is that Software Engineers, being technical, are understanding and embracing AI much faster than Product Managers. Even today, most companies have difficulty finding people who know how to develop products and also understand AI, and I expect this shortage to grow.\\nFurther, AI Product Management requires a different set of skills than traditional software Product Management. It requires:\\nFinally, AI Product Managers will need to know how to ensure that AI is implemented responsibly (for example, when we need to implement guardrails to prevent bad outcomes), and also be skilled at gathering feedback fast to keep projects moving. Increasingly, I also expect strong product managers to be able to build prototypes for themselves.', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='953cc3075eb8c554665310e2e465a1122e06b11a4c0f2841163817591b70b3d5-bb4efe88-338f-41a9-af61-4c2db3cd8400', content='The demand for good AI Product Managers will be huge. In addition to growing AI Product Management as a discipline, perhaps some engineers will also end up doing more product management work.\\nThe variety of valuable things we can build is nearly unlimited. What a great time to build!\\nKeep learning,\\nAndrew\\nGet up-close and personal with OpenAI’s groundbreaking o1 model! In our short course “Reasoning with o1,” you’ll learn how to get the best performance in coding, planning, and STEM tasks; perform complex, multi-step tasks; and optimize prompts with meta prompting. Enroll today\\nA new model from Hangzhou upstart DeepSeek delivers outstanding performance and may change the equation for training costs.\\nWhat’s new: DeepSeek-V3 is an open large language model that outperforms Llama 3.1 405B and GPT-4o on key benchmarks and achieves exceptional scores in coding and math. The weights are open except for applications that involve military uses, harming minors, generating false information, and similar restrictions. You can download them here .', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='64ef12ca534c54568c57ecfd9c1380194a8aeb6e9405e0d03259c14692789475-aa226cf8-9407-4e1a-b1f3-48bb61c5cebb', content='Mixture of experts (MoE) basics: The MoE architecture uses different subsets of its parameters to process different inputs. Each MoE layer contains a group of neural networks, or experts, preceded by a gating module that learns to choose which one(s) to use based on the input. In this way, different experts learn to specialize in different types of examples. Because not all parameters are used to produce any given output, the network uses less energy and runs faster than models of similar size that use all parameters to process every input.\\nHow it works: DeepSeek-V3 is a mixture-of-experts (MoE) transformer that comprises 671 billion parameters, of which 37 billion are active at any moment. The team trained the model in 2.79 million GPU hours — less than 1/10 the time required to train Llama 3.1 405B , which DeepSeek-V3 substantially outperforms — at an extraordinarily low cost of $5.6 million.\\nResults: In DeepSeek’s tests, DeepSeek-V3 outperformed Llama 3.1 405B and Qwen 2.5 72B across the board, and its performance compared favorably with that of GPT-4o.\\nBehind the news: OpenAI’s o1 models excel thanks to agentic workflows in which they reflect on their own outputs, use tools, and so on. DeepSeek swims against the tide and achieves superior results without relying on agentic workflows.', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='d459dae2ffdea23f8a83fa22b1d6abc7ec276287085a3031b84c29fa99fc8097-6207474e-f6c6-496a-a787-9b6cf2c333e3', content='Why it matters: Open models continue to challenge closed models, giving developers high-quality options that they can modify and deploy at will. But the larger story is DeepSeek-V3’s shockingly low training cost. The team doesn’t explain precisely how the model achieves outstanding performance with such a low processing budget. (The paper credits “meticulous engineering optimizations.”) But it’s likely that DeepSeek’s steady refinement of MoE is a key factor. DeepSeek-V2, also an MoE model, saved more than 40 percent in training versus the earlier DeepSeek 67B, which didn’t employ MoE. In 2022, Microsoft found that MoE cost five times less in training for equal performance compared to a dense model, and Google and Meta reported that MoE achieved better performance than dense models trained on the same numbers of tokens.\\nWe’re thinking: If they can be replicated, DeepSeek’s results have significant implications for the economics of training foundation models. If indeed it now costs around $5 million to build a GPT-4o-level model, more teams will be able to train such models, and the cost of competing with the AI giants could fall dramatically.\\nThe United States proposed limits on exports of AI technology that would dramatically expand previous restrictions, creating a new international hierarchy for access to advanced chips and models.', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='af133bceb5b2c43fe191ab3f34892bfa7c799eadd6a2ce6e87e14ccf53402943-d37c989c-8ae0-4e88-9ada-ff788032377f', content='What’s new: The Biden administration, which will transition to leadership under incoming President Trump next week, issued new rules that restrict exports of AI chips and models to most countries beyond a select group of close allies. The rules, which are not yet final, would create a three-tier system that limits exports to a number of close allies and blocks access entirely to China, Iran, North Korea, Russia, and others. They also would introduce the U.S.’ first-ever restrictions on exporting closed weights for large AI models.\\nHow it works: The restrictions were announced shortly after a leak reached the press. A public comment period of 120 days will enable the incoming U.S. Presidential administration to consider input from the business and diplomatic communities and modify the rules before they take effect. The rules are scheduled to take effect in one year.\\nBehind the news: The proposed rules build on 2022’s CHIPS and Science Act , which was designed to strengthen domestic semiconductor production and restrict technologies abroad that could bear on U.S. security. An initial round of restrictions in late 2022 barred semiconductor suppliers AMD and Nvidia from selling advanced chips to Chinese firms. In November 2024, the U.S. tightened restrictions further, ordering Taiwan Semiconductor Manufacturing Company, which fabricates those chips, to halt production of advanced chips destined for China.', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='a2c1a07e2df47af83801f1dc5af9c80a6019f5ba744abbfda196d9ec9d080d10-aadb1d46-290a-4b8d-8c9e-83f0f01d2af1', content='Plus green AI infrastructure: In addition, President Biden issued an executive order to encourage the rapid build-out of computing infrastructure for AI. The federal government will hold competitions among private companies to lease sites it owns for the building of data centers at private expense. The selection of sites will take into account availability of sources of clean energy, including support for nuclear energy. The government will expedite permitting on these sites and support development of energy transmission lines around them. It will also encourage international allies to invest in AI infrastructure powered by clean energy.\\nWhy it matters: Protecting the United States’ advantages in high tech has been a rising priority for the White House over the past decade.\\xa0The earlier export restrictions forced many Chinese AI developers to rely on less-powerful hardware. The new limits are likely to have a far broader impact. They could force developers in the Tier 2 and Tier 3 countries to build less resource-intensive models and lead them to collaborate more closely with each other, reducing the value of U.S.-made technology worldwide. They could hurt U.S. chip vendors, which have warned that the rules could weaken U.S. competitiveness in the global economy. They could also force companies that are building huge data centers to process AI calculations to reconsider their plans.', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='3c896a12dd3e19f070a3ee55766de86f924c99dda763aa96e649f27577771795-655fcdb1-1ae8-42ca-9abb-90ff0a1df027', content='We’re thinking: The Biden administration’s embargo on AI chips has been leaky . So far, it has slowed down adversaries only slightly while spurring significant investment in potential suppliers that aren’t connected to the U.S. While the public comment period invites lobbying and industry feedback, ultimately geopolitical priorities may hold sway. Whatever the outcome, reducing the world’s dependence on U.S. chips and models would result in a very different global AI ecosystem.\\nNvidia’s new desktop computer is built specifically to run large AI models.\\nWhat’s new: Project Digits is a personal supercomputer intended to help developers fine-tune and run large models locally. Project Digits, which is small enough to hold in one hand, will be available in May, starting at $3000.\\nHow it works: Project Digits is designed to run models of up to 200 billion parameters — roughly five times the size that fits comfortably on typical consumer hardware — provided they’re quantized to 4 bits of precision. Two units can be connected to run models such as Meta’s Llama 3.1 405B. Complete specifications are not yet available.', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='7299885a596ee6f6aa982e9f591b5021656fc3ad78e54d1974c4d88eb9b800cb-f9913205-2602-4fd5-8fb7-1868a3223057', content='Behind the news: In a blitz of announcements at the Consumer Electronics Show (CES), Nvidia also launched a platform for developing robotics, autonomous vehicles, and other physical AI systems. Cosmos includes pretrained language and vision models that range from 4 billion to 14 billion parameters for generating synthetic training data for robots or building policy models that translate a robot’s state into its next action. Nvidia also released Cosmos Nemotron, a 34 billion-parameter, vision-language model designed for use by AI agents, plus a video tokenizer and other tools for robotics developers.\\nWhy it matters: It’s common to train models on Nvidia A100 or H100 GPUs, which come with a price tag of at least $8,000 or $20,000 respectively, along with 40 gigabytes to 80 gigabytes of memory. These hefty requirements push many developers to buy access to computing infrastructure from a cloud provider. Coming in at $3,000 with 128 gigabytes of memory, Project Digits is designed to empower machine learning engineers to train and run larger models on their own machines.\\nWe’re thinking: We look forward to seeing cost/throughput comparisons between running a model on Project Digits, A100, and H100.\\nContrastive loss functions make it possible to produce good embeddings without labeled data. A twist on this idea makes even more useful embeddings.', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='52f8bd80512c69730f39ec79766906dd88a5eed61a72b3b4130d81faceb485d8-b8ab5f9c-fe1e-42b3-b3ec-076b94e4c8d9', content='What’s new: Vlad Sobal and colleagues at Meta, New York University, Brown University, Genentech, and Canadian Institute for Advanced Research introduced X-Sample contrastive loss (X-CLR), a self-supervised loss function that enables vision models to learn embeddings that capture similarities and differences among examples with greater subtlety.\\nKey insight: Contrastive loss functions like SimCLR equally encourage a model to produce dissimilar embeddings of images of, say, a cat, a dog, and a dump truck. But, of course, cats and dogs are more similar to each other than either are to dump trucks. Instead of marking examples as similar or dissimilar, X-CLR assigns similarity scores, so a model can learn to produce embeddings that match those scores.\\nHow it works: The authors used X-CLR to train an embedding model on Conceptual Captions datasets of image-text pairs scraped from the web: CC-3M (3 million text-image pairs) and CC-12M (12 million text-image pairs). The model was similar to CLIP , except the text encoder was a sentence transformer pretrained on sentence pairs, and the vision encoder was a ResNet-50 pretrained on ImageNet.', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='ac8bdaffb5228c1eb06c00eddd5dfbac12d1384ade4d66851e570d34894f7adc-bd3d5572-24b4-4935-a681-b746c1a9a5fd', content='Results: Systems trained using X-CLR outperformed competitors in ImageNet classification, especially when less training data was available. (The authors followed CLIP’s method of classification: They computed the similarity between an image embedding and text embeddings of all classes. The image’s classification was the class that corresponds to the text embedding with the highest similarity to the image embedding.)\\nWhy it matters: Contrastive loss functions are very useful, but the similar/dissimilar dichotomy leaves important nuances unaccounted for. Like CLIP, X-CLR takes advantage of both images and their captions for self-supervised learning. However, CLIP learns to recognize image-text pairs as similar or dissimilar, while X-CLR matches image-image pairs using captions as a similarity signal that’s continuous rather than discrete.\\nWe’re thinking: Reality is not black and white. Allowing for shades of gray makes for better modeling.\\nStay updated with weekly AI News and Insights delivered to your inbox', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " ImageDocument(id='848f8ad5d57320b6a79a9ff5ec1244061baa479fac35136662280df95e1cd4eb-87a34771-e727-4071-987c-bed37bb19d14', content='a cartoon depicting two men in front of a computer', image=<PIL.PngImagePlugin.PngImageFile image mode=RGB size=1200x676 at 0x25DF729F230>, source_url='https://dl-staging-website.ghost.io/content/images/2025/01/AIProductManager-2_1200px-1.jpg', image_url='https://dl-staging-website.ghost.io/content/images/2025/01/AIProductManager-2_1200px-1.jpg'),\n",
       " ImageDocument(id='ba9a7eb563572172d71b5056438ac8f41d05348fa966aeb6a9300d0c4251ce59-698ce24e-41cf-4d14-83e6-dfe9d00b0cf0', content='a yellow background with a white and blue graphic of a brain', image=<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=1890x1063 at 0x25DF7BC4050>, source_url='https://dl-staging-website.ghost.io/content/images/2025/01/The-Batch-ads-and-exclusive-banners---2024-12-16T174314.640--1-.png', image_url='https://dl-staging-website.ghost.io/content/images/2025/01/The-Batch-ads-and-exclusive-banners---2024-12-16T174314.640--1-.png'),\n",
       " ImageDocument(id='aee5b2d8292e9aa9b4a93cb496e016d6243aca10932e09632611d24d13ea89d0-7f1ba73e-0ea1-4183-be80-5d968debb480', content='a bar chart showing the number of people who have been in the us', image=<PIL.PngImagePlugin.PngImageFile image mode=RGB size=1200x675 at 0x25DF72DA0F0>, source_url='https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--45-.png', image_url='https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--45-.png'),\n",
       " ImageDocument(id='d4f301b136d02134102c4a988be93c328e188508598b3e9064b472746d4a9d14-1aa9c6dc-37e8-4f95-aba4-dfdff831f258', content='the world map with countries and their countries', image=<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1200x676 at 0x25DF74B4050>, source_url='https://dl-staging-website.ghost.io/content/images/2025/01/BIDENCHIPS-10_1200px.jpg', image_url='https://dl-staging-website.ghost.io/content/images/2025/01/BIDENCHIPS-10_1200px.jpg'),\n",
       " ImageDocument(id='5d7f5bd5b9a7d013ae8209644737732c154b196262c1f9298b899939136db59a-90636abf-de80-4745-abce-e07f927e96aa', content='a gold box with a black background and a diagram of the components', image=<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1200x674 at 0x25DF7BC42B0>, source_url='https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--47-.jpg', image_url='https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--47-.jpg'),\n",
       " ImageDocument(id='d44734ce3b328c9ab5e503377659c37b1b1c8585214034a98ca63ca944845164-1d79159b-9100-4de9-9056-a8f8bbe50a74', content='a white sheet with a yellow border', image=<PIL.GifImagePlugin.GifImageFile image mode=P size=600x336 at 0x25DF74B5E50>, source_url='https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--44-.gif', image_url='https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--44-.gif')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveTextSplitter()\n",
    "image_describer = BLIPImageDescriber()\n",
    "\n",
    "text_docs = text_splitter.split(text, loaded_data.url)\n",
    "image_docs = [image_describer.describe(image) for image in images]\n",
    "docs = text_docs + image_docs\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8182d158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-25 02:02:51,149 | sentence_transformers.SentenceTransformer | INFO] -> Use pytorch device_name: cpu\n",
      "[2025-05-25 02:02:51,149 | sentence_transformers.SentenceTransformer | INFO] -> Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 57.84it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 40.02it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 44.54it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 42.63it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.58it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.22it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 38.88it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 40.00it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.51it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 37.63it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 27.09it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 26.93it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 29.72it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 40.71it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 37.34it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 38.90it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 37.08it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 38.93it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 44.00it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.40it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 38.63it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 39.08it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 39.81it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 38.49it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 40.78it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 40.40it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 37.72it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 37.48it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 105.64it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.39it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 38.47it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 36.18it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 37.33it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 39.64it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 40.96it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 39.20it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 39.62it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.24it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.46it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 37.28it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 40.26it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.54it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 44.99it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 61.95it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 106.54it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 137.11it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 147.36it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 42.40it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.53it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 42.63it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.99it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 42.80it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 44.28it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.56it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.35it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 42.50it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.81it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.46it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.91it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 39.26it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 75.96it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 142.78it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 124.76it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 38.37it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 44.45it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 42.57it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 40.15it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.89it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.24it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.16it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.91it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.99it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 39.83it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.14it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 40.24it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 39.56it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 56.42it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 65.52it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 44.61it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 44.86it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 37.57it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.17it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 56.10it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 40.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 40.72it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 47.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.25it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.37it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.85it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 44.97it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 44.55it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 42.56it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.77it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 47.49it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 131.36it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 142.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 141.41it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 124.10it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 140.27it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 146.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.07752761, -0.07712671, -0.00187728, ..., -0.00018483,\n",
       "        -0.04130648,  0.03334473],\n",
       "       [-0.07596719, -0.04356242,  0.04169593, ..., -0.04087131,\n",
       "        -0.01327076,  0.02455314],\n",
       "       [-0.00362282, -0.09913214,  0.05776122, ..., -0.01191531,\n",
       "         0.0412215 ,  0.01541616],\n",
       "       ...,\n",
       "       [ 0.09326685,  0.0327084 , -0.00491121, ..., -0.02058907,\n",
       "        -0.0873061 , -0.03950423],\n",
       "       [ 0.02394519,  0.0708113 , -0.04790877, ...,  0.0354294 ,\n",
       "        -0.01772317, -0.02503958],\n",
       "       [-0.06404288,  0.10308387, -0.06203021, ...,  0.03419654,\n",
       "         0.03382072,  0.08427884]], shape=(101, 384), dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_func = SentenceTransformerTextEmbedding()\n",
    "docs_embeddings = np.vstack([embedding_func.encode([doc.content]) for doc in docs])\n",
    "docs_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcc0da2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-25 02:03:26,345 | sentence_transformers.SentenceTransformer | INFO] -> Use pytorch device_name: cpu\n",
      "[2025-05-25 02:03:26,346 | sentence_transformers.SentenceTransformer | INFO] -> Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "adapted_embedding_func = ChromaTextEmbeddingAdapter(embedding_function=SentenceTransformerTextEmbedding())\n",
    "vectorstore = ChromaVectorStore(collection_name='new_collection', \n",
    "                                 embedding_function=adapted_embedding_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd06443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.add_documents(documents=docs,\n",
    "                          embeddings=docs_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f30dea60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 81.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ImageDocument(id='848f8ad5d57320b6a79a9ff5ec1244061baa479fac35136662280df95e1cd4eb-87a34771-e727-4071-987c-bed37bb19d14', content='a cartoon depicting two men in front of a computer', image=None, source_url='https://dl-staging-website.ghost.io/content/images/2025/01/AIProductManager-2_1200px-1.jpg', image_url='https://dl-staging-website.ghost.io/content/images/2025/01/AIProductManager-2_1200px-1.jpg'),\n",
       " TextDocument(id='3606b3a086420ec6180eff7a8613d6e277c849638e3fa4668e562f5799a5e5fd-59614c7f-8d02-4c14-ae5e-e56b0cd90081', content='can be connected to run models such as Meta’s Llama 3.1 405B. Complete specifications are not yet available. Project Digits runs Nvidia’s DGX operating system, a flavor of Ubuntu Linux. The system is based on a GB10 system-on-a-chip that combines the Nvidia Blackwell GPU architecture (which serves as the basis for its latest B100 GPUs) and Grace CPU architecture (designed to manage AI workloads in data centers), connected via high-bandwidth NVLink interconnect. It comes with 128 GB of unified memory and 4 terabytes of solid-state storage. The system connects to Nvidia’s DGX Cloud service to enable developers to deploy models from a local machine to cloud infrastructure. Behind the news: In a blitz of announcements at the Consumer Electronics Show (CES), Nvidia also launched a platform for developing robotics, autonomous vehicles, and other physical AI systems. Cosmos includes pretrained language and vision models that range from 4 billion to 14 billion parameters for generating synthetic training data for robots or building policy models that translate a robot’s state into its next action. Nvidia also released Cosmos Nemotron, a 34 billion-parameter, vision-language model designed for use by AI agents, plus a video tokenizer and other tools for robotics developers. Why it matters: It’s common to train models on Nvidia A100 or H100 GPUs, which come with a price tag of at least $8,000 or $20,000 respectively, along with 40 gigabytes to 80 gigabytes of memory. These hefty', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='b53fd95126f3947324d73cfd39e8688ee7f59790ee57a2e7ef85eeb2a4f45c82-8131af37-7a49-4201-bbe9-a9eab2faefd2', content='The U.S. Commerce Department’s export control agency must approve the export of models or transfer of weights of closed models that were trained using more than 10 26 computational operations. These rules target future systems, as no known models today used this amount of computation during training.\\nCompanies based in the U.S. must maintain at least 50 percent of their total AI computing power within U.S. borders. They also must track distribution of their models, implement security measures, and submit to regular audits.\\nProject Digits runs Nvidia’s DGX operating system, a flavor of Ubuntu Linux.\\nThe system is based on a GB10 system-on-a-chip that combines the Nvidia Blackwell GPU architecture (which serves as the basis for its latest B100 GPUs) and Grace CPU architecture (designed to manage AI workloads in data centers), connected via high-bandwidth NVLink interconnect.\\nIt comes with 128 GB of unified memory and 4 terabytes of solid-state storage.\\nThe system connects to Nvidia’s DGX Cloud service to enable developers to deploy models from a local machine to cloud infrastructure.\\nThe sentence transformer embedded text captions for all examples. The system computed similarity scores according to cosine similarity between the text embeddings.\\nSimilarly, a ResNet-50 computed image embeddings, and the system computed similarity scores between them.', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='d02e297b265862f009c67d4ec2c8e39b0345e8061084699108db6f98bb1e0563-4a4a8519-eded-48ae-aa25-14d61506b042', content='Technical proficiency in AI. PMs need to understand what products might be technically feasible to build. They also need to understand the lifecycle of AI projects, such as data collection, building, then monitoring, and maintenance of AI models.\\nIterative development. Because AI development is much more iterative than traditional software and requires more course corrections along the way, PMs need to understand how to manage such a process.\\nData proficiency. AI products often learn from data, and they can be designed to generate richer forms of data than traditional software.\\nSkill in managing ambiguity. Because AI’s performance is hard to predict in advance, PMs need to be comfortable with this and have tactics to manage it.\\nOngoing learning. AI technology is advancing rapidly. PMs, like everyone else who aims to make best use of the technology, need to keep up with the latest technology advances, product ideas, and how they fit into users’ lives.\\nThe developers trained it on roughly 15 trillion tokens, including a larger percentage of coding and math data relative to DeepSeek-V2. They fine-tuned it on a wide variety of tasks using output generated by DeepSeek-R1 and DeepSeek-V2.5. They further sharpened its performance across diverse domains using the reinforcement learning algorithm known as group relative policy optimization .', source_url='https://www.deeplearning.ai/the-batch/issue-284/'),\n",
       " TextDocument(id='547594176e43104e0bce000ce830433683b713d474495a40576342aca257bc42-9ecac01f-828d-4af4-ba95-3c687624d704', content='system is based on a GB10 system-on-a-chip that combines the Nvidia Blackwell GPU architecture (which serves as the basis for its latest B100 GPUs) and Grace CPU architecture (designed to manage AI workloads in data centers), connected via high-bandwidth NVLink interconnect. It comes with 128 GB of unified memory and 4 terabytes of solid-state storage. The system connects to Nvidia’s DGX Cloud service to enable developers to deploy models from a local machine to cloud infrastructure. Behind the news: In a blitz of announcements at the Consumer Electronics Show (CES), Nvidia also launched a platform for developing robotics, autonomous vehicles, and other physical AI systems. Cosmos includes pretrained language and vision models that range from 4 billion to 14 billion parameters for generating synthetic training data for robots or building policy models that translate a robot’s state into its next action. Nvidia also released Cosmos Nemotron, a 34 billion-parameter, vision-language model designed for use by AI agents, plus a video tokenizer and other tools for robotics developers. Why it matters: It’s common to train models on Nvidia A100 or H100 GPUs, which come with a price tag of at least $8,000 or $20,000 respectively, along with 40 gigabytes to 80 gigabytes of memory. These hefty requirements push many developers to buy access to computing infrastructure from a cloud provider. Coming in at $3,000 with 128 gigabytes of memory, Project Digits is designed to empower machine', source_url='https://www.deeplearning.ai/the-batch/issue-284/')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is computer?\"\n",
    "vectorstore.similarity_search(query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e8bb06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "News_article_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"user_query\"],\n",
    "    template=\"\"\"\n",
    "You are an advanced AI assistant designed to provide comprehensive and well-reasoned answers to user queries based on relevant news articles. You have access to the following context, which may include text from news articles and associated images (described in text form).\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Instructions:\n",
    "- Carefully read the context above, which contains multiple news articles relevant to the user's question.\n",
    "- If any images are described (e.g., captions, OCR, extracted text), incorporate them into your analysis.\n",
    "- Summarize and synthesize the information to answer the user's question.\n",
    "- Ensure your answer is accurate, relevant, and concise.\n",
    "\n",
    "User query:\n",
    "{user_query}\n",
    "\n",
    "Your answer:\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "230e8359",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_llm = OllamaRAGLLM(vectorstore=vectorstore, prompt_template=News_article_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19bcd8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 134.67it/s]\n"
     ]
    }
   ],
   "source": [
    "user_query = 'computer'\n",
    "res = rag_llm.query(user_query, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb43096d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RAGLLMResponse(user_query='computer')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67065b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context provided, I'll provide a comprehensive answer to the user's query \"computer\".\n",
      "\n",
      "From the given context, it appears that computers have become an integral part of our daily lives. The image depicts two men sitting in front of a computer, suggesting that they are engaging with this technology for various purposes.\n",
      "\n",
      "News articles and relevant information:\n",
      "\n",
      "1. **Computing Industry Trends**: According to recent news articles, the computing industry has seen significant advancements in the field of artificial intelligence (AI) and machine learning (ML). These technologies have enabled computers to become more intelligent and efficient, making them an essential tool for businesses, individuals, and organizations.\n",
      "2. **Computer Security Concerns**: Another article highlights the growing concern about computer security threats, such as cyber attacks and data breaches. This emphasizes the importance of using secure computers and protecting personal data from malicious online activities.\n",
      "3. **Environmental Impact**: A recent report notes that the production of computers has a significant environmental impact due to e-waste generation and energy consumption. This highlights the need for sustainable computing practices and responsible disposal methods.\n",
      "\n",
      "Incorporating image information:\n",
      "\n",
      "The caption accompanying the image reads: \"Two men working on their laptops, with a cityscape in the background.\" This suggests that the individuals are likely professionals or students using computers for work or education purposes.\n",
      "\n",
      "Synthesizing the information:\n",
      "\n",
      "In conclusion, computers have become an essential part of modern life, and their impact extends beyond personal use. The computing industry continues to evolve with advancements in AI and ML, while also raising concerns about security and environmental sustainability. As technology advances, it is crucial to consider these factors and adopt responsible practices to ensure a positive impact on society and the environment.\n",
      "\n",
      "Please let me know if you'd like me to expand on any of these points or provide additional information!\n"
     ]
    }
   ],
   "source": [
    "print(res.llm_resopnse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea68c375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ImageDocument(id='848f8ad5d57320b6a79a9ff5ec1244061baa479fac35136662280df95e1cd4eb-87a34771-e727-4071-987c-bed37bb19d14', content='a cartoon depicting two men in front of a computer', image=None, source_url='https://dl-staging-website.ghost.io/content/images/2025/01/AIProductManager-2_1200px-1.jpg', image_url='https://dl-staging-website.ghost.io/content/images/2025/01/AIProductManager-2_1200px-1.jpg')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9262416",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
