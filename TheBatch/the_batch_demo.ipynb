{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50e78e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-26 03:04:14,589 | python_pytorch_profiling_logger | INFO] -> ParserConfig validation.\n",
      "[2025-05-26 03:04:14,590 | python_pytorch_profiling_logger | INFO] -> ParserConfig validation done successfully.\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "[2025-05-26 03:04:21,783 | python_pytorch_profiling_logger | INFO] -> Loading TheBatch vectorestore.\n",
      "[2025-05-26 03:04:21,784 | python_pytorch_profiling_logger | INFO] -> SentenceTransformerTextEmbedding initialization.\n",
      "[2025-05-26 03:04:21,786 | sentence_transformers.SentenceTransformer | INFO] -> Use pytorch device_name: cpu\n",
      "[2025-05-26 03:04:21,787 | sentence_transformers.SentenceTransformer | INFO] -> Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "[2025-05-26 03:04:24,145 | python_pytorch_profiling_logger | INFO] -> SentenceTransformerTextEmbedding done successfully.\n",
      "C:\\Users\\User\\Desktop\\MultimodalRAGSystem\\VectorStore\\chroma_vector_store.py:64: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  self.vectorstore = Chroma(embedding_function=self.embedding_function,\n",
      "[2025-05-26 03:04:24,555 | chromadb.telemetry.product.posthog | INFO] -> Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "[2025-05-26 03:04:24,633 | python_pytorch_profiling_logger | INFO] -> TheBatch vectorestore loaded successfully.\n",
      "C:\\Users\\User\\Desktop\\MultimodalRAGSystem\\LLM\\rag_llm.py:63: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  model: Ollama = pydantic.Field(default=Ollama(model='llama3.2'))\n",
      "[2025-05-26 03:04:24,862 | python_pytorch_profiling_logger | INFO] -> OllamaRAGLLM initialization\n",
      "[2025-05-26 03:04:24,863 | python_pytorch_profiling_logger | INFO] -> OllamaRAGLLM initialization done successfully.\n"
     ]
    }
   ],
   "source": [
    "from TheBatch.the_batch_model import TheBatchLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b08c253",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-26 03:07:51,133 | python_pytorch_profiling_logger | INFO] -> OllamaRAGLLM processing user query: What is AI?\n",
      "[2025-05-26 03:07:51,134 | python_pytorch_profiling_logger | INFO] -> Searching 3 similar documents for query: What is AI? in ChromaVectoreStore\n",
      "[2025-05-26 03:07:51,134 | python_pytorch_profiling_logger | INFO] -> SentenceTransformerTextEmbedding encoding sentences.\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 112.36it/s]\n",
      "[2025-05-26 03:07:51,147 | python_pytorch_profiling_logger | INFO] -> SentenceTransformerTextEmbedding successfuly encoded sentences.\n",
      "[2025-05-26 03:07:51,149 | python_pytorch_profiling_logger | INFO] -> 3 similar documents for query: What is AI? successfully retieved from ChromaVectoreStore\n",
      "[2025-05-26 03:07:57,051 | python_pytorch_profiling_logger | INFO] -> OllamaRAGLLM successfully processed user query: What is AI?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RAGLLMResponse(user_query='What is AI?')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is AI?\"\n",
    "answer = TheBatchLLM.query(question, 3)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "108c2a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, I can summarize that \"AI\" refers to Artificial Intelligence. The context includes articles about various advancements and developments in the field of AI, such as new models, robotic systems, language models, and multimodal approaches.\n",
      "\n",
      "In general, Artificial Intelligence (AI) is a broad term that encompasses a range of technologies aimed at creating intelligent machines that can perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and more.\n",
      "\n",
      "The context highlights various aspects of AI, including:\n",
      "\n",
      "1. Language models: Such as Llama 4, which is mentioned in the article \"Inside the Mind of Claude\" as a mixture of vision-language experts.\n",
      "2. Multimodal approaches: Which enable AI systems to understand and interact with multiple forms of data, such as text, images, and speech, as seen in articles like \"Open Voice-to-Voice With Vision\" and \"Compact Vision-Language with Open Weights\".\n",
      "3. Robotics and automation: Such as Hugging Face's Open Robot, mentioned in the article \"OpenAI’s Five New Models\".\n",
      "4. Emotion recognition and understanding: As demonstrated by ChatGPT in the article \"Open Voice-to-Voice With Vision\".\n",
      "\n",
      "Overall, AI has become an increasingly important field, with various applications across industries, including healthcare, finance, education, and more.\n",
      "\n",
      "References:\n",
      "\n",
      "* The Batch AI News and Insights\n",
      "* Inside the Mind of Claude\n",
      "* OpenAI’s Five New Models\n",
      "* Hugging Face’s Open Robot\n",
      "* Compact Vision-Language with Open Weights\n"
     ]
    }
   ],
   "source": [
    "print(answer.llm_resopnse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "652d8b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TextDocument(id='e8ca36693b9c8ef2e03f6cd02f1d96da5094b88e310b70ae7221b8d2abebdb8e-d4907494-a904-458d-b19b-ef58c3ac0292', content='can empower everyone to build with AI. Apr 23, 2025 OpenAI’s Five New Models, Hugging Face’s Open Robot, U.S. Tightens Grip on AI Chips, Text-Only LLMs Go Multimodal The Batch AI News and Insights: Even though I’m a much better Python than JavaScript developer, with AI assistance, I’ve been writing a lot of JavaScript code recently. Apr 16, 2025 Google Unveils Gemini 2.5, MCP Gains Momentum, Behind Sam Altman’s Fall and Rise, LLMs That Understand Misspellings The Batch AI News and Insights: I’ve noticed that many GenAI application projects put in automated evaluations (evals) of the system’s output probably later — and rely on humans to manually examine and judge outputs longer — than they should. Apr 09, 2025 Inside the Mind of Claude, Llama 4’s Mixture of Vision-Language Experts, More Open Multimodal Models, Neural Net for Tabular Data The Batch AI News and Insights: I am so sorry that the U.S. is letting down our friends and allies. Apr 02, 2025 Open Voice-to-Voice With Vision, ChatGPT Creates Emotional Bonds, Human Action in 3D, Web Scrapers Caught in Maze The Batch AI News and Insights: Contrary to standard prompting advice that you should give LLMs the context they need to succeed, I find it’s sometimes faster to be lazy and dash off a quick, imprecise prompt and see what happens. Mar 26, 2025 Compact Vision-Language with Open Weights, Faster Learning, Diffusion in Few Steps, LLMs Aid Tutors The Batch AI News and Insights: Fine-tuning small language models has been', source_url='https://www.deeplearning.ai/the-batch/'),\n",
       " TextDocument(id='e8ca36693b9c8ef2e03f6cd02f1d96da5094b88e310b70ae7221b8d2abebdb8e-bd88b098-cdbf-4bd5-b775-9cde1df8808b', content='can empower everyone to build with AI. Apr 23, 2025 OpenAI’s Five New Models, Hugging Face’s Open Robot, U.S. Tightens Grip on AI Chips, Text-Only LLMs Go Multimodal The Batch AI News and Insights: Even though I’m a much better Python than JavaScript developer, with AI assistance, I’ve been writing a lot of JavaScript code recently. Apr 16, 2025 Google Unveils Gemini 2.5, MCP Gains Momentum, Behind Sam Altman’s Fall and Rise, LLMs That Understand Misspellings The Batch AI News and Insights: I’ve noticed that many GenAI application projects put in automated evaluations (evals) of the system’s output probably later — and rely on humans to manually examine and judge outputs longer — than they should. Apr 09, 2025 Inside the Mind of Claude, Llama 4’s Mixture of Vision-Language Experts, More Open Multimodal Models, Neural Net for Tabular Data The Batch AI News and Insights: I am so sorry that the U.S. is letting down our friends and allies. Apr 02, 2025 Open Voice-to-Voice With Vision, ChatGPT Creates Emotional Bonds, Human Action in 3D, Web Scrapers Caught in Maze The Batch AI News and Insights: Contrary to standard prompting advice that you should give LLMs the context they need to succeed, I find it’s sometimes faster to be lazy and dash off a quick, imprecise prompt and see what happens. Mar 26, 2025 Compact Vision-Language with Open Weights, Faster Learning, Diffusion in Few Steps, LLMs Aid Tutors The Batch AI News and Insights: Fine-tuning small language models has been', source_url='https://www.deeplearning.ai/the-batch/'),\n",
       " TextDocument(id='e8ca36693b9c8ef2e03f6cd02f1d96da5094b88e310b70ae7221b8d2abebdb8e-af5d1325-0a6d-4c71-b2b6-2b01801ba02e', content='can empower everyone to build with AI. Apr 23, 2025 OpenAI’s Five New Models, Hugging Face’s Open Robot, U.S. Tightens Grip on AI Chips, Text-Only LLMs Go Multimodal The Batch AI News and Insights: Even though I’m a much better Python than JavaScript developer, with AI assistance, I’ve been writing a lot of JavaScript code recently. Apr 16, 2025 Google Unveils Gemini 2.5, MCP Gains Momentum, Behind Sam Altman’s Fall and Rise, LLMs That Understand Misspellings The Batch AI News and Insights: I’ve noticed that many GenAI application projects put in automated evaluations (evals) of the system’s output probably later — and rely on humans to manually examine and judge outputs longer — than they should. Apr 09, 2025 Inside the Mind of Claude, Llama 4’s Mixture of Vision-Language Experts, More Open Multimodal Models, Neural Net for Tabular Data The Batch AI News and Insights: I am so sorry that the U.S. is letting down our friends and allies. Apr 02, 2025 Open Voice-to-Voice With Vision, ChatGPT Creates Emotional Bonds, Human Action in 3D, Web Scrapers Caught in Maze The Batch AI News and Insights: Contrary to standard prompting advice that you should give LLMs the context they need to succeed, I find it’s sometimes faster to be lazy and dash off a quick, imprecise prompt and see what happens. Mar 26, 2025 Compact Vision-Language with Open Weights, Faster Learning, Diffusion in Few Steps, LLMs Aid Tutors The Batch AI News and Insights: Fine-tuning small language models has been', source_url='https://www.deeplearning.ai/the-batch/')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer.relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fae646e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
